<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  



























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>B.Sc. Psychologie Statisik II | Psychologische Methodenlehre | PHB</title>

<link rel="icon" href="">

<meta name="title" content="B.Sc. Psychologie Statisik II | Psychologische Methodenlehre | PHB">
<meta name="description" content="Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin">

<meta property="og:title" content="B.Sc. Psychologie Statisik II | Psychologische Methodenlehre | PHB">
<meta property="og:site_title" content="PHB">
<meta property="og:description" content="Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin">
<meta property="og:url" content="http://methodenlehre.phb.de">
<meta property="og:image" content="/images/share.jpg">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="B.Sc. Psychologie Statisik II">
<meta property="twitter:description" content="Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin">
<meta property="twitter:url" content="http://methodenlehre.phb.de">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/images/share.jpg">


  <meta name="author" content="Esther Weidauer">
  <meta property="og:type" content="article">
  <meta property="og:updated_time" content="2024-10-01T10:57:29+00:00">
  <meta property="article:published_time" content="">
  <meta property="article:modified_time" content="2024-10-01T10:57:29+00:00">
  <meta name="revised" content="2024-10-01T10:57:29+00:00">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "BlogPosting",
      "author": { "@type": "Person", "name": "B.Sc. Psychologie Statisik II" },
      "datePublished": "",
      "dateModified": "2024-10-01T10:57:29+00:00",
    
    "name": "B.Sc. Psychologie Statisik II",
    "description": "Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin",
    "headline": "B.Sc. Psychologie Statisik II",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "" }
    },
    "url": "http://methodenlehre.phb.de"
  }
</script>

<link rel="alternate" type="application/rss+xml" href="http://methodenlehre.phb.de/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet" media="none" onload="this.removeAttribute('media'); this.onload = null;">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/_styles/all.css" rel="stylesheet">
  

  
    <link href="/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/_styles/background.css" rel="stylesheet">
  

  
    <link href="/_styles/body.css" rel="stylesheet">
  

  
    <link href="/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/_styles/button.css" rel="stylesheet">
  

  
    <link href="/_styles/card.css" rel="stylesheet">
  

  
    <link href="/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/_styles/code.css" rel="stylesheet">
  

  
    <link href="/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/_styles/float.css" rel="stylesheet">
  

  
    <link href="/_styles/font.css" rel="stylesheet">
  

  
    <link href="/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/_styles/form.css" rel="stylesheet">
  

  
    <link href="/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/_styles/header.css" rel="stylesheet">
  

  
    <link href="/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/_styles/image.css" rel="stylesheet">
  

  
    <link href="/_styles/link.css" rel="stylesheet">
  

  
    <link href="/_styles/list.css" rel="stylesheet">
  

  
    <link href="/_styles/main.css" rel="stylesheet">
  

  
    <link href="/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/_styles/section.css" rel="stylesheet">
  

  
    <link href="/_styles/table.css" rel="stylesheet">
  

  
    <link href="/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/_scripts/anchors.js"></script>

  <script src="/_scripts/dark-mode.js"></script>

  <script src="/_scripts/fetch-tags.js"></script>

  <script src="/_scripts/search.js"></script>

  <script src="/_scripts/site-search.js"></script>

  <script src="/_scripts/table-wrap.js"></script>

  <script src="/_scripts/tooltip.js"></script>


<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

  <body>
    







<header class="background" style="--image: url('/images/lines-7.png')" data-dark="true">
  <a href="/" class="home">
    
      <span class="logo">
        
          <img src="/images/logo.png" alt="logo">
        
      </span>
    
    
      <span class="title-text" data-tooltip="Home">
        
          <span class="title">PHB</span>
        
        
          <span class="subtitle">Psychologische Methodenlehre</span>
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/team/" data-tooltip="Unser Team">
          Team
        </a>
      
    
      
        <a href="/lehre/" data-tooltip="Methodenausbildung">
          Lehre
        </a>
      
    
      
        <a href="/beratung/" data-tooltip="Beratung zu Methodenfragen">
          Beratung
        </a>
      
    
      
        <a href="/forschung/" data-tooltip="Forschungsprojekte">
          Forschung
        </a>
      
    
      
        <a href="/aktuelles/" data-tooltip="Neuigkeiten und AnkÃ¼ndigungen">
          Aktuelles
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - filter out blank sections
-->






  
  
  

  <section class="background" data-size="1">
    <!--
  background: ;
  dark: ;
  size: 1;
-->


<h1 class="center">B.Sc. Psychologie Statisik II</h1>

<div class="post-info">
  
    
    
      <span data-tooltip="Author">
        <i class="icon fa-solid fa-feather-pointed"></i>
        <span>Esther Weidauer</span>
      </span>
    
  

  
  

  

  
    <span data-tooltip="Last updated on">
      <i class="icon fa-solid fa-clock-rotate-left"></i>
      <span>October 01, 2024</span>
    </span>
  
</div>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->









<div id="TOC">
<ul>
<li><a href="#einleitung" id="toc-einleitung">Einleitung</a></li>
<li>
<a href="#stichprobenkennwerte-verteilung" id="toc-stichprobenkennwerte-verteilung">Stichprobenkennwerte-Verteilung</a>
<ul>
<li><a href="#beispiel-mittelwert" id="toc-beispiel-mittelwert">Beispiel: Mittelwert</a></li>
<li><a href="#standardfehler-des-mittelwertes" id="toc-standardfehler-des-mittelwertes">Standardfehler des
Mittelwertes</a></li>
<li><a href="#berechnung-des-standardfehlers-des-mittelwertes" id="toc-berechnung-des-standardfehlers-des-mittelwertes">Berechnung des
Standardfehlers des Mittelwertes</a></li>
<li><a href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes" id="toc-schÃ¤tzung-des-standardfehlers-des-mittelwertes">SchÃ¤tzung des
Standardfehlers des Mittelwertes</a></li>
<li><a href="#zentraler-grenzwertsatz" id="toc-zentraler-grenzwertsatz">Zentraler Grenzwertsatz</a></li>
</ul>
</li>
<li>
<a href="#punktsch%C3%A4tzung-von-populationsparametern" id="toc-punktschÃ¤tzung-von-populationsparametern">PunktschÃ¤tzung von
Populationsparametern</a>
<ul>
<li><a href="#g%C3%BCtekriterien-f%C3%BCr-parametersch%C3%A4tzung" id="toc-gÃ¼tekriterien-fÃ¼r-parameterschÃ¤tzung">GÃ¼tekriterien fÃ¼r
ParameterschÃ¤tzung</a></li>
<li><a href="#punktsch%C3%A4tzung-des-mittelwertes" id="toc-punktschÃ¤tzung-des-mittelwertes">PunktschÃ¤tzung des
Mittelwertes</a></li>
<li><a href="#punktsch%C3%A4tzung-der-varianz" id="toc-punktschÃ¤tzung-der-varianz">PunktschÃ¤tzung der Varianz</a></li>
</ul>
</li>
<li>
<a href="#intervallsch%C3%A4tzung-von-populationsparametern" id="toc-intervallschÃ¤tzung-von-populationsparametern">IntervallschÃ¤tzung
von Populationsparametern</a>
<ul>
<li>
<a href="#konfidenzintervall-des-mittelwertes" id="toc-konfidenzintervall-des-mittelwertes">Konfidenzintervall des
Mittelwertes</a>
<ul>
<li><a href="#konfidenzintervall-pro-stichprobe" id="toc-konfidenzintervall-pro-stichprobe">Konfidenzintervall pro
Stichprobe</a></li>
</ul>
</li>
<li><a href="#sch%C3%A4tzung-des-konfidenzintervalls-des-mittelwertes" id="toc-schÃ¤tzung-des-konfidenzintervalls-des-mittelwertes">SchÃ¤tzung
des Konfidenzintervalls des Mittelwertes</a></li>
<li><a href="#konfidenzintervall-abg%C3%A4ngig-von-stichprobengr%C3%B6%C3%9Fe" id="toc-konfidenzintervall-abgÃ¤ngig-von-stichprobengrÃ¶Ãe">Konfidenzintervall
abgÃ¤ngig von StichprobengrÃ¶Ãe</a></li>
</ul>
</li>
<li>
<a href="#statistische-hypothesenpr%C3%BCfung" id="toc-statistische-hypothesenprÃ¼fung">Statistische
HypothesenprÃ¼fung</a>
<ul>
<li>
<a href="#signifikanztests" id="toc-signifikanztests">Signifikanztests</a>
<ul>
<li><a href="#einseitiger-signifikanztest" id="toc-einseitiger-signifikanztest">Einseitiger
Signifikanztest</a></li>
<li><a href="#zweiseitiger-signifikanztest" id="toc-zweiseitiger-signifikanztest">Zweiseitiger
Signifikanztest</a></li>
<li><a href="#standardisierte-pr%C3%BCfgr%C3%B6%C3%9Fen" id="toc-standardisierte-prÃ¼fgrÃ¶Ãen">Standardisierte PrÃ¼fgrÃ¶Ãen</a></li>
<li><a href="#signifikanztest-mit-empirischen-daten" id="toc-signifikanztest-mit-empirischen-daten">Signifikanztest mit
empirischen Daten</a></li>
</ul>
</li>
<li>
<a href="#hypothesentests" id="toc-hypothesentests">Hypothesentests</a>
<ul>
<li><a href="#standardisierter-effekt-cohens-delta" id="toc-standardisierter-effekt-cohens-delta">Standardisierter Effekt:
Cohenâs <span class="math inline">\(\delta\)</span></a></li>
<li><a href="#konfidenzintervalle-f%C3%BCr-cohens-delta" id="toc-konfidenzintervalle-fÃ¼r-cohens-delta">Konfidenzintervalle fÃ¼r
Cohenâs <span class="math inline">\(\delta\)</span></a></li>
<li><a href="#einstichproben-gauss-test" id="toc-einstichproben-gauss-test">Einstichproben-Gauss-Test</a></li>
<li><a href="#einstichproben-t-test" id="toc-einstichproben-t-test">Einstichproben T-Test</a></li>
<li><a href="#einstichproben-t-test-f%C3%BCr-abh%C3%A4ngige-beobachtungen" id="toc-einstichproben-t-test-fÃ¼r-abhÃ¤ngige-beobachtungen">Einstichproben
T-Test fÃ¼r abhÃ¤ngige Beobachtungen</a></li>
<li><a href="#einstichproben-binomialtest" id="toc-einstichproben-binomialtest">Einstichproben
Binomialtest</a></li>
<li><a href="#zweistichproben-t-test" id="toc-zweistichproben-t-test">Zweistichproben T-Test</a></li>
</ul>
</li>
<li>
<a href="#power-und-stichprobenplanung" id="toc-power-und-stichprobenplanung">Power und Stichprobenplanung</a>
<ul>
<li><a href="#stichprobenplanung-in-r" id="toc-stichprobenplanung-in-r">Stichprobenplanung in R</a></li>
</ul>
</li>
<li>
<a href="#tests-f%C3%BCr-kategoriale-merkmale" id="toc-tests-fÃ¼r-kategoriale-merkmale">Tests fÃ¼r Kategoriale
Merkmale</a>
<ul>
<li><a href="#chi2-statistik" id="toc-chi2-statistik"><span class="math inline">\(\chi^2\)</span>-Statistik</a></li>
<li><a href="#cramers-v" id="toc-cramers-v">Cramerâs <span class="math inline">\(V\)</span></a></li>
<li><a href="#chi2-test" id="toc-chi2-test"><span class="math inline">\(\chi^2\)</span>-Test</a></li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#multiplizit%C3%A4t" id="toc-multiplizitÃ¤t">MultiplizitÃ¤t</a>
<ul>
<li><a href="#bonferroni-korrektur" id="toc-bonferroni-korrektur">Bonferroni-Korrektur</a></li>
<li><a href="#holm-bonferroni-korrektur" id="toc-holm-bonferroni-korrektur">Holm-Bonferroni-Korrektur</a></li>
<li><a href="#fallback-prozedur" id="toc-fallback-prozedur">Fallback-Prozedur</a></li>
</ul>
</li>
<li>
<a href="#varianzanalyse-anova" id="toc-varianzanalyse-anova">Varianzanalyse (ANOVA)</a>
<ul>
<li><a href="#voraussetzungen" id="toc-voraussetzungen">Voraussetzungen</a></li>
<li>
<a href="#einfaktorielle-varianzanalyse" id="toc-einfaktorielle-varianzanalyse">Einfaktorielle Varianzanalyse</a>
<ul>
<li><a href="#messwertezerlegung" id="toc-messwertezerlegung">Messwertezerlegung</a></li>
<li><a href="#quadratsummenzerlegung" id="toc-quadratsummenzerlegung">Quadratsummenzerlegung</a></li>
<li><a href="#effektgr%C3%B6%C3%9Fensch%C3%A4tzer-hateta2" id="toc-effektgrÃ¶ÃenschÃ¤tzer-hateta2">EffektgrÃ¶ÃenschÃ¤tzer <span class="math inline">\(\hat{\eta}^2\)</span></a></li>
<li><a href="#effektgr%C3%B6%C3%9Fensch%C3%A4tzer-hatomega2" id="toc-effektgrÃ¶ÃenschÃ¤tzer-hatomega2">EffektgrÃ¶ÃenschÃ¤tzer <span class="math inline">\(\hat{\omega}^2\)</span></a></li>
<li><a href="#effektgr%C3%B6%C3%9Fe-phi2-signal-rausch-verh%C3%A4ltnis" id="toc-effektgrÃ¶Ãe-phi2-signal-rausch-verhÃ¤ltnis">EffektgrÃ¶Ãe <span class="math inline">\(\phi^2\)</span>, Signal-Rausch-VerhÃ¤ltnis</a></li>
<li><a href="#effektgr%C3%B6%C3%9Fe-phi" id="toc-effektgrÃ¶Ãe-phi">EffektgrÃ¶Ãe
<span class="math inline">\(\phi\)</span></a></li>
<li><a href="#effektgr%C3%B6%C3%9Fe-lambda" id="toc-effektgrÃ¶Ãe-lambda">EffektgrÃ¶Ãe <span class="math inline">\(\lambda\)</span></a></li>
<li><a href="#beziehungen-zwischen-effektgr%C3%B6%C3%9Fensch%C3%A4tzern" id="toc-beziehungen-zwischen-effektgrÃ¶ÃenschÃ¤tzern">Beziehungen zwischen
EffektgrÃ¶ÃenschÃ¤tzern</a></li>
<li><a href="#konfidenzintervalle-der-effektgr%C3%B6%C3%9Fen" id="toc-konfidenzintervalle-der-effektgrÃ¶Ãen">Konfidenzintervalle der
EffektgrÃ¶Ãen</a></li>
<li><a href="#sch%C3%A4tzung-der-populationsparameter" id="toc-schÃ¤tzung-der-populationsparameter">SchÃ¤tzung der
Populationsparameter</a></li>
</ul>
</li>
<li>
<a href="#hypothesenpr%C3%BCfung-in-der-varianzanalyse" id="toc-hypothesenprÃ¼fung-in-der-varianzanalyse">HypothesenprÃ¼fung in
der Varianzanalyse</a>
<ul>
<li><a href="#f-test" id="toc-f-test">F-Test</a></li>
<li><a href="#automatische-durchf%C3%BChrung-in-r" id="toc-automatische-durchfÃ¼hrung-in-r">Automatische DurchfÃ¼hrung in
R</a></li>
</ul>
</li>
<li>
<a href="#zweifaktorielle-varianzanalyze" id="toc-zweifaktorielle-varianzanalyze">Zweifaktorielle
Varianzanalyze</a>
<ul>
<li><a href="#nicht-partiielles-effektst%C3%A4rkenma%C3%9F-hateta2" id="toc-nicht-partiielles-effektstÃ¤rkenmaÃ-hateta2">Nicht-partiielles
EffektstÃ¤rkenmaÃ: <span class="math inline">\(\hat{\eta}^2\)</span></a></li>
<li><a href="#partielles-effektgr%C3%B6%C3%9Fenma%C3%9F-hateta_p2" id="toc-partielles-effektgrÃ¶ÃenmaÃ-hateta_p2">Partielles EffektgrÃ¶ÃenmaÃ
<span class="math inline">\(\hat{\eta}_p^2\)</span></a></li>
<li><a href="#sch%C3%A4tzung-der-haupteffekte" id="toc-schÃ¤tzung-der-haupteffekte">SchÃ¤tzung der Haupteffekte</a></li>
<li><a href="#sch%C3%A4tzung-des-residuums" id="toc-schÃ¤tzung-des-residuums">SchÃ¤tzung des Residuums</a></li>
<li><a href="#sch%C3%A4tzung-der-populationsresidualvarianz" id="toc-schÃ¤tzung-der-populationsresidualvarianz">SchÃ¤tzung der
Populationsresidualvarianz</a></li>
<li><a href="#hypothesenpr%C3%BCfung-bei-zweifaktorieller-varianzanalyse" id="toc-hypothesenprÃ¼fung-bei-zweifaktorieller-varianzanalyse">HypothesenprÃ¼fung
bei zweifaktorieller Varianzanalyse</a></li>
</ul>
</li>
<li><a href="#varianzanalyse-mit-messwiederholung" id="toc-varianzanalyse-mit-messwiederholung">Varianzanalyse mit
Messwiederholung</a></li>
<li><a href="#populationsmodell-der-varianzanalyse" id="toc-populationsmodell-der-varianzanalyse">Populationsmodell der
Varianzanalyse</a></li>
</ul>
</li>
<li>
<a href="#allgemeines-lineares-modell" id="toc-allgemeines-lineares-modell">Allgemeines Lineares Modell</a>
<ul>
<li>
<a href="#einfache-lineare-regression" id="toc-einfache-lineare-regression">Einfache lineare Regression</a>
<ul>
<li><a href="#bestimmung-der-regressionskoeffizienten" id="toc-bestimmung-der-regressionskoeffizienten">Bestimmung der
Regressionskoeffizienten</a></li>
<li><a href="#standardfehler-der-modellparameter" id="toc-standardfehler-der-modellparameter">Standardfehler der
Modellparameter</a></li>
<li><a href="#alternative-wege-zur-bestimmung-der-regressionskoeffizienten" id="toc-alternative-wege-zur-bestimmung-der-regressionskoeffizienten">Alternative
Wege zur Bestimmung der Regressionskoeffizienten</a></li>
<li><a href="#hypothesenpr%C3%BCfung-bei-einfacher-linearer-regression" id="toc-hypothesenprÃ¼fung-bei-einfacher-linearer-regression">HypothesenprÃ¼fung
bei einfacher linearer Regression</a></li>
<li><a href="#konfidenzintervalle-f%C3%BCr-regressionskoeffizienten" id="toc-konfidenzintervalle-fÃ¼r-regressionskoeffizienten">Konfidenzintervalle
fÃ¼r Regressionskoeffizienten</a></li>
<li><a href="#einfache-lineare-regression-in-r" id="toc-einfache-lineare-regression-in-r">Einfache lineare Regression in
R</a></li>
</ul>
</li>
<li>
<a href="#multiple-lineare-regression" id="toc-multiple-lineare-regression">Multiple lineare Regression</a>
<ul>
<li><a href="#modellgleichung" id="toc-modellgleichung">Modellgleichung</a></li>
<li><a href="#bestimmung-der-regressionskoeffizienten-1" id="toc-bestimmung-der-regressionskoeffizienten-1">Bestimmung der
Regressionskoeffizienten</a></li>
<li><a href="#kompensatorisches-modell" id="toc-kompensatorisches-modell">Kompensatorisches Modell</a></li>
<li><a href="#dummy-kodierung" id="toc-dummy-kodierung">Dummy
Kodierung</a></li>
<li><a href="#interpretation-von-multiplen-regressionsgewichten" id="toc-interpretation-von-multiplen-regressionsgewichten">Interpretation
von multiplen Regressionsgewichten</a></li>
<li><a href="#inkrementelle-varianzaufkl%C3%A4rung" id="toc-inkrementelle-varianzaufklÃ¤rung">Inkrementelle
VarianzaufklÃ¤rung</a></li>
<li><a href="#punktsch%C3%A4tzung-der-varianzaufkl%C3%A4rung" id="toc-punktschÃ¤tzung-der-varianzaufklÃ¤rung">PunktschÃ¤tzung der
VarianzaufklÃ¤rung</a></li>
<li><a href="#hypothesenpr%C3%BCfung-mit-multipler-linearer-regression" id="toc-hypothesenprÃ¼fung-mit-multipler-linearer-regression">HypothesenprÃ¼fung
mit multipler linearer Regression</a></li>
<li><a href="#modellvergleiche-in-r" id="toc-modellvergleiche-in-r">Modellvergleiche in R</a></li>
<li><a href="#interaktionseffekte-bei-mutlipler-linearer-regression" id="toc-interaktionseffekte-bei-mutlipler-linearer-regression">Interaktionseffekte
bei mutlipler linearer Regression</a></li>
</ul>
</li>
<li>
<a href="#annahmen-des-allgemeinen-linearen-modells" id="toc-annahmen-des-allgemeinen-linearen-modells">Annahmen des
allgemeinen linearen Modells</a>
<ul>
<li><a href="#korrekte-spezifikation-linearit%C3%A4t" id="toc-korrekte-spezifikation-linearitÃ¤t">Korrekte Spezifikation,
LinearitÃ¤t</a></li>
<li><a href="#pr%C3%BCfung-der-homoskedastizit%C3%A4t" id="toc-prÃ¼fung-der-homoskedastizitÃ¤t">PrÃ¼fung der
HomoskedastizitÃ¤t</a></li>
<li><a href="#normalverteilung-der-residuen" id="toc-normalverteilung-der-residuen">Normalverteilung der
Residuen</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>

<div id="einleitung" class="section level1">
<h1>Einleitung</h1>
<p>Statistik II umfasst hauptsÃ¤chlich Inferenzstatistik und
hypothesen-prÃ¼fende Tests sowie Verfahren zur Behandlung von
Fehlerwahrscheinlichkeiten in wissenschaftlichen Studien.</p>
<p>Diese Zusammenfassung basiert auf der Vorlesung Statistik II im
Sommersemester 2024 an der PHB bei Professor Robert Miller, sowie dem
Lehrbuch âStatistik und Forschungsmethodenâ von Eid, Gollwitzer und
Schmitt (5.Auflage).</p>
</div>
<div id="stichprobenkennwerte-verteilung" class="section level1">
<h1>Stichprobenkennwerte-Verteilung</h1>
<div id="beispiel-mittelwert" class="section level2">
<h2>Beispiel: Mittelwert</h2>
<p><span class="math display">\[\overline{x} = \frac{1}{k}
\sum_{i=1}^{k}\overline{x}_i\]</span></p>
<ul>
<li>
<span class="math inline">\(k\)</span>: Anzahl gezogener
Stichproben</li>
<li>
<span class="math inline">\(\overline{x}_{i}\)</span>: Mittelwerte
innerhalb der Stichproben</li>
<li>
<span class="math inline">\(\overline{x}\)</span>:
durchschnittlicher Mittelwerte der Stichproben</li>
</ul>
<p>Erwartungswert des durchschnittlichen Mittelwertes der Stichproben
ist der Mittelwert der Population:</p>
<p><span class="math display">\[E(\overline{x}) = \mu\]</span></p>
</div>
<div id="standardfehler-des-mittelwertes" class="section level2">
<h2>Standardfehler des Mittelwertes</h2>
<p>Die Standardabweichung der Stichprobenkennwert-Verteilung wird
<em>Standardfehler</em> genannt, z.B. Standardfehler des Mittelwertes:
<span class="math inline">\(\sigma_{\overline{x}}\)</span></p>
</div>
<div id="berechnung-des-standardfehlers-des-mittelwertes" class="section level2">
<h2>Berechnung des Standardfehlers des Mittelwertes</h2>
<ul>
<li>wird anhand der Standardabweichung der Population <span class="math inline">\(\sigma\)</span> berechnet</li>
</ul>
<p>Bei <span class="math inline">\(n &lt; 5\%\)</span> der
PopulationsgrÃ¶Ãe N:</p>
<p><span class="math display">\[\sigma_{\overline{x}} =
\frac{\sigma}{\sqrt{n}}\]</span></p>
<p>Bei <span class="math inline">\(n \ge 5\%\)</span> der
PopulationsgrÃ¶Ãe N wird die âFinite Populationâ-Korrektur
eingefÃ¼hrt:</p>
<p><span class="math display">\[\sigma_{\overline{x}} =
\frac{\sigma}{\sqrt{n}} \cdot
\color{red}{\sqrt{\frac{N-n}{N-1}}}\]</span></p>
<p>Je grÃ¶Ãer die einzelnen StichprobengrÃ¶Ãen, umso geringer wird der
Standardfehler:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-1-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
<div id="schÃ¤tzung-des-standardfehlers-des-mittelwertes" class="section level2">
<h2>SchÃ¤tzung des Standardfehlers des Mittelwertes</h2>
<p>Wenn die Varianz der Population <span class="math inline">\(\sigma^2\)</span> nicht bekannt ist, wird er
geschÃ¤tzte Standardfehler <span class="math inline">\(\hat{\sigma}_{\overline{x}}\)</span> aus der
empirischen Varianz <span class="math inline">\(s^{2*}\)</span>
bestimmt:</p>
<p><span class="math display">\[\hat{\sigma}_{\overline{x}} =
\sqrt{\frac{\hat\sigma^2_x}{n}} = \sqrt{\frac{s^{2*}_x}{n - 1}}\]</span>
Wichtig: die empirische Varianz <span class="math inline">\(s^{2*}\)</span> ist <strong>nicht</strong> gleich
der Stichprobenvarianz <span class="math inline">\(s^2\)</span>, siehe
<a href="#punktsch%C3%A4tzung-der-varianz">PunktschÃ¤tzung der Varianz</a>.
Die Stichprobenvarianz <span class="math inline">\(s^2\)</span> enthÃ¤lt
bereits die Bessel-Korrektur <span class="math inline">\(n-1\)</span>
und muss entsprechend nicht nochmals in der Berechnung des geschÃ¤tzten
Standardfehlers korrigiert werden:</p>
<p><span class="math display">\[\hat{\sigma}_{\overline{x}} =
\sqrt{\frac{s^2_x}{n}}\]</span></p>
<p>Die Stichprobenkennwerte-Verteilung folgt dann <strong>nicht
mehr</strong> der Normalverteilung sondern nach Standardisierung einer
Student-t-Verteilung mit <span class="math inline">\(n - 1\)</span>
Freiheitsgraden:</p>
<p><span class="math display">\[\frac{\overline{x} -
\mu}{\hat{\sigma}_{\overline{x}}} \sim Student(df = n -1)\]</span></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-2-1.png" width="768" style="display: block; margin: auto;"></p>
<ul>
<li>
<span class="math inline">\(Normal(\mu = 0, \sigma = 1)\)</span>
(blaue Kurve): Verteilung in der Population</li>
<li>
<span class="math inline">\(Student(df = n-1)\)</span> (grÃ¼ne
Kurve): geschÃ¤tzte Populationsverteilung</li>
</ul>
<p>Mit steigendem <span class="math inline">\(n\)</span> nÃ¤hern sich die
beiden Verteilungen immer weiter an.</p>
</div>
<div id="zentraler-grenzwertsatz" class="section level2">
<h2>Zentraler Grenzwertsatz</h2>
<p>Die Stichprobenkennwerteverteilung der Mittelwerte nÃ¤hert sich mit
zunehmender StichprobengrÃ¶Ãe der Normalverteilung an, unabhÃ¤ngig davon,
wie das Merkmal in der Population verteilt ist.</p>
<p>1 Sample (<span class="math inline">\(n = 1000\)</span>) mit
uniformer Verteilung:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Mittelwerteverteilung von <span class="math inline">\(k =
500\)</span> Samples mit je <span class="math inline">\(n =
1000\)</span>:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Verteilung nÃ¤hert sich sichtbar der Normalverteilung an.</p>
</div>
</div>
<div id="punktschÃ¤tzung-von-populationsparametern" class="section level1">
<h1>PunktschÃ¤tzung von Populationsparametern</h1>
<p>Populationsparameter sind meist unbekannt, daher werden sie auf Basis
der Statistiken (Verteilungskennwerte) einer einzelnen Stichprobe
geschÃ¤tzt. (âPunktschÃ¤tzungâ, weil ein Punktwert und kein Intervall
geschÃ¤tzt wird)</p>
<p><strong>Populationsparameter</strong>: Kennwert einer theoretisch
unendlich groÃen Population</p>
<p><strong>Stichprobenstatistik</strong>: Kennwert einer Verteilung
tatsÃ¤chlicher, empirischer Stichproben</p>
<p><strong>SchÃ¤tzer</strong>: Inferenz von der Stichprobe auf die
Population</p>
<table>
<colgroup>
<col width="30%">
<col width="17%">
<col width="27%">
<col width="24%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th align="right">Population</th>
<th align="right">Stichprobenstatistik</th>
<th align="right">SchÃ¤tzer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Arithmetisches Mittel</td>
<td align="right"><span class="math inline">\(\mu\)</span></td>
<td align="right"><span class="math inline">\(\overline{x}\)</span></td>
<td align="right"><span class="math inline">\(\hat{\mu}\)</span></td>
</tr>
<tr class="even">
<td>Standardabweichung (SD)</td>
<td align="right"><span class="math inline">\(\sigma\)</span></td>
<td align="right"><span class="math inline">\(s\)</span></td>
<td align="right"><span class="math inline">\(\hat{\sigma}\)</span></td>
</tr>
<tr class="odd">
<td>Varianz</td>
<td align="right"><span class="math inline">\(\sigma^{2}\)</span></td>
<td align="right"><span class="math inline">\(s^{2}\)</span></td>
<td align="right"><span class="math inline">\(\hat{\sigma}^{2}\)</span></td>
</tr>
<tr class="even">
<td>Korrelation</td>
<td align="right"><span class="math inline">\(\rho\)</span></td>
<td align="right"><span class="math inline">\(r\)</span></td>
<td align="right"><span class="math inline">\(\hat{\rho}\)</span></td>
</tr>
<tr class="odd">
<td>Regressionsgewicht</td>
<td align="right"><span class="math inline">\(\beta\)</span></td>
<td align="right"><span class="math inline">\(b\)</span></td>
<td align="right"><span class="math inline">\(\hat{\beta}\)</span></td>
</tr>
</tbody>
</table>
<div id="gÃ¼tekriterien-fÃ¼r-parameterschÃ¤tzung" class="section level2">
<h2>GÃ¼tekriterien fÃ¼r ParameterschÃ¤tzung</h2>
<ol style="list-style-type: decimal">
<li>
<p><strong>Erwartungstreue</strong></p>
<p>Erwartungswert des Stichprobenkennwertes entspricht dem
Populationsparameter</p>
</li>
<li>
<p><strong>Konsistenz</strong></p>
<p>Stichprobenkennwert nÃ¤hert sich mit wachsender Stichprobe dem
Populationsparameter</p>
</li>
<li>
<p><strong>Effizienz</strong></p>
<p>Stichprobenkennwert hat den geringsten Standardfehler unter allen
erwartungstreuen SchÃ¤tzern fÃ¼r einen Populationsparameter</p>
</li>
<li>
<p><strong>Suffizienz</strong></p>
<p>Stichprobenkennwert basiert auf alles in den Daten enthaltenen
Informationen</p>
</li>
</ol>
</div>
<div id="punktschÃ¤tzung-des-mittelwertes" class="section level2">
<h2>PunktschÃ¤tzung des Mittelwertes</h2>
<p><span class="math inline">\(k = 100\)</span> Stichproben einer
uniform verteilten Merkmals <span class="math inline">\(x\)</span> mit
jeweils <span class="math inline">\(n = 100\)</span> Messungen.</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Der Mittelwert der Stichprobenverteilung <span class="math inline">\(\hat{\mu}\)</span> (rote Linie) nÃ¤hert sich mit
steigender Stichprobenzahl (<span class="math inline">\(i\)</span>) dem
Populationsmittelwert <span class="math inline">\(\mu\)</span> (blaue
Linie) immer weiter an.</p>
<p>Der Mittelwert der Stichprobenverteilung <span class="math inline">\(\hat{\mu}\)</span> ist also ein erwartungstreuer
und konsistenter SchÃ¤tzer des Populationsmittelwertes <span class="math inline">\(\mu\)</span>.</p>
</div>
<div id="punktschÃ¤tzung-der-varianz" class="section level2">
<h2>PunktschÃ¤tzung der Varianz</h2>
<table>
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<thead>
<tr class="header">
<th align="center">empirische Varianz</th>
<th align="center">Stichprobenvarianz</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(s^{2*} = \frac{1}{n}
\sum_{i = 1}^{n}(x_i - \overline{x})^2\)</span></td>
<td align="center"><span class="math inline">\(s^2 = \frac{1}{n - 1}
\sum_{i = 1}^{n}(x_i - \overline{x})^2\)</span></td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(k = 100\)</span> Stichproben mit je <span class="math inline">\(n = 100\)</span> Messungen eines normalverteilten
Merkmals:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-6-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Die empirische Varianz <span class="math inline">\(s^{2*}\)</span>
(rote Linie) weicht stÃ¤rker vom wahren Kennwert der Population <span class="math inline">\(\sigma^{2}\)</span> (blaue Linie) ab als die
Stichproben-Varianz <span class="math inline">\(s^2\)</span> (grÃ¼ne
Linie).</p>
<p>Die empirische Varianz ist kein erwartungstreuer SchÃ¤tzer der
Populationsvarianz, die Stichproben-Varianz dagegen schon.</p>
<p><strong>Aber:</strong> <span class="math inline">\(\sqrt{s^2}\)</span>
(Stichproben-Standardabweichung <span class="math inline">\(s\)</span>)
ist <strong>KEIN</strong> erwartungstreuer SchÃ¤tzer der
Populations-Standardabweichung <span class="math inline">\(\sigma\)</span>!</p>
</div>
</div>
<div id="intervallschÃ¤tzung-von-populationsparametern" class="section level1">
<h1>IntervallschÃ¤tzung von Populationsparametern</h1>
<p><strong>Konfidenzintervall</strong>: Intervall um den geschÃ¤tzten
Parameter, in dem mit Wahrscheinlichkeit <span class="math inline">\(1-\alpha\)</span> der wahre Populationsparameter
liegt.</p>
<div id="konfidenzintervall-des-mittelwertes" class="section level2">
<h2>Konfidenzintervall des Mittelwertes</h2>
<p>Nach dem <a href="#zentraler-grenzwertsatz">zentralem
Grenzwertsatz</a> folgen die Mittelwerte der Stichproben <span class="math inline">\(\overline{x}\)</span> einer Normalverteilung mit
den Parametern Populationsmittelwert <span class="math inline">\(\mu\)</span> und Standardfehler der
Stichprobenmittelwerte <span class="math inline">\(\sigma_{\overline{x}}\)</span>:</p>
<p><span class="math display">\[\overline{x} \sim Normal(\mu,
\sigma_{\overline{x}})\]</span></p>
<p>Entsprechend folgen die z-standardisierten Mittelwerte der
Stichproben der Standard-Normalverteilung:</p>
<p><span class="math display">\[\frac{\overline{x} -
\mu}{\sigma_{\overline{x}}} \sim Normal(0,1)\]</span></p>
<p>Die FlÃ¤che <span class="math inline">\(1 - \alpha = 0.95\)</span>
liegt im Intervall <span class="math inline">\(z = [-1.96,
1.96]\)</span> der Standard-Normalverteilung.</p>
<p><span class="math inline">\(1-\alpha\)</span> wird auch
Konfidenzkoeffizient genannt.</p>
<p>Beispiel: Stichprobe mit <span class="math inline">\(n = 100\)</span>
Messungen eines normalverteilten Merkmals:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-7-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Der Populationsparameter <span class="math inline">\(\mu\)</span>
liegt im Intervall um den Stichprobenmittelwert <span class="math inline">\(\overline{x}\)</span> (grÃ¼ne Linie), das 95% der
FlÃ¤che der Kennwertverteilung (pink) abdeckt.</p>
<p>Da es ein zweiseitiges Konfidenzintervall ist, wird an beidem Seiten
der Verteilung 2.5% abgeschnitten damit insgesamt <span class="math inline">\(\alpha = 5\%\)</span> gilt.</p>
<div id="konfidenzintervall-pro-stichprobe" class="section level3">
<h3>Konfidenzintervall pro Stichprobe</h3>
<p><span class="math inline">\(k = 100\)</span> Stichproben zu je <span class="math inline">\(n = 1000\)</span> normalverteilten Messungen, mit
zweiseitigem Konfidenzintervall <span class="math inline">\(\alpha =
0.05\)</span>:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-8-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Prozentsatz der Mittelwerte die mit ihrem Konfidenzintervall
<strong>nicht</strong> den Populationsmittelwert abdecken, entspricht in
etwa dem Fehlerniveau <span class="math inline">\(\alpha = 5\%\)</span>.
4 Stichproben von <span class="math inline">\(k = 100\)</span> decken
nicht den Populationsmittelwert in ihrem Konfidenzintervall ab.</p>
<pre class="r"><code>samples %&gt;%
  filter(
    x.mean.lower &gt; mu | x.mean.upper &lt; mu
  ) %&gt;% summarize(p = n() / k)</code></pre>
<pre><code>## # A tibble: 1 Ã 1
##       p
##   &lt;dbl&gt;
## 1  0.04</code></pre>
</div>
</div>
<div id="schÃ¤tzung-des-konfidenzintervalls-des-mittelwertes" class="section level2">
<h2>SchÃ¤tzung des Konfidenzintervalls des Mittelwertes</h2>
<p>Wenn die Standardabweichung <span class="math inline">\(\sigma\)</span> der Population nicht bekannt ist,
der Standardfehler also nicht daraus abgeleitet werden kann, wird das
Konfidenzintervall anhand des <a href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes">geschÃ¤tzten
Standardfehlers</a> berechnet.</p>
<p><span class="math display">\[\overline{x} \pm t(1- \frac{\alpha}{2},
n - 1) \cdot \hat\sigma_{\overline{x}}\]</span></p>
<p>Stichprobe von <span class="math inline">\(n = 10\)</span> Messungen
eines normalverteilten Merkmals:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-10-1.png" width="768" style="display: block; margin: auto;"></p>
<p><em>Es ist gleichgÃ¼ltig ob das Konfidenzintervall um den
Populationsmittelwert oder den Stichprobenmittelwert gelegt wird.
Wichtig ist, dass beide Werte im Intervall liegen. Bei t-Verteilungen
ist es einfacher, das Intervall um den 0-Punkt zu legen und alle Werte
entsprechend zu standardisieren.</em></p>
</div>
<div id="konfidenzintervall-abgÃ¤ngig-von-stichprobengrÃ¶Ãe" class="section level2">
<h2>Konfidenzintervall abgÃ¤ngig von StichprobengrÃ¶Ãe</h2>
<p>Sowohl der Standardfehler <span class="math inline">\(\sigma_{\overline{x}}\)</span> als auch der
geschÃ¤tzte Standardfehler <span class="math inline">\(\hat{\sigma}_{\overline{x}}\)</span> hÃ¤ngen von
der StichprobengrÃ¶Ãe ab und werden kleiner, je grÃ¶Ãer die Stichprobe
ist. Entsprechend verÃ¤ndert sich auch das Konfidenzintervall.</p>
<p>Zwei Stichproben mit <span class="math inline">\(n_1 = 20\)</span>
(grau) und <span class="math inline">\(n_2 = 40\)</span> (pink)
Messungen des gleichen normalverteilten Merkmals, sowie
Populationsmittelwert (blau):</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-11-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Die grÃ¶Ãere Stichprobe <span class="math inline">\(n_2 = 40\)</span>
hat ein deutlich schmaleres Konfidenzintervall.</p>
</div>
</div>
<div id="statistische-hypothesenprÃ¼fung" class="section level1">
<h1>Statistische HypothesenprÃ¼fung</h1>
<div id="signifikanztests" class="section level2">
<h2>Signifikanztests</h2>
<p><strong>Nullhypothese <span class="math inline">\(H_0\)</span>:</strong> Annahme, dass kein
Unterschied zwischen zwei Parametern besteht.</p>
<p><strong>p-Wert:</strong> Wahrscheinlichkeit, dass ein beobachteter
Effekt trotz Annahme der <span class="math inline">\(H_0\)</span>
zufÃ¤llig auftritt.</p>
<ul>
<li>Bedingte Wahrscheinlichkeit <span class="math inline">\(Pr(\overline{x} | H_0)\)</span>, also eine Aussage
Ã¼ber die Wahrscheinlichkeit des beobachteten Stichprobenmittelwertes
<span class="math inline">\(Pr(\overline{x})\)</span> unter der
Voraussetzung dass die Nullhypothese <span class="math inline">\(H_0\)</span> wahr ist, <strong>NICHT</strong> Ã¼ber
die Wahrscheinlichkeit, dass die Nullhypothese <span class="math inline">\(H_0\)</span> an sich zutrifft.</li>
</ul>
<p><strong>âSignifikantâ</strong> ist ein Effekt, wenn der
<strong>p-Wert</strong> unter einem zuvor festgelegten
Signifikanz-Niveau <span class="math inline">\(\alpha\)</span> liegt,
oft 5%.</p>
<div id="einseitiger-signifikanztest" class="section level3">
<h3>Einseitiger Signifikanztest</h3>
<p>Population mit <span class="math inline">\(\mu = 100\)</span> und
<span class="math inline">\(\sigma = 55\)</span>, Stichprobe mit <span class="math inline">\(n = 200\)</span>.</p>
<p>Liegt eine Stichprobe mit <span class="math inline">\(\overline{x} =
107\)</span> (blaue Linie) in den oberen 5% der
Wahrscheinlichkeitsmasse? D.h. ist die Wahrscheinlichkeit fÃ¼r solch eine
Stichprobe unter dem Signifikanz-Niveau?</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-12-1.png" width="768" style="display: block; margin: auto;"></p>
<p><strong>Die Parameter der Dichtefunktion sind hier
Populationsmittelwert und Standardfehler <span class="math inline">\(\sigma_{\overline{x}}\)</span>, errechnet aus der
Standardabweichung <span class="math inline">\(\sigma\)</span> der
Population und der StichprobengrÃ¶Ãe <span class="math inline">\(n\)</span>. (siehe <a href="#berechnung-des-standardfehlers-des-mittelwertes">Berechnung des
Standardfehlers</a>)</strong></p>
</div>
<div id="zweiseitiger-signifikanztest" class="section level3">
<h3>Zweiseitiger Signifikanztest</h3>
<p>Population mit <span class="math inline">\(\mu = 100\)</span> und
<span class="math inline">\(\sigma = 55\)</span>, Stichprobe mit <span class="math inline">\(n = 200\)</span>.</p>
<p>Beim zweiseitigen Signifikanztest wird das Signifikanz-Niveau auf
beide Seiten aufgeteilt, da es die Wahrscheinlichkeit betrifft mit der
eine Stichprobe in einem der beiden Extrembereiche liegt, egal in
welchem.</p>
<p>Liegt eine Stichprobe mit <span class="math inline">\(\overline{x} =
107\)</span> (blaue Linie) auÃerhalb der zentralen 95% der
Wahrscheinlichkeitsmasse?</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-13-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
<div id="standardisierte-prÃ¼fgrÃ¶Ãen" class="section level3">
<h3>Standardisierte PrÃ¼fgrÃ¶Ãen</h3>
<p>Oft werden Daten zur HypothesenprÃ¼fung standardisiert:</p>
<p><span class="math display">\[z_{\overline{x}} = \frac{\overline{x} -
\mu}{\sigma_{\overline{x}}}\]</span> Die Verteilung der
Stichprobenkennwerte in der Population ist dann auf <span class="math inline">\(\mu = 0\)</span> zentriert und hat einen
Standardfehler <span class="math inline">\(\sigma_{\overline{x}} =
1.0\)</span>.</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-14-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
<div id="signifikanztest-mit-empirischen-daten" class="section level3">
<h3>Signifikanztest mit empirischen Daten</h3>
<p><strong>One-Sample-T-Test:</strong> gibt fÃ¼r gegebene Samples und
Populationsmittelwert den p-Wert aus. Verglichen wird eine Stichprobe
(daher âone sampleâ) mit der Gesamtpopulation.</p>
<p>Da die Standardabweichung der Population nicht bekannt ist, wird der
Standardfehler mittels der T-Verteilung geschÃ¤tzt. (siehe <a href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes">SchÃ¤tzung
des Standardfehlers</a>)</p>
<p>Samples:</p>
<pre><code>## # A tibble: 10 Ã 1
##        x
##    &lt;dbl&gt;
##  1 168. 
##  2  88.7
##  3 171. 
##  4 169. 
##  5 126. 
##  6  28.0
##  7  58.6
##  8  90.3
##  9 105. 
## 10 225.</code></pre>
<p>Einseitiger One-Sample-T-Test:</p>
<pre class="r"><code>mu &lt;- 100
alpha &lt;- 0.05

# alternative = "greater" -  &gt; Einseitiger Test in positiver Richtung
# alternative = "less"      -&gt; Einseitiger Test in negativer Richtung
# alternative = "two.sided" -&gt; Zweiseitiger Test
t.test(samples, mu = mu, alternative = "greater", conf.level = 1 - alpha)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  samples
## t = 1.204, df = 9, p-value = 0.1296
## alternative hypothesis: true mean is greater than 100
## 95 percent confidence interval:
##  88.01066      Inf
## sample estimates:
## mean of x 
##  122.9462</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-17-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
</div>
<div id="hypothesentests" class="section level2">
<h2>Hypothesentests</h2>
<p><strong>Nullhypothese <span class="math inline">\(H_0\)</span>:</strong> Annahme, dass ein
bestimmter bedeutsamer Effekt nicht existiert.</p>
<p><strong>Alternativhypothese <span class="math inline">\(H_1\)</span>:</strong> Annahme, dass ein
bestimmter bedeutsamer Effekt existiert</p>
<p><strong>Die Nullhypothese ist niemals wirklich wahr. Mit
ausreichender StichprobengrÃ¶Ãe lÃ¤sst sich ein beliebig kleiner Effekt
zeigen.</strong></p>
<p><strong>Irrtumswahrscheinlichkeit <span class="math inline">\(\alpha\)</span>:</strong> Wahrscheinlichkeit, dass
ein Test in einer Stichprobe einen bedeutsamen Effekt zufÃ¤llig anzeigt,
der eigentlich in der Population nicht existiert, also dass die
Nullhypothese <span class="math inline">\(H_0\)</span> fÃ¤lschlicherweise
abgelehnt wird. (<span class="math inline">\(\alpha\)</span>-Fehler,
False-Positive)</p>
<p><strong>Irrtumswahrscheinlichkeit <span class="math inline">\(\beta\)</span>:</strong> Wahrscheinlichkeit, dass
ein Effekt, der in der Population vorhanden ist, zufÃ¤llig in der
getesteten Stichprobe nicht auftaucht, also dass die Nullhypothese <span class="math inline">\(H_0\)</span> fÃ¤lschlicherweise angenommen wird.
(<span class="math inline">\(\beta\)</span>-Fehler, False-Negative)</p>
<p><strong>TeststÃ¤rke/Power:</strong> <span class="math inline">\(1 -
\beta\)</span>, je hÃ¶her die Power, umso unwahrscheinlicher werden <span class="math inline">\(\beta\)</span>-Fehler</p>
<p><strong>parametrische vs.Â nicht-parametrische Tests:</strong>
parametrische Tests setzen voraus, dass Merkmale in der Population
normalverteilt sind (z.B. Gauss-Test, T-Test). Nicht-parametrische Tests
machen diese Annahme nicht (Gegenstand im M.Sc.-Studium).</p>
<p>Ein Test kann zwar einen p-Wert unter <span class="math inline">\(\alpha\)</span>-Niveau (0.05) liefern, aber
trotzdem einen sehr groÃer <span class="math inline">\(\beta\)</span>-Fehler haben:</p>
<ul>
<li>grÃ¼ne Linie: <span class="math inline">\(\mu\)</span>
</li>
<li>blaue Linie: <span class="math inline">\(\overline{x}\)</span>
</li>
<li>rosa FlÃ¤che: <span class="math inline">\(\alpha\)</span>
</li>
<li>blaue FlÃ¤che: <span class="math inline">\(\beta\)</span>
</li>
<li>gestrichelte Linie: kritischer Wert</li>
</ul>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-18-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Mit niedrigerem <span class="math inline">\(\alpha\)</span>-Niveau
(0.01) wird der <span class="math inline">\(\beta\)</span>-Fehler sogar
noch grÃ¶Ãer.</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-19-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Um den <span class="math inline">\(\beta\)</span>-Fehler zu
reduzieren, mÃ¼sste ein stÃ¤rkerer Effekt (<span class="math inline">\(\overline{x} - \mu\)</span>) vorhanden sein:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-20-1.png" width="768" style="display: block; margin: auto;"></p>
<div id="standardisierter-effekt-cohens-delta" class="section level3">
<h3>Standardisierter Effekt: Cohenâs <span class="math inline">\(\delta\)</span>
</h3>
<p><em>(Manchmal auch: âCohenâs dâ)</em></p>
<p><span class="math display">\[\delta = \frac{\overline{x} -
\mu}{\sigma}\]</span></p>
<ul>
<li>
<span class="math inline">\(\overline{x}\)</span>:
Stichproben-Mittelwert</li>
<li>
<span class="math inline">\(\mu\)</span>: Populationsmittelwert</li>
<li>
<span class="math inline">\(\sigma\)</span>: Standardabweichung der
Population</li>
</ul>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-21-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
<div id="konfidenzintervalle-fÃ¼r-cohens-delta" class="section level3">
<h3>Konfidenzintervalle fÃ¼r Cohenâs <span class="math inline">\(\delta\)</span>
</h3>
<p>Die Stichprobenkennwerte-Verteilung von <span class="math inline">\(\overline{x}\)</span> ist normalverteilt (siehe <a href="#zentraler-grenzwertsatz">Zentraler Grenzwertsatz</a>)</p>
<p>Der Erwartungswert von <span class="math inline">\(\delta\)</span>
entspricht der standardisierten Differenz zwischen Stichprobenmittelwert
und Populationsmittelwert.</p>
<p><span class="math display">\[E_{\delta} = \frac{\overline{x} -
\mu}{\sigma}\]</span></p>
<p>Die Streuung <span class="math inline">\(\sigma_{\delta}\)</span> ist
der Standardfehler wobei dieser hier vereinfacht <span class="math inline">\(\frac{1}{\sqrt{n}}\)</span> ist weil
Standardisierung bereits erfolgt ist (die Standardabweichung von
standardisierten GrÃ¶Ãen ist 1):</p>
<p><span class="math display">\[\sigma_{\delta} = \sigma_{\overline{x}}
= \frac{1}{\sqrt{n}}\]</span></p>
<p><span class="math display">\[\delta \sim  Normal(E_{\delta} =
\frac{\overline{x} - \mu}{\sigma}, \sigma_{\delta} =
\frac{1}{\sqrt{n}})\]</span></p>
<p>Damit lassen sich die Konfidenzintervalle fÃ¼r ein gegebenes <span class="math inline">\(\alpha\)</span>-Niveau berechnen:</p>
<p><span class="math display">\[\delta \pm z(1-\frac{\alpha}{2}) \cdot
\sigma_{\delta} = \frac{\overline{x} - \mu}{\sigma}
\pm  z(1-\frac{\alpha}{2}) \cdot \frac{1}{\sqrt{n}}\]</span></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-22-1.png" width="768" style="display: block; margin: auto;">
Konventionen fÃ¼r Effektinterpretationen fÃ¼r <span class="math inline">\(\delta\)</span> nach Cohen:</p>
<ul>
<li>
<span class="math inline">\(|d|  \approx 0.14\)</span>: âkleinerâ
Effekt</li>
<li>
<span class="math inline">\(|d|  \approx 0.35\)</span>: âmittlererâ
Effekt</li>
<li>
<span class="math inline">\(|d|  \approx 0.57\)</span>: âgroÃerâ
Effekt</li>
</ul>
</div>
<div id="einstichproben-gauss-test" class="section level3">
<h3>Einstichproben-Gauss-Test</h3>
<p>Voraussetzungen:</p>
<ul>
<li>Merkmal ist in der Population normalverteilt
<ul>
<li>
<p>alternativ: bei nicht-normalverteiltem Merkmal <span class="math inline">\(x\)</span> ist der Stichproben Mittelwert ab ca.
<span class="math inline">\(n = 30\)</span> nahezu normalverteilt.
(Siehe <a href="#zentraler-grenzwertsatz">zentraler
Grenzwertsatz</a>)</p>
<p>Der z-Test ist dann allerdings nicht mehr exakt.</p>
</li>
</ul>
</li>
<li>Standardabweichung <span class="math inline">\(\sigma\)</span> in
der Population ist bekannt</li>
</ul>
<p>Gauss-Test, auch âz-Testâ genannt, ist geeignet, wenn die
Standardabweichung <span class="math inline">\(\sigma\)</span> der
Population bekannt ist, und damit der Standardfehler <span class="math inline">\(\sigma_{\overline{x}}\)</span> berechnet werden
kann. (Siehe <a href="#berechnung-des-standardfehlers-des-mittelwertes">Berechnung des
Standardfehlers des Mittelwertes</a>)</p>
<p>PrÃ¼fgrÃ¶Ãe: <span class="math inline">\(z_{\overline{x} -
\mu}\)</span>, z-standardisierte Differenz von Stichprobenmittelwert und
Populationsmittelwert</p>
<p><span class="math display">\[z_{\overline{x} - \mu} =
\frac{\overline{x} - \mu}{\sigma_{\overline{x}}}\]</span></p>
<p>Kritischer Wert: Wert fÃ¼r <span class="math inline">\(\overline{x}\)</span> der Ã¼ber- bzw.
unterschritten werden muss damit <span class="math inline">\(p \le
0.05\)</span> eingehalten wird.</p>
<p><span class="math inline">\(Q(p)\)</span> ist hier die
Quantilsfunktion der Normalverteilung, die bestimmt welcher Wert eine
Wahrscheinlichkeit von <span class="math inline">\(p\)</span> oder
weniger hat.</p>
<p>Die Nullhypothese <span class="math inline">\(H_0\)</span> wird
abgelehnt wenn:</p>
<ul>
<li>
<p>bei einseitigem Test in positiver Richtung</p>
<p><span class="math inline">\(z_{\overline{x} - \mu} \ge Q(1 -
\alpha)\)</span></p>
</li>
<li>
<p>bei einseitigem Test in negativer Richtung</p>
<p><span class="math inline">\(z_{\overline{x} - \mu} \le
Q(\alpha)\)</span></p>
</li>
<li>
<p>bei zweiseitigem Test</p>
<p><span class="math inline">\(z_{\overline{x} - \mu} \le
Q(\frac{\alpha}{2}) \cup z_{\overline{x} - \mu} \ge Q(1 -
\frac{\alpha}{2})\)</span></p>
<p>(<span class="math inline">\(\cup\)</span>: âoderâ)</p>
</li>
</ul>
<p>Siehe auch: <a href="#signifikanztests">Signifikanztests</a></p>
<div id="einstichproben-gauss-test-in-r" class="section level4">
<h4>Einstichproben-Gauss-Test in R</h4>
<p>Samples mit <span class="math inline">\(\mu = 0.5\)</span>, <span class="math inline">\(\sigma = 1.0\)</span>, und <span class="math inline">\(n = 20\)</span></p>
<pre><code>##  [1]  1.76295428  0.17376664  1.82979926  1.77242932  0.91464143 -1.03995004
##  [7] -0.42856703  0.20527955  0.49423283  2.90465339  1.26359346 -0.29900925
## [13] -0.64765701  0.21053843  0.20078488  0.08848917  0.75222345 -0.39192113
## [19]  0.93568330 -0.73753842</code></pre>
<pre class="r"><code># Paket: BSDA

z.test(samples, mu = 0, sigma.x = 1, conf.level = 0.95, alternative = "greater")</code></pre>
<pre><code>## 
##  One-sample z-Test
## 
## data:  samples
## z = 2.2281, p-value = 0.01294
## alternative hypothesis: true mean is greater than 0
## 95 percent confidence interval:
##  0.1304209        NA
## sample estimates:
## mean of x 
## 0.4982213</code></pre>
</div>
</div>
<div id="einstichproben-t-test" class="section level3">
<h3>Einstichproben T-Test</h3>
<p>Voraussetzungen:</p>
<ul>
<li>Merkmal ist in der Population normalverteilt
<ul>
<li>alternativ: bei nicht-normalverteiltem Merkmal <span class="math inline">\(x\)</span> ist der Stichproben Mittelwert ab ca.
<span class="math inline">\(n = 30\)</span> nahezu normalverteilt.
(Siehe <a href="#zentraler-grenzwertsatz">zentraler
Grenzwertsatz</a>)</li>
</ul>
</li>
<li>StichprobengrÃ¶Ãe ist bekannt (zur SchÃ¤tzung des
Standardfehlers)</li>
</ul>
<p><em>Der T-Test ist wenn mÃ¶glich dem Gauss-Test vorzuziehen, da er
auch ohne bekannte Standardabweichung der Population exakter
ist.</em></p>
<p>SchÃ¤tzung des Standardfehlers <span class="math inline">\(\hat{\sigma}_{\overline{x}}\)</span></p>
<ul>
<li>
<span class="math inline">\(\hat{\sigma}^2_{x}\)</span>: geschÃ¤tzte
Populations-Varianz</li>
<li>
<span class="math inline">\(s^2_{x}\)</span>:
Stichproben-Varianz</li>
<li>
<span class="math inline">\(s^{2*}\)</span>: empirische Varianz</li>
</ul>
<p><span class="math display">\[\hat{\sigma}_{\overline{x}} =
\sqrt{\frac{\hat{\sigma}^2_{x}}{n}} = \sqrt{\frac{s^2_{x}}{n}} =
\sqrt{\frac{s^{2*}_{x}}{n-1}}\]</span></p>
<p>PrÃ¼fgrÃ¶Ãe: <span class="math inline">\(t_{\overline{x} -
\mu}\)</span></p>
<p><span class="math display">\[t_{\overline{x} - \mu} =
\frac{\overline{x} - \mu}{\hat{\sigma}_{\overline{x}}}\]</span></p>
<p>Kritischer Wert: Analog zum <a href="#einstichproben-gauss-test">Einstichproben Gauss-Test</a></p>
<p><span class="math inline">\(Q(p)\)</span> ist beim t-Test die
Quantilsfunktion der Student-T-Verteilung mit <span class="math inline">\(n-1\)</span> Freiheitsgraden, denn die Verteilung
von <span class="math inline">\(t_{\overline{x} - \mu}\)</span> folgt
dieser Student-T-Verteilung:</p>
<p><span class="math display">\[t_{\overline{x} - \mu} \sim Student(df =
n -1 )\]</span></p>
<p>Beispiel: Zwei T-Tests mit entsprechenden Student-T-Verteilungen fÃ¼r
<span class="math inline">\(n=10\)</span> und <span class="math inline">\(n=100\)</span>.</p>
<p>Die PrÃ¼fgrÃ¶Ãe fÃ¤llt bei <span class="math inline">\(n=10\)</span>
nicht Ã¼ber den kritischen Wert fÃ¼r <span class="math inline">\(p \le
\alpha\)</span>, bei <span class="math inline">\(n=100\)</span> aber
schon, da der geschÃ¤tzte Standardfehler geringer wird, d.h. der Test
wird genauer.</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-26-1.png" width="768" style="display: block; margin: auto;"></p>
<div id="einstichproben-t-test-in-r" class="section level4">
<h4>Einstichproben T-Test in R</h4>
<p>Samples mit <span class="math inline">\(\mu = 0.5\)</span>, <span class="math inline">\(\sigma = 1.0\)</span>, und <span class="math inline">\(n = 20\)</span></p>
<pre><code>##  [1] 0.8525909 0.5347533 0.8659599 0.8544859 0.6829283 0.2920100 0.4142866
##  [8] 0.5410559 0.5988466 1.0809307 0.7527187 0.4401982 0.3704686 0.5421077
## [15] 0.5401570 0.5176978 0.6504447 0.4216158 0.6871367 0.3524923</code></pre>
<pre class="r"><code>t.test(samples, alternative = "greater", mu = 0.5, conf.level = 0.95)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  samples
## t = 2.1812, df = 19, p-value = 0.02097
## alternative hypothesis: true mean is greater than 0.5
## 95 percent confidence interval:
##  0.5206532       Inf
## sample estimates:
## mean of x 
## 0.5996443</code></pre>
</div>
</div>
<div id="einstichproben-t-test-fÃ¼r-abhÃ¤ngige-beobachtungen" class="section level3">
<h3>Einstichproben T-Test fÃ¼r abhÃ¤ngige Beobachtungen</h3>
<p>T-Test fÃ¼r abhÃ¤ngige Messungen in einer Stichprobe. z.B. wenn die
gleiche Stichprobe von Versuchspersonen vor und nach einem Treatment die
gleiche Messung durchlÃ¤uft.</p>
<p>StichprobengrÃ¶Ãe ist hier die Anzahl der Messwertpaare, nicht die
Anzahl aller Messungen.</p>
<p>Es wird eine neue Variable <span class="math inline">\(\overline{x}_D\)</span> eingefÃ¼hrt, der Mittelwert
der Differenz der beiden Messungen von jeweils der gleichen
Versuchsperson.</p>
<ul>
<li>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\overline{x}_D = 0\)</span>
</li>
<li>
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(\overline{x}_D \neq 0\)</span> (zweiseitiger
Test)</li>
</ul>
<p><em>Es ist egal ob zuerst die Differenzen der Messungen fÃ¼r jede
Versuchsperson gebildet und dann gemittelt werden, oder ob die Differenz
der Mittelwerte beider Messungen gebildet wird. Das Ergebnis ist das
gleiche</em></p>
<p>Der Rest der Tests verlÃ¤uft wie beim Einstichproben T-Test.</p>
<div id="einstichproben-t-test-fÃ¼r-abhÃ¤ngige-beobachtungen-t-test-in-r" class="section level4">
<h4>Einstichproben T-Test fÃ¼r abhÃ¤ngige Beobachtungen T-Test in R</h4>
<p><span class="math inline">\(n=20\)</span> Samples,</p>
<pre class="r"><code>samples</code></pre>
<pre><code>## # A tibble: 10 Ã 2
##       m1    m2
##    &lt;dbl&gt; &lt;dbl&gt;
##  1 163.  164. 
##  2  83.7  81.6
##  3 166.  164. 
##  4 164.  163. 
##  5 121.  120. 
##  6  23.0  21.7
##  7  53.6  53.6
##  8  85.3  83.0
##  9  99.7 100. 
## 10 220.  217.</code></pre>
<pre class="r"><code>xd = samples$m2 - samples$m1
t.test(xd, mu = 0, alternative = "two.sided", conf.level = 0.95)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  xd
## t = -2.853, df = 9, p-value = 0.019
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -2.1962337 -0.2536916
## sample estimates:
## mean of x 
## -1.224963</code></pre>
<p>Alternativ kann die Funktion <code>t.test</code> auch die paarweisen
Differenzen automatisch bestimmen:</p>
<pre class="r"><code>t.test(x = samples$m2, y = samples$m1,
       paired = TRUE,
       mu = 0,
       alternative = "two.sided",
       conf.level = 0.95)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  samples$m2 and samples$m1
## t = -2.853, df = 9, p-value = 0.019
## alternative hypothesis: true mean difference is not equal to 0
## 95 percent confidence interval:
##  -2.1962337 -0.2536916
## sample estimates:
## mean difference 
##       -1.224963</code></pre>
</div>
</div>
<div id="einstichproben-binomialtest" class="section level3">
<h3>Einstichproben Binomialtest</h3>
<p>Test fÃ¼r ein dichotomes Merkmal <span class="math inline">\(x\)</span> (Merkmal mit zwei mÃ¶glichen
AusprÃ¤gungen): <span class="math inline">\(x \in \{0,1\}\)</span></p>
<p><span class="math inline">\(\pi_0\)</span>: Wahrscheinlichkeit in der
Population fÃ¼r <span class="math inline">\(x = 1\)</span></p>
<p><span class="math inline">\(\pi\)</span>: Wahrscheinlichkeit in der
Stichprobe fÃ¼r <span class="math inline">\(x = 1\)</span></p>
<p>Hypothesenpaare:</p>
<ul>
<li>ungerichtet
<ul>
<li>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\pi_0 = \pi\)</span>
</li>
<li>
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(\pi_0 \ne \pi\)</span>
</li>
</ul>
</li>
<li>gerichtet, positiv
<ul>
<li>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\pi_0 \ge \pi\)</span>
</li>
<li>
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(\pi_0 \lt \pi\)</span>
</li>
</ul>
</li>
<li>gerichtet, negativ
<ul>
<li>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\pi_0 \le \pi\)</span>
</li>
<li>
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(\pi_0 \gt \pi\)</span>
</li>
</ul>
</li>
</ul>
<p>Aus <span class="math inline">\(\pi_0\)</span> und <span class="math inline">\(\pi\)</span> ergeben sich zwei
Binomialverteilungen Ã¼ber <span class="math inline">\(n\)</span>
Ziehungen, mit <span class="math inline">\(\alpha\)</span>-Fehler analog
zu anderen Tests.</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-34-1.png" width="768" style="display: block; margin: auto;"></p>
<div id="binomialtest-in-r" class="section level4">
<h4>Binomialtest in R</h4>
<pre class="r"><code>binom.test(39, 60, p = 0.5, conf.level = 0.95, alternative = "greater")</code></pre>
<pre><code>## 
##  Exact binomial test
## 
## data:  39 and 60
## number of successes = 39, number of trials = 60, p-value = 0.01367
## alternative hypothesis: true probability of success is greater than 0.5
## 95 percent confidence interval:
##  0.5363726 1.0000000
## sample estimates:
## probability of success 
##                   0.65</code></pre>
</div>
</div>
<div id="zweistichproben-t-test" class="section level3">
<h3>Zweistichproben T-Test</h3>
<p>Wird angewendet beim Vergleich von 2 unabhÃ¤ngigen Stichproben (z.B.
Studienarme).</p>
<p>Voraussetzungen:</p>
<ul>
<li>normalverteiltes Merkmal</li>
<li>Messwerte in beiden Stichproben unabhÃ¤ngig</li>
<li>VarianzhomogenitÃ¤t zwischen den Stichproben</li>
</ul>
<p>PrÃ¼fgrÃ¶Ãe:</p>
<p><span class="math display">\[T = t_{\overline{x}_1} -
t_{\overline{x}_2} = \frac{\overline{x}_1 - \overline{x}_2}
{\hat{\sigma}_{\overline{x}_1 - \overline{x}_2}}\]</span></p>
<p><span class="math inline">\(T\)</span> folgt der Student-T-Verteilung
mit <span class="math inline">\(df = n_1 + n_2 - 2\)</span>$
Freiheitsgraden</p>
<p><span class="math display">\[T \sim Student(0, 1, n_1 + n_2 -
2)\]</span></p>
<p>Standardfehler hÃ¤ngt hier von den GrÃ¶Ãen beider Stichproben ab, da
diese nicht unbedingt gleich groÃ sind.</p>
<p><span class="math display">\[\hat{\sigma}_{\overline{x}_1 -
\overline{x}_2} = \sqrt{\frac{\hat{\sigma}^2_{inn}} {n_1} +
\frac{\hat{\sigma}^2_{inn}}{n_2}}\]</span></p>
<p>Geteilte/Gepoolte Innerhalb-Varianz <span class="math inline">\(\hat{\sigma}^2_{inn}\)</span> wird aus den
geschÃ¤tzten Varianzen der Stichproben (<span class="math inline">\(\hat{\sigma}^2_1\)</span>, <span class="math inline">\(\hat{\sigma}^2_2\)</span>) berechnet (siehe auch
<a href="#punktsch%C3%A4tzung-der-varianz">PunktschÃ¤tzung der
Varianz</a>):</p>
<p><span class="math display">\[\hat{\sigma}^2_{inn} =
\frac{\hat{\sigma}^2_1 \cdot (n_1 -1) + \hat{\sigma}^2_2 \cdot (n_2 -1)}
{(n_1 - 1) + (n_2 - 1)}\]</span></p>
<p>Beispiel: Stichproben aus zwei Studienarmen mit jeweils <span class="math inline">\(n = 100\)</span></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-36-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Verteilung der PrÃ¼fgrÃ¶Ãe <span class="math inline">\(T\)</span>:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-37-1.png" width="768" style="display: block; margin: auto;"></p>
<div id="zweistichproben-t-test-in-r" class="section level4">
<h4>Zweistichproben T-Test in R</h4>
<pre class="r"><code>t.test(samples2$x, y = samples1$x, alternative = "greater", conf.level = 0.95) -&gt; t.result
t.result</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  samples2$x and samples1$x
## t = 2.5715, df = 193.31, p-value = 0.005438
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  6.070815      Inf
## sample estimates:
## mean of x mean of y 
##  118.1253  101.1334</code></pre>
<p>Bestimmung der Konfidenzintervalle des Effekts (Cohenâs <span class="math inline">\(d\)</span>):</p>
<pre class="r"><code># Paket: MBESS

ci.smd(t.result$statistic,
       n.1 = length(samples1),
       n.2 = length(samples2),
       conf.level = 0.95)</code></pre>
<pre><code>## $Lower.Conf.Limit.smd
## [1] -0.5441647
## 
## $smd
##        t 
## 2.571521 
## 
## $Upper.Conf.Limit.smd
## [1] 5.534741</code></pre>
</div>
</div>
</div>
<div id="power-und-stichprobenplanung" class="section level2">
<h2>Power und Stichprobenplanung</h2>
<p><strong>Power: <span class="math inline">\(1-\beta\)</span></strong></p>
<p><span class="math inline">\(\beta\)</span> und Power hÃ¤ngen vom
Standardfehler und damit von der StichprobengrÃ¶Ãe ab.</p>
<p>Beispiel <span class="math inline">\(n = 20\)</span>, <span class="math inline">\(\beta\)</span>-Fehler ist gering:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-40-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Bei <span class="math inline">\(n = 7\)</span> ist der <span class="math inline">\(\beta\)</span>-Fehler deutlich hÃ¶her und die Power
daher geringer, wÃ¤hrend <span class="math inline">\(\alpha\)</span>-Niveau weiterhin unterschritten
wird:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-41-1.png" width="768" style="display: block; margin: auto;"></p>
<p><span class="math inline">\(\beta\)</span> ist ebenfalls vom Effekt
abhÃ¤ngig. Zur Planung der StichprobengrÃ¶Ãe mÃ¼ssen <span class="math inline">\(\alpha\)</span>-Niveau und der minimale als
signifikant akzeptierte Effekt bekannt sein.</p>
<div id="stichprobenplanung-in-r" class="section level3">
<h3>Stichprobenplanung in R</h3>
<pre class="r"><code># Paket: pwr

# post-hoc Power-Analyse fÃ¼r einseitigen Gauss-Test/Z-Test
# - Stichproben-Signifikanztest
# - Normalverteilte Merkmale
# - bekannter Standardabweichung
pwr.norm.test(0.5, n = 10, sig.level = 0.05, alternative = "greater")</code></pre>
<pre><code>## 
##      Mean power calculation for normal distribution with known variance 
## 
##               d = 0.5
##               n = 10
##       sig.level = 0.05
##           power = 0.4745987
##     alternative = greater</code></pre>
<pre class="r"><code># bei Test in negativer Richtung: alternative = "lesser"
# bei zweiseitigem Test: alternative = "two.sided"</code></pre>
<pre class="r"><code># a priori Power Analyse fÃ¼r Zweistichproben-T-Test
# n ist noch nicht bekannt, aber alpha-Niveau, Effekt und Power sind gegeben
pwr.t.test(d = 0.5, sig.level = 0.05, power = 0.9, type = "two.sample")</code></pre>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 85.03128
##               d = 0.5
##       sig.level = 0.05
##           power = 0.9
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>Plot von Power in AbhÃ¤ngigkeit von StichprobengrÃ¶Ãe:</p>
<p>Effekt <span class="math inline">\(d = 0.7\)</span>, <span class="math inline">\(\alpha_1 = 5\%\)</span> (blau), <span class="math inline">\(\alpha_2 = 1\%\)</span> (pink)</p>
<pre class="r"><code># Funktion die einen einseitigen Z-Test ausfÃ¼hrt
# und den Power-Wert aus dem Ergebnis extrahiert
power &lt;- function(n, d = 1, alpha = 0.05) {
  test &lt;- pwr.norm.test(d, n = n, sig.level = alpha, alternative = "greater")
  
  return(test[[4]])
}

# Plot der Funktion Ã¼ber StichprobengrÃ¶Ãen 1-75
# Effekt d = 0.7
# alpha = 0.05 und alpha = 0.01
tibble(
  n = 1:50,
  power5 = power(n, d = 0.7, alpha = 0.05),
  power1 = power(n, d = 0.7, alpha = 0.01),
  ) %&gt;% ggplot(aes(x = n, y = power)) +
  geom_col(aes(y = power5), fill = colors[2]) +
  geom_col(aes(y = power1), fill = colors[1]) +
  annotate("text", label = "alpha[1] == 0.05", parse = TRUE, x = 2, y = 0.95, color = colors[2]) +
  annotate("text", label = "alpha[2] == 0.01", parse = TRUE, x = 2, y = 0.90, color = colors[1]) +
  xlab("StichprobengrÃ¶Ãe") +
  ylab("Power") +
  theme_custom</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-44-1.png" width="768" style="display: block; margin: auto;"></p>
<p>FÃ¼r ein strengeres <span class="math inline">\(\alpha_2 =
1\%\)</span> ist gegenÃ¼ber <span class="math inline">\(\alpha_1 =
5\%\)</span> eine grÃ¶Ãere Stichrobe nÃ¶tig, um die gleiche Power zu
erreichen.</p>
</div>
</div>
<div id="tests-fÃ¼r-kategoriale-merkmale" class="section level2">
<h2>Tests fÃ¼r Kategoriale Merkmale</h2>
<p>Kategoriale Merkmale:</p>
<ul>
<li>nominalskalierte Merkmale</li>
<li>ordinalskalierte Merkmale
<ul>
<li>auch geschichtete metrische Merkmale</li>
</ul>
</li>
</ul>
<div id="chi2-statistik" class="section level3">
<h3>
<span class="math inline">\(\chi^2\)</span>-Statistik</h3>
<p><span class="math display">\[\chi^2 =
\sum_{i=1}^r{\sum_{j=1}^c{\frac{(f_{ij} -
e_{ij})^2}{e_{ij}}}}\]</span></p>
<ul>
<li><p><span class="math inline">\(r\)</span>: Anzahl Zeilen</p></li>
<li><p><span class="math inline">\(c\)</span>: Anzahl Spalten</p></li>
<li><p><span class="math inline">\(f_{ij}\)</span>: beobachtete
HÃ¤ufigkeiten</p></li>
<li>
<p><span class="math inline">\(e_{ij}\)</span>: erwartete
HÃ¤ufigkeiten</p>
<p><span class="math inline">\(e_{ij} = \frac{Zeilensumme \cdot
Spaltensumme}{Stichprobenumfang}\)</span></p>
</li>
</ul>
</div>
<div id="cramers-v" class="section level3">
<h3>Cramerâs <span class="math inline">\(V\)</span>
</h3>
<p><span class="math display">\[V = \sqrt{\frac{\chi^2}{n \cdot (m -
1)}}\]</span></p>
<ul>
<li><p><span class="math inline">\(n\)</span>:
Stichprobenumfang</p></li>
<li>
<p><span class="math inline">\(m\)</span>: MerkmalsausprÃ¤gungen</p>
<p><span class="math inline">\(m = min(r, c)\)</span></p>
</li>
</ul>
</div>
<div id="chi2-test" class="section level3">
<h3>
<span class="math inline">\(\chi^2\)</span>-Test</h3>
<ul>
<li>
<span class="math inline">\(V\)</span>: EffektstÃ¤rke</li>
<li>
<span class="math inline">\(\chi^2\)</span>: PrÃ¼fgrÃ¶Ãe</li>
</ul>
<p>Nullhypothese <span class="math inline">\(H_0\)</span>: <span class="math inline">\(V = 0\)</span>, es existiert kein Effekt</p>
<p>Die PrÃ¼fgrÃ¶Ãe folgt einer <span class="math inline">\(\chi^2\)</span>-Verteilung mit Freiheitsgraden
<span class="math inline">\(df = (r-1) \cdot (c-1)\)</span>.</p>
<div id="chi2-test-in-r" class="section level4">
<h4>
<span class="math inline">\(\chi^2\)</span>-Test in R</h4>
<p>Beispieldaten:</p>
<pre><code>##      A   B   C
## I  125 108 125
## II 127  93 230</code></pre>
<pre class="r"><code>chisq.test(samples)</code></pre>
<pre><code>## 
##  Pearson's Chi-squared test
## 
## data:  samples
## X-squared = 22.002, df = 2, p-value = 1.669e-05</code></pre>
</div>
<div id="kontinuitÃ¤tskorrektur" class="section level4">
<h4>KontinuitÃ¤tskorrektur</h4>
<p>Zellen mit <span class="math inline">\(f_{ij} \lt 5\)</span> gelten
als âunterbesetztâ. Der <span class="math inline">\(\chi^2\)</span>-Test
reagiert dann progressiv, das <span class="math inline">\(\alpha\)</span>-Fehlerniveau wird unterschritten
und die Wahrscheinlichkeit, die <span class="math inline">\(H_1\)</span>
anzunehmen steigt.</p>
<p>Die PrÃ¼fgrÃ¶Ãe muss in diesem Fall adjustiert werden:</p>
<p><span class="math display">\[\chi^2_{adj} =
\sum_{i=1}^r{\sum_{j=1}^c{\frac{(|f_{ij} - e_{ij}| -
0.5)^2}{e_{ij}}}}\]</span></p>
<p>In R erfolgt die Korrektur automatisch, kann aber auch mit der
<code>correct</code>-Option explizit aktiviert oder deaktiviert
werden:</p>
<pre><code>##     A  B
## I  10  8
## II  4 16</code></pre>
<p>Ohne Korrektur wird <span class="math inline">\(\alpha =
0.05\)</span> unterschritten:</p>
<pre class="r"><code>chisq.test(samples, correct = FALSE)</code></pre>
<pre><code>## 
##  Pearson's Chi-squared test
## 
## data:  samples
## X-squared = 5.1471, df = 1, p-value = 0.02329</code></pre>
<p>Mit Korrektur wird <span class="math inline">\(\alpha = 0.05\)</span>
nicht unterschritten:</p>
<pre class="r"><code>chisq.test(samples, correct = TRUE)</code></pre>
<pre><code>## 
##  Pearson's Chi-squared test with Yates' continuity correction
## 
## data:  samples
## X-squared = 3.7325, df = 1, p-value = 0.05336</code></pre>
</div>
</div>
</div>
</div>
<div id="multiplizitÃ¤t" class="section level1">
<h1>MultiplizitÃ¤t</h1>
<p>Wenn mit erhobenen Daten mehrere Tests durchgefÃ¼hrt werden, gilt fÃ¼r
jeden Test (âEndpunktâ) ein eigenes <span class="math inline">\(\alpha\)</span>-Fehlerniveau (âPer-Comparison
Error Rateâ, PCER).</p>
<p><span class="math display">\[\alpha_1 = \alpha_2 = \ldots = \alpha_k
= 0.05\]</span></p>
<p>Insgesamt bilden diese dann die âFamily-Wise Error Rateâ (FWER), die
deutlich hÃ¶her ausfallen kann, da die Wahrscheinlichkeiten <span class="math inline">\(1-\alpha_i\)</span>, also dafÃ¼r, sich
korrekterweise fÃ¼r <span class="math inline">\(H_0\)</span> zu
entscheiden, entsprechend der Kettenregel multipliziert werden.</p>
<p><span class="math display">\[(1-\alpha_1) \cdot (1-\alpha_2) \cdot
\ldots \cdot (1-\alpha_k) = (1-\alpha_i)^k\]</span></p>
<p>Bei <span class="math inline">\(\alpha = 0.05\)</span> und 5
Endpunkten:</p>
<p><span class="math display">\[(1 - 0.05)^5 = 0.95^5 \approx
0.774\]</span> <span class="math display">\[1-0.774 = 0.226 =
\alpha_{FWER}\]</span></p>
<p>Bei 14 Endpunkten und <span class="math inline">\(\alpha =
0.05\)</span> wird eine FWER von 50% Ã¼berschritten:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-50-1.png" width="768" style="display: block; margin: auto;"></p>
<div id="bonferroni-korrektur" class="section level2">
<h2>Bonferroni-Korrektur</h2>
<ul>
<li>bestimmt <span class="math inline">\(\alpha_i\)</span>, so dass
<span class="math inline">\(\alpha_{FWER} \le 0.05\)</span> wird.</li>
</ul>
<p>FÃ¼r <span class="math inline">\(k\)</span> unabhÃ¤ngige Endpunkte:</p>
<p><span class="math display">\[\alpha_i =
\frac{\alpha_{FWER}}{k}\]</span> <strong>Beispiel: <span class="math inline">\(\alpha_{FWER} = 0.05\)</span> und <span class="math inline">\(k = 3\)</span></strong></p>
<p><span class="math display">\[\alpha_i = \frac{0.05}{3} \approx 0.0167
\]</span></p>
<p><span class="math display">\[1 - (1- 0.0167)^3 \approx 0.049 \le
0.05\]</span></p>
<p><strong>Beispiel: Zwei Endpunkte in Form von zwei gerichteten
Alternativhypothesen <span class="math inline">\(H_{1,1}\)</span> und
<span class="math inline">\(H_{1,2}\)</span> gegenÃ¼ber Nullhypothese
<span class="math inline">\(H_{0,1}\)</span></strong></p>
<p><em>(analog zu einer ungerichteten <span class="math inline">\(H_1\)</span>, wo <span class="math inline">\(\alpha\)</span> ebenfalls auf beide Seiten
aufgeteilt wird. Siehe <a href="#zweiseitiger-signifikanztest">Zweiseitiger
Signifikanztest</a>)</em></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-51-1.png" width="768" style="display: block; margin: auto;"></p>
<p><span class="math inline">\(\overline{x}_1\)</span> liegt Ã¼ber dem
kritischen Wert fÃ¼r <span class="math inline">\(\alpha_i =
0.025\)</span> in positiver Richtung wÃ¤hrend <span class="math inline">\(\overline{x}_2\)</span> nicht unterhalb des
kritischen Wertes in negativer Richtung liegt.</p>
<p><span class="math inline">\(H_{1,1}\)</span> kann also akzeptiert
werden, <span class="math inline">\(H_{1,2}\)</span> jedoch nicht.</p>
</div>
<div id="holm-bonferroni-korrektur" class="section level2">
<h2>Holm-Bonferroni-Korrektur</h2>
<p><span class="math inline">\(k\)</span> UnabhÃ¤ngige Endpunkte werden
aufsteigend nach p-Wert sortiert.</p>
<p><span class="math display">\[\alpha_i = \frac{\alpha_{FWER}}{k - (i -
1)}\]</span></p>
<p><span class="math display">\[\alpha_1 = \frac{\alpha_{FWER}}{k},
\alpha_2 = \frac{\alpha_{FWER}}{k - 1}, \alpha_3 =
\frac{\alpha_{FWER}}{k - 2}, \dots, \alpha_k =
\frac{\alpha_{FWER}}{1}\]</span></p>
</div>
<div id="fallback-prozedur" class="section level2">
<h2>Fallback-Prozedur</h2>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(k\)</span> unabhÃ¤ngige Endpunkte werde
<em>a priori</em> nach Wichtigkeit sortiert.</li>
<li>
<span class="math inline">\(\alpha\)</span> Fehler (z.B.) 5% wird
frei auf Endpunkte verteilt.</li>
<li>Endpunkte werden der Reihe nach getestet</li>
</ol>
<ul>
<li><p><span class="math inline">\(p_i &gt; \alpha_i \rightarrow
\alpha_i = 0\)</span>, nicht signifikant</p></li>
<li>
<p><span class="math inline">\(p_i \le \alpha_i \rightarrow
\alpha^*_{i + 1} = \alpha_{i + 1} + \alpha_{i}\)</span></p>
<p>âunverbrauchterâ <span class="math inline">\(\alpha\)</span>-Fehler
wird an folgenden Test vererbt</p>
</li>
</ul>
<p>Beispiel:</p>
<pre><code>## # A tibble: 5 Ã 5
##   Endpunkt alpha     p `alpha*` signifikant
##      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;lgl&gt;      
## 1        1 0.03  0.01     0.03  TRUE       
## 2        2 0.01  0.03     0.04  TRUE       
## 3        3 0.005 0.05     0.045 FALSE      
## 4        4 0.003 0.002    0.003 TRUE       
## 5        5 0.002 0.004    0.005 TRUE</code></pre>
<p>Durch die âVererbungâ des <span class="math inline">\(\alpha\)</span>-Fehlers werden einige Tests
signifikant, die bei einfacher Aufteilung der Fehlerwahrscheinlichkeit
nicht als signifikant gelten kÃ¶nnten. Insgesamt beleibt aber <span class="math inline">\(\alpha_{FWER} \le 5\%\)</span>.</p>
</div>
</div>
<div id="varianzanalyse-anova" class="section level1">
<h1>Varianzanalyse (ANOVA)</h1>
<p>Zweck der ANOVA ist es, aufzuklÃ¤ren, ob die Variation zwischen
Stichproben, z.B. Versuchsarmen (Kontrollgruppe vs.Â Treatment-Gruppe),
auf die experimentelle Manipulation zurÃ¼ckzufÃ¼hren ist, oder zufÃ¤llige
Variation ist, die auch auftreten wÃ¼rde, wenn mehrere Zufallsstichproben
aus der gleichen Population gezogen wÃ¼rden.</p>
<div id="voraussetzungen" class="section level2">
<h2>Voraussetzungen</h2>
<ul>
<li>
<p><strong>unabhÃ¤ngige Variable in Faktorstufen</strong></p>
<p>UV muss in diskreten Faktorstufen vorliegen, damit sich eindeutige
Gruppen bilden lassen.</p>
</li>
<li>
<p><strong>HomooskedastizitÃ¤t</strong></p>
<p>Die Varianzen der einzelnen Gruppen dÃ¼rfen sich nicht
unterscheiden</p>
<p>In R mittels <code>leveneTest</code> im Paket
<code>car</code></p>
</li>
<li><p><strong>Normalverteilung der Residuen</strong></p></li>
</ul>
</div>
<div id="einfaktorielle-varianzanalyse" class="section level2">
<h2>Einfaktorielle Varianzanalyse</h2>
<div id="messwertezerlegung" class="section level3">
<h3>Messwertezerlegung</h3>
<ul>
<li><p>Messwert eines Merkmals einer Versuchsperson <span class="math inline">\(m\)</span>, unter Versuchsbedingung <span class="math inline">\(j\)</span>: <span class="math inline">\(x_{mj}\)</span></p></li>
<li><p>Durchschnittlicher Messwert aller VP unter Bedingung <span class="math inline">\(j\)</span>: <span class="math inline">\(\overline{x}_j\)</span></p></li>
<li>
<p>Abweichung vom Durchschnitt der Bedingungsgruppe <span class="math inline">\(j\)</span>: <span class="math inline">\(\overline{x}_j - x_{jm} = e_{mj}\)</span></p>
<p><span class="math inline">\(e\)</span>: Fehlerwert, auch Residuum
genannt: die Variation von Messwerten, die Ã¼brig bleibt, nachdem alle
systematischen Anteile der Variation entfernt wurden</p>
</li>
</ul>
<p><span class="math display">\[x_{mj}=\overline{x}_j +
e_{mj}\]</span></p>
<p>Der Messwert <span class="math inline">\(x_{mj}\)</span> wird zerlegt
in den Gruppenmittelwert <span class="math inline">\(\overline{x}_j\)</span> und das Residuum <span class="math inline">\(e_{mj}\)</span>.</p>
<div id="effekt-von-faktorstufen" class="section level4">
<h4>Effekt von Faktorstufen</h4>
<p>Der Effekt <span class="math inline">\(t_j\)</span> jeder Faktorstufe
(Bedingung) ist die Abweichung des jeweiligen Gruppenmittelwertes <span class="math inline">\(\overline{x}_j\)</span> vom Gesamtmittelwert <span class="math inline">\(\overline{x}\)</span>:</p>
<p><span class="math display">\[t_j = \overline{x}_j -
\overline{x}\]</span> Der Effekt <span class="math inline">\(t_j\)</span> ist <em>nur bedingt
interpretierbar</em>, da er sowohl eine systematische AbhÃ¤ngigkeit von
der Faktorstufe <span class="math inline">\(j\)</span> haben kann, aber
auch durch Stichprobenfehler entstehen kann.</p>
<p>Der Messwert <span class="math inline">\(x_{mj}\)</span> einer
einzelnen Versuchsperson <span class="math inline">\(m\)</span> unter
Bedingung <span class="math inline">\(j\)</span> wird also zerlegt in
den Gesamtmittelwert <span class="math inline">\(\overline{x}\)</span>
(Grundniveau), den Effekt der Bedingung <span class="math inline">\(t_j\)</span> und das Residuum der Person selbst
<span class="math inline">\(e_{mj}\)</span>:</p>
<p><span class="math display">\[x_{mj} = \overline{x} + t_j +
e_{mj}\]</span></p>
</div>
</div>
<div id="quadratsummenzerlegung" class="section level3">
<h3>Quadratsummenzerlegung</h3>
<p><strong>Quadratsumme</strong>: MaÃ der Variation (analog zur Varianz,
nur ohne Einfluss der StichprobengrÃ¶Ãe)</p>
<p><span class="math display">\[QS_{total} =
\sum_{j=1}^{J}{\sum_{m=1}^{n_j}{(x_{mj} - \overline{x})^2}}\]</span></p>
<p><span class="math inline">\(J\)</span>: Anzahl der Faktorstufen</p>
<p><span class="math inline">\(n_j\)</span>: Anzahl Individuen in der
jeweiligen Faktorgruppe</p>
<p><strong>Quadratsumme zwischen der Gruppen:</strong></p>
<p><span class="math display">\[QS_{zw} =
\sum_{j=1}^{J}{\sum_{m=1}^{n_j}{(\overline{x}_{j} -
\overline{x})^2}}\]</span></p>
<p>In <span class="math inline">\((\overline{x}_{j} -
\overline{x})\)</span> kommt <span class="math inline">\(m\)</span>
nicht mehr vor. <span class="math inline">\(QS_{zw}\)</span> ist also
unabhÃ¤ngig von der Variation die nur durch die einzelnen
Versuchspersonen verursacht wird. Also lÃ¤sst sich <span class="math inline">\(QS_{zw}\)</span> vereinfachen als, weil <span class="math inline">\((\overline{x}_{j} - \overline{x})\)</span> jeweils
fÃ¼r jedes <span class="math inline">\(m\)</span> gleich ist:</p>
<p><span class="math display">\[QS_{zw} = \sum_{j=1}^{J}{n_j \cdot
(\overline{x}_{j} - \overline{x})^2}\]</span></p>
<p><strong>Quadratsumme innerhalb der Gruppen:</strong></p>
<p><span class="math display">\[QS_{inn} =
\sum_{j=1}^{J}{\sum_{m=1}^{n_j}{(x_{mj} -
\overline{x}_{j})^2}}\]</span></p>
<p>Hier taucht <span class="math inline">\(\overline{x}\)</span> nicht
mehr auf und die Abweichungen der Faktorgruppen vom Gesamtmittelwert
haben keinen Einfluss mehr.</p>
<p><strong>Die Gesamtquadratsumme entspricht der Summe der
Teilquadratsummen:</strong></p>
<p><span class="math display">\[QS_{total} = QS_{zw} +
QS_{inn}\]</span></p>
<p>Die Teilquadratsummen stellen ein MaÃ dafÃ¼r dar, wie viel Varianz
durch den Effekt des jeweiligen Faktors bzw. die Residuen individuellen
Versuchspersonen erklÃ¤rt werden.</p>
<p><span class="math inline">\(QS_{zw}\)</span>: Quadratsumme des
Effektes</p>
<p><span class="math inline">\(QS_{inn}\)</span>: Quadratsumme der
Residuen</p>
</div>
<div id="effektgrÃ¶ÃenschÃ¤tzer-hateta2" class="section level3">
<h3>EffektgrÃ¶ÃenschÃ¤tzer <span class="math inline">\(\hat{\eta}^2\)</span>
</h3>
<p><span class="math inline">\(\eta\)</span>: Eta</p>
<p>Das VerhÃ¤ltnis der Effekt-Quadratsumme zur Gesamtquadratsumme stellt
dar, welcher Anteil der Gesamtvarianz durch den Effekt aufgeklÃ¤rt
wird.</p>
<p><span class="math display">\[\hat{\eta}^2 =
\frac{QS_{zw}}{QS_{total}}\]</span></p>
<p><span class="math inline">\(\hat{\eta}^2\)</span> kann auch direkt
aus dem empirischen F-Wert berechnet werden (siehe <a href="#f-test">F-Test</a>):</p>
<p><span class="math display">\[\hat{\eta}^2 = \frac{F \cdot df_{zw}}{F
\cdot df_{zw} + df_{inn}}\]</span></p>
<p><span class="math inline">\(\hat{\eta}^2 = 0\)</span>: Variation
entsteht komplett aus den Residuen und es gibt keinen gemessenen
Effekt.</p>
<p><span class="math inline">\(\hat{\eta}^2 = 1\)</span>: Variation
stammt vollstÃ¤ndig vom Effekt, keine Residuen.</p>
</div>
<div id="effektgrÃ¶ÃenschÃ¤tzer-hatomega2" class="section level3">
<h3>EffektgrÃ¶ÃenschÃ¤tzer <span class="math inline">\(\hat{\omega}^2\)</span>
</h3>
<p><span class="math inline">\(\omega\)</span>: Omega</p>
<p><span class="math inline">\(\hat{\eta}^2\)</span> ist kein
erwartungstreuer SchÃ¤tzer fÃ¼r <span class="math inline">\(\eta^2\)</span>, da die zugrundeliegende
ZÃ¤hlerquadratsumme <span class="math inline">\(QS_{zw}\)</span>
Stichprobenfehler enthÃ¤lt.</p>
<p><span class="math inline">\(\hat{\omega}^2\)</span> enthÃ¤lt diese
ÃberschÃ¤tzung von <span class="math inline">\(\eta^2\)</span> nicht.</p>
<p><span class="math display">\[\hat{\omega}^2 = \frac{QS_{zw} - (J - 1)
\cdot MQS_{inn}}{QS_{total} + MQS_{inn}}\]</span></p>
</div>
<div id="effektgrÃ¶Ãe-phi2-signal-rausch-verhÃ¤ltnis" class="section level3">
<h3>EffektgrÃ¶Ãe <span class="math inline">\(\phi^2\)</span>,
Signal-Rausch-VerhÃ¤ltnis</h3>
<p><span class="math inline">\(\phi\)</span>: Phi</p>
<p>In der Population ist <span class="math inline">\(\phi^2\)</span> der
Quotient aus Effektvarianz und Residualvarianz:</p>
<p><span class="math display">\[\phi^2 =
\frac{\sigma_{\tau}^2}{\sigma_{\epsilon}^2}\]</span></p>
<p><span class="math inline">\(\phi^2\)</span> lÃ¤sst sich auch aus <span class="math inline">\(\eta^2\)</span> berechnen:</p>
<p><span class="math display">\[\phi^2 = \frac{\eta^2}{1 -
\eta^2}\]</span></p>
<p>Analog gilt fÃ¼r den SchÃ¤tzer <span class="math inline">\(\hat{\phi}^2\)</span>:</p>
<p><span class="math display">\[\hat{\phi}^2 = \frac{\hat{\eta}^2}{1 -
\hat{\eta}^2}\]</span></p>
<div id="konventionen-fÃ¼r-phi2" class="section level4">
<h4>Konventionen fÃ¼r <span class="math inline">\(\phi^2\)</span>:</h4>
<ul>
<li>
<span class="math inline">\(\phi^2 \approx 0.01\)</span>: kleiner
Effekt</li>
<li>
<span class="math inline">\(\phi^2 \approx 0.0625\)</span>:
mittlerer Effekt</li>
<li>
<span class="math inline">\(\phi^2 \approx 0.16\)</span>: groÃer
Effekt</li>
</ul>
</div>
</div>
<div id="effektgrÃ¶Ãe-phi" class="section level3">
<h3>EffektgrÃ¶Ãe <span class="math inline">\(\phi\)</span>
</h3>
<p>Auch <span class="math inline">\(f\)</span> genannt</p>
<p><span class="math display">\[\phi = f = \sqrt{\phi^2}\]</span></p>
<p><span class="math inline">\(\phi\)</span> ist leichter
interpretierbar als <span class="math inline">\(\phi^2\)</span>, da es
Vielfache der Standardabweichung <span class="math inline">\(\sigma\)</span> des Merkmals angibt.</p>
</div>
<div id="effektgrÃ¶Ãe-lambda" class="section level3">
<h3>EffektgrÃ¶Ãe <span class="math inline">\(\lambda\)</span>
</h3>
<p><span class="math inline">\(\lambda\)</span>: Lambda</p>
<p><span class="math inline">\(\lambda\)</span> ist der
Nicht-ZentralitÃ¤ts-Parameter der F-Verteilung. Je grÃ¶Ãer <span class="math inline">\(\lambda\)</span>, umso weiter nach rechts
verschoben und flacher ist die Dichtefunktion der F-Verteilung:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-53-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Die Kurve fÃ¼r <span class="math inline">\(\lambda = 0\)</span>
(âzentrale F-Verteilungâ) ist die Verteilung unter der Nullhypothese dar
wÃ¤hrend die Kurve mit <span class="math inline">\(\lambda \gt 0\)</span>
die Alternativhypothese unter Annahme eines Effektes darstellt.</p>
<p><span class="math display">\[\lambda = n \cdot
\frac{\sigma_{\tau}^2}{\sigma_{\epsilon}^2} = n \cdot
\phi^2\]</span></p>
</div>
<div id="beziehungen-zwischen-effektgrÃ¶ÃenschÃ¤tzern" class="section level3">
<h3>Beziehungen zwischen EffektgrÃ¶ÃenschÃ¤tzern</h3>
<p><span class="math display">\[\hat{\lambda} = n \cdot \hat{\phi}^2 = n
\cdot \frac{\hat{\eta}^2}{1 - \hat{\eta}^2}\]</span></p>
<p><span class="math display">\[\hat{\eta}^2 =
\frac{\hat{\lambda}}{\hat{\lambda} + n}\]</span></p>
<p><span class="math display">\[\hat{\phi}^2 =
\frac{\hat{\lambda}}{n}\]</span> FÃ¼r die EffektgrÃ¶Ãen in der Population
gelten die Formeln analog ohne SchÃ¤tzer.</p>
</div>
<div id="konfidenzintervalle-der-effektgrÃ¶Ãen" class="section level3">
<h3>Konfidenzintervalle der EffektgrÃ¶Ãen</h3>
<p>Es wird meistens das Konfidenzintervall fÃ¼r eine EffektgrÃ¶Ãe
berechnet und dann je nach Bedarf in eine der anderen EffektgrÃ¶Ãen
umgerechnet.</p>
<p>Das Konfidenzintervall fÃ¼r <span class="math inline">\(\hat{\eta}^2\)</span> kann in R mit der Funktion
<code>ci.pvaf</code> (Paket MBESS) ermittelt werden.</p>
<p><em>(CI: confidence interval, PVAF: proportion of variance accounted
for)</em></p>
<pre class="r"><code>df1 &lt;- 2
df2 &lt;- 20
n &lt;- 100
f_v &lt;- 6

ci.pvaf(F.value = f_v, df.1 = df1, df.2 = df2, N = n, conf.level = 0.95) -&gt; ci_result
ci_result</code></pre>
<pre><code>## $Lower.Limit.Proportion.of.Variance.Accounted.for
## [1] 0.007685688
## 
## $Probability.Less.Lower.Limit
## [1] 0.025
## 
## $Upper.Limit.Proportion.of.Variance.Accounted.for
## [1] 0.2357811
## 
## $Probability.Greater.Upper.Limit
## [1] 0.025
## 
## $Actual.Coverage
## [1] 0.95</code></pre>
<p>Dargestellt als F-Verteilungen mit <span class="math inline">\(\lambda\)</span>-Konfidenzintervall:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-55-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
<div id="schÃ¤tzung-der-populationsparameter" class="section level3">
<h3>SchÃ¤tzung der Populationsparameter</h3>
<div id="schÃ¤tzung-des-populationsmittelwertes" class="section level4">
<h4>SchÃ¤tzung des Populationsmittelwertes</h4>
<p><span class="math display">\[\hat{\mu} = \overline{x} =
\frac{\sum_{j=1}^J{\sum_{m=1}^{n_j}{x_{mj}}}}{n}\]</span></p>
<p>Der Gesamtmittelwert aller Messungen <span class="math inline">\(x_{mj}\)</span> ist der SchÃ¤tzer fÃ¼r den
Mittelwert der Population <span class="math inline">\(\hat{\mu}\)</span>.</p>
</div>
<div id="schÃ¤tzung-des-effektes-tau_j" class="section level4">
<h4>SchÃ¤tzung des Effektes <span class="math inline">\(\tau_j\)</span>
</h4>
<p><span class="math display">\[\hat{\tau_j} = t_j = x_{mj} -
\overline{x}\]</span></p>
</div>
<div id="schÃ¤tzung-der-varianz-der-residuen-in-der-population" class="section level4">
<h4>SchÃ¤tzung der Varianz der Residuen in der Population</h4>
<p>Die geschÃ¤tzte Varianz der Residuen in der Population <span class="math inline">\(\hat{\sigma}_\epsilon^2\)</span> entspricht der
mittleren Quadratsumme <span class="math inline">\(MQS_{inn}\)</span>
innerhalb der einzelnen Bedingungen <span class="math inline">\(MQS_{j}\)</span>:</p>
<p><span class="math display">\[MQS_{j} =
\frac{\sum_{m-1}^{n_j}{(x_{mj}-\overline{x})^2}}{n_j - 1}\]</span></p>
<p><span class="math display">\[\hat{\sigma}_\epsilon^2 = MQS_{inn} =
\frac{\sum_{j=1}^{J}{MQS_j}}{J}\]</span></p>
<p>Beim unterschiedlich groÃen Gruppen wird ein gewichtetes
arithmetisches Mittel der <span class="math inline">\(MQS_j\)</span>
berechnet:</p>
<p><span class="math display">\[\hat{\sigma}_\epsilon^2 = MQS_{inn} =
\frac{\sum_{j=1}^{J}{MQS_j \cdot (n_j -
1)}}{\sum_{j=1}^J{n_j-1}}\]</span></p>
<p>Das lÃ¤sst sich vereinfachen als:</p>
<p><span class="math display">\[\hat{\sigma}_\epsilon^2 = MQS_{inn} =
\frac{QS_{inn}}{n-J}\]</span></p>
</div>
</div>
</div>
<div id="hypothesenprÃ¼fung-in-der-varianzanalyse" class="section level2">
<h2>HypothesenprÃ¼fung in der Varianzanalyse</h2>
<p>Wenn <span class="math inline">\(H_0\)</span> gilt, und kein Effekt
zwischen den Faktorgruppen besteht, so sind <span class="math inline">\(MQS_{zw}\)</span> und <span class="math inline">\(MQS_{inn}\)</span> beides erwartungstreue SchÃ¤tzer
der Varianz der Residuen in der Population <span class="math inline">\(\hat{\sigma}^2_\epsilon\)</span>, da auÃer den
Residuen keine andere Quelle fÃ¼r Varianz vorhanden ist.</p>
<p>Je mehr <span class="math inline">\(MQS{zw}\)</span> von <span class="math inline">\(MQS_{inn}\)</span> abweicht, umso mehr spricht das
dafÃ¼r, dass die Nullhypothese nicht haltbar ist.</p>
<p><span class="math display">\[MQS_{zw} =
\frac{QS_{zw}}{J-1}\]</span></p>
<div id="f-test" class="section level3">
<h3>F-Test</h3>
<p>Die F-Statistik ist ein MaÃ dafÃ¼r, wie stark <span class="math inline">\(MQS_{zw}\)</span> von <span class="math inline">\(MQS_{inn}\)</span> abweicht:</p>
<p><span class="math display">\[F =
\frac{MQS_{zw}}{MQS_{inn}}\]</span></p>
<p><span class="math inline">\(F\)</span> folgt der F-Verteilung. Diese
hat zwei Parameter:</p>
<ul>
<li>
<p>Freiheitsgrade des Kennwertes im ZÃ¤hler, hier <span class="math inline">\(MQS_{zw}\)</span></p>
<p><span class="math inline">\(df_{zw} = J-1\)</span></p>
</li>
<li>
<p>Freiheitsgrade des Kennwertes in Nenner, hier <span class="math inline">\(MQS_{inn}\)</span></p>
<p><span class="math inline">\(df_{inn} = n-J\)</span></p>
</li>
</ul>
<p>GeprÃ¼ft wird der empirische F-Wert also gegen die Verteilung <span class="math inline">\(F(df_{zw}; df_{inn})\)</span>. Wenn der kritische
F-Wert fÃ¼r das festgelegte <span class="math inline">\(\alpha\)</span>-Niveau erreicht wird, ist die
Nullhypothese zu verwerfen.</p>
<p>Der F-Test <strong>prÃ¼ft nur die globale Nullhypothese</strong>, also
dass ALLE Effekte <span class="math inline">\(\tau_j\)</span> in der
Population 0 sind. Er gibt keine Auskunft darÃ¼ber, welche
Mittelwertunterschiede zwischen welchen Faktorstufen signifikant
sind.</p>
<div id="beispiel-fÃ¼r-f-test" class="section level4">
<h4>Beispiel fÃ¼r F-Test</h4>
<p>Zwei Faktorgruppen (Studienarme), je 10 Versuchspersonen, <span class="math inline">\(J = 2, n_j = 10\)</span></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-56-1.png" width="768" style="display: block; margin: auto;"></p>
<p><strong>Gesamtquadratsumme <span class="math inline">\(QS_{total}\)</span>:</strong></p>
<pre class="r"><code>samples %&gt;%
  summarize(
    QS_total= sum( (x - mean(x))^2 )
  ) %&gt;% pull(1) -&gt; QS_total

QS_total</code></pre>
<pre><code>## [1] 41.86613</code></pre>
<p><strong>Quadratsumme zwischen den Faktorgruppen <span class="math inline">\(QS_{zw}\)</span>:</strong></p>
<pre class="r"><code>samples %&gt;% group_by(j) %&gt;%
  mutate(
    x_j = mean(x),
  ) %&gt;% ungroup() %&gt;%
  summarize(
    QS_zw = sum( (x_j - mean(x))^2 )
  ) %&gt;% pull(1) -&gt; QS_zw

QS_zw</code></pre>
<pre><code>## [1] 16.27101</code></pre>
<p><strong>Quadratsumme innerhalb der Gruppen <span class="math inline">\(QS_{inn}\)</span>:</strong></p>
<pre class="r"><code>samples %&gt;% group_by(j) %&gt;%
  mutate(
    x_j = mean(x)
  ) %&gt;% ungroup() %&gt;%
  summarize(
    QS_inn = sum( (x - x_j)^2 )
  ) %&gt;% pull(1) -&gt; QS_inn

QS_inn</code></pre>
<pre><code>## [1] 25.59512</code></pre>
<p><strong>AdditivitÃ¤t der Quadratsummen:</strong></p>
<pre class="r"><code>QS_total == QS_zw + QS_inn</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p><strong>VarianzaufklÃ¤rung <span class="math inline">\(\eta^2\)</span>:</strong></p>
<pre class="r"><code>eta_sq = QS_zw / QS_total
eta_sq</code></pre>
<pre><code>## [1] 0.3886438</code></pre>
<p>Der Effekt zwischen den Faktorstufen klÃ¤rt 38.9% der Varianz auf.</p>
<p><strong>HypothesenprÃ¼fung:</strong></p>
<pre class="r"><code>MQS_zw &lt;- QS_zw / (J - 1)
MQS_zw</code></pre>
<pre><code>## [1] 16.27101</code></pre>
<pre class="r"><code>MQS_inn &lt;- QS_inn / (n_total - J)
MQS_inn</code></pre>
<pre><code>## [1] 1.421951</code></pre>
<p>Empirischer F-Wert:</p>
<pre class="r"><code>f_emp &lt;- MQS_zw / MQS_inn
f_emp</code></pre>
<pre><code>## [1] 11.44274</code></pre>
<p>Freiheitsgrade:</p>
<pre class="r"><code>df_zw &lt;- J - 1
df_inn &lt;- n_total - J
list(df_zw = df_zw, df_inn = df_inn)</code></pre>
<pre><code>## $df_zw
## [1] 1
## 
## $df_inn
## [1] 18</code></pre>
<p>F-Verteilung und Vergleich mit kritischem F-Wert bei <span class="math inline">\(\alpha = 0.05\)</span>:</p>
<pre class="r"><code>f_crit &lt;- qf(0.95, df1 = df_zw, df2 = df_inn)

ggplot() +
  xlim(2.5, 13) +
  geom_function(fun = df, args = list(df1 = df_zw, df2 = df_inn)) +
  stat_function(fun = df, args = list(df1 = df_zw, df2 = df_inn),
                geom = "area",
                fill = colors[1], alpha = 0.3,
                xlim = c(f_crit, 13)) +
  geom_vline(xintercept = f_emp, color = colors[2]) +
  annotate("text", label = paste("F =", round(f_emp,2)), x = 10, y = 0.025, hjust = 0, color = colors[2]) +
  labs(x = "F-Wert", y = "Wahrscheinlichkeitsdichte") +
  theme_custom</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-66-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Der empirische F-Wert Ã¼berschreitet den kritischen F-Wert fÃ¼r <span class="math inline">\(\alpha = 0.05\)</span>. Die Nullhypothese wird
also verworfen. Es besteht ein signifikanter Unterschied zwischen den
Faktorgruppen, der sich nicht durch zufÃ¤llige Variation erklÃ¤ren
lÃ¤sst.</p>
</div>
</div>
<div id="automatische-durchfÃ¼hrung-in-r" class="section level3">
<h3>Automatische DurchfÃ¼hrung in R</h3>
<p>Die <code>aov()</code> Funktion ist standardmÃ¤Ãig verfÃ¼gbar.</p>
<p>Es muss eine Formel angegeben werden, die den Zusammenhang zwischen
unabhÃ¤ngigen und abhÃ¤ngigen Variablen beschreibt, hier z.B.
<code>x ~ j</code> (Messwert <span class="math inline">\(x\)</span> in
AbhÃ¤ngigkeit von Faktor <span class="math inline">\(j\)</span>).</p>
<pre class="r"><code>aov(x ~ j, data = samples) %&gt;% summary</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value  Pr(&gt;F)   
## j            1  16.27  16.271   11.44 0.00332 **
## Residuals   18  25.59   1.422                   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<div id="zweifaktorielle-varianzanalyze" class="section level2">
<h2>Zweifaktorielle Varianzanalyze</h2>
<p>ZusÃ¤tzlich zum ersten Faktor <span class="math inline">\(A\)</span>
und einem zweiten Faktor <span class="math inline">\(B\)</span>, die die
Haupteffekte verursachen kÃ¶nnen, kommt noch die Interaktion <span class="math inline">\(A \times B\)</span> hinzu. Die Gesamtquadratsumme
$QS_{total} wird bei zwei Faktoren zerlegt in:</p>
<ul>
<li><span class="math inline">\(QS_A\)</span></li>
<li><span class="math inline">\(QS_B\)</span></li>
<li><span class="math inline">\(QS_{A \times B}\)</span></li>
<li><span class="math inline">\(QS_{inn}\)</span></li>
</ul>
<p>FÃ¼r die Quadratsummen der Haupteffekte werden die Abweichungen der
Mittelwerte in ALLEN Gruppen der gleichen Faktorstufe auf dem jeweiligen
Faktor vom Gesamtmittelwert bestimmt.</p>
<p>FÃ¼r Faktor <span class="math inline">\(A\)</span> mit <span class="math inline">\(j\)</span> Stufen:</p>
<p><span class="math display">\[QS_A =
\sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{(\overline{x}_j -
\overline{x})^2}}}\]</span></p>
<p>Vereinfacht, da Variation der <span class="math inline">\(n_{Zelle}\)</span> Messwerte in jeder Zelle
gemittelt werden:</p>
<p><em>(Vorausgesetzt alle Zellen enthalten gleich viele
Messwerte)</em></p>
<p><span class="math display">\[QS_A = n_{Zelle} \cdot K
\cdot\sum_{j=1}^J{}{(\overline{x}_j - \overline{x})^2}\]</span></p>
<p>FÃ¼r Faktor <span class="math inline">\(B\)</span> analog:</p>
<p><span class="math display">\[QS_B =
\sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{(\overline{x}_k -
\overline{x})^2}}} = n_{Zelle} \cdot J
\cdot\sum_{k=1}^K{}{(\overline{x}_k - \overline{x})^2} \]</span></p>
<p>Die Quadratsumme des Interaktionseffektes <span class="math inline">\(QS_{A \times B}\)</span> ergibt sich, indem die
Mittelwertabweichungen der Haupteffekte <span class="math inline">\(A\)</span> und <span class="math inline">\(B\)</span> von der Mittelwertabweichung in jeder
Zelle abgezogen werden:</p>
<p><span class="math display">\[QS_{A \times B} =
\sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{((\overline{x}_{jk} -
\overline x) - (\overline x_j - \overline x) - (\overline x_k -
\overline{x}))^2}}}\]</span></p>
<p>Auch hier lÃ¤sst sich vereinfachen:</p>
<p><span class="math display">\[QS_{A \times B} = n_{Zelle} \cdot
\sum_{k=1}^K{\sum_{j=1}^J{((\overline{x}_{jk} - \overline x) -
(\overline x_j - \overline{x}) - (\overline x_k -
\overline{x}))^2}}\]</span></p>
<div id="nicht-partiielles-effektstÃ¤rkenmaÃ-hateta2" class="section level3">
<h3>Nicht-partiielles EffektstÃ¤rkenmaÃ: <span class="math inline">\(\hat{\eta}^2\)</span>
</h3>
<p>Genau wie in der einfaktoriellen Varianzanalyse ist <span class="math inline">\(\hat{\eta}^2\)</span> das VerhÃ¤ltnis von
Effektquadratsumme zu Gesamtquadratsumme.</p>
<p><span class="math display">\[\hat{\eta}_A^2 =
\frac{QS_A}{QS_{total}}\]</span> <span class="math display">\[\hat{\eta}_B^2 = \frac{QS_B}{QS_{total}}\]</span>
<span class="math display">\[\hat{\eta}_{A \times B}^2 = \frac{QS_{A
\times B}}{QS_{total}}\]</span></p>
<p>Das nicht-partielle <span class="math inline">\(\hat{\eta}^2\)</span>
hat das Problem, dass es nur Auskunft darÃ¼ber gibt, wie viel der
Gesamtvarianz in einer konkreten Untersuchung ein Faktor oder eine
Interaktion aufklÃ¤rt. Es ermÃ¶glicht keinen Vergleich mit anderen
Untersuchungen, die den gleichen Faktor enthalten aber zusÃ¤tzlich noch
weitere, die nicht in beiden Untersuchungen vorhanden sind.</p>
</div>
<div id="partielles-effektgrÃ¶ÃenmaÃ-hateta_p2" class="section level3">
<h3>Partielles EffektgrÃ¶ÃenmaÃ <span class="math inline">\(\hat{\eta}_p^2\)</span>
</h3>
<p>Das partielle <span class="math inline">\(\hat{\eta}_p^2\)</span> ist
das VerhÃ¤ltnis einer Effektquadratsumme und einer Teilquadratsumme, die
Effekt und Residuum enthÃ¤lt:</p>
<p><span class="math display">\[\hat{\eta}_{pA}^2 = \frac{QS_{A}}{QS_{A}
+ QS_{inn}}\]</span></p>
<p><em>(analog fÃ¼r Effekte <span class="math inline">\(B\)</span> und
<span class="math inline">\(A \times B\)</span>)</em></p>
</div>
<div id="schÃ¤tzung-der-haupteffekte" class="section level3">
<h3>SchÃ¤tzung der Haupteffekte</h3>
<p><span class="math display">\[\tau_{b_j} = \hat{\tau}_{b_j} =
\overline{x}_j - \overline {x}\]</span></p>
<p><span class="math display">\[\tau_{b_k} = \hat{\tau}_{b_k} =
\overline{x}_k - \overline {x}\]</span></p>
<p><span class="math display">\[\tau_{b_{(A \times B)_{jk}}} =
\hat{\tau}_{b_k} = (\overline{x}_{jk} - \overline {x}) -
(\overline{x}_{j} - \overline {x}) - (\overline{x}_{k} - \overline
{x})\]</span></p>
</div>
<div id="schÃ¤tzung-des-residuums" class="section level3">
<h3>SchÃ¤tzung des Residuums</h3>
<p><span class="math display">\[\hat{\epsilon}_{mjk} = x_{mjk} -
\overline x_{jk}\]</span></p>
</div>
<div id="schÃ¤tzung-der-populationsresidualvarianz" class="section level3">
<h3>SchÃ¤tzung der Populationsresidualvarianz</h3>
<p><span class="math display">\[\hat{\sigma}^2_{\epsilon} =
\frac{\sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{(x_{mjk} -
\overline x_{jk})^2}}}}{J \cdot K \cdot (n_{Zelle} - 1)}\]</span></p>
</div>
<div id="hypothesenprÃ¼fung-bei-zweifaktorieller-varianzanalyse" class="section level3">
<h3>HypothesenprÃ¼fung bei zweifaktorieller Varianzanalyse</h3>
<div id="zerlegung-der-freiheitsgrade" class="section level4">
<h4>Zerlegung der Freiheitsgrade</h4>
<p><span class="math display">\[df_{zw} = df_A + df_B + df_{A \times B}
= J \cdot K - 1\]</span></p>
<p><span class="math display">\[df_A = J - 1\]</span> <span class="math display">\[df_B = K - 1\]</span> <span class="math display">\[df_{inn} = J \cdot K \cdot (n_{Zelle} -
1)\]</span></p>
<p>daraus folgt:</p>
<p><span class="math display">\[df_{A \times B} = (J \cdot K - 1) - (J -
1) - (K - 1)\]</span> <span class="math display">\[df_{A \times B} = (J
- 1) \cdot (K - 1)\]</span></p>
<p><span class="math display">\[df_{total} = df_A + df_B + df_{A \times
B} +df_{inn}\]</span></p>
<p>Entsprechende mittlere Quadratsummen und F-Werte wie bei
einfaktorieller ANOVA:</p>
<p><span class="math display">\[MQS_{inn} =
\frac{QS_{inn}}{df_{inn}}\]</span></p>
<p><span class="math display">\[\begin{align*}
MQS_A &amp;= \frac{QS_A}{df_A} \\
F_A &amp;= \frac{MQS_A}{MQS_{inn}}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
MQS_B &amp;= \frac{QS_B}{df_B} \\
F_B &amp;= \frac{MQS_B}{MQS_{inn}}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
MQS_{A \times B} &amp;= \frac{QS_{A \times B}}{df_{A \times B}} \\
F_{A \times B} &amp;= \frac{MQS_{A \times B}}{MQS_{inn}}
\end{align*}\]</span></p>
<p>F-Tests und Konfidenzintervalle funktionieren genau wie bei der
einfaktoriellen Varianzanalyse.</p>
</div>
<div id="hypothesenpaare" class="section level4">
<h4>Hypothesenpaare</h4>
<ul>
<li>
<p>Haupteffekt <span class="math inline">\(A\)</span></p>
<p><span class="math inline">\(H_0: \mu_j - \mu = 0\)</span> bzw. <span class="math inline">\(\tau_{A_j} = 0\)</span></p>
<p><span class="math inline">\(H_1: \mu_j = \mu \neq 0\)</span> bzw.
<span class="math inline">\(\tau_{A_j} \neq 0\)</span></p>
</li>
<li>
<p>Haupteffekt <span class="math inline">\(B\)</span></p>
<p><span class="math inline">\(H_0: \mu_k - \mu = 0\)</span> bzw. <span class="math inline">\(\tau_{B_k} = 0\)</span></p>
<p><span class="math inline">\(H_1: \mu_k = \mu \neq 0\)</span> bzw.
<span class="math inline">\(\tau_{B_k} \neq 0\)</span></p>
</li>
<li>
<p>Interaktion <span class="math inline">\(A \times B\)</span></p>
<p><span class="math inline">\(H_0: \mu_{jk} - \mu_j - \mu_k =
0\)</span> bzw. <span class="math inline">\(\tau_{(A \times B)_{jk}} =
0\)</span></p>
<p><span class="math inline">\(H_1: \mu_{jk} - \mu_j - \mu_k \neq
0\)</span> bzw. <span class="math inline">\(\tau_{(A \times B)_{jk}}
\neq 0\)</span></p>
</li>
</ul>
</div>
</div>
</div>
<div id="varianzanalyse-mit-messwiederholung" class="section level2">
<h2>Varianzanalyse mit Messwiederholung</h2>
<p>Sowohl bei einfaktorieller als auch zweifaktorieller ANOVA kÃ¶nnen
Messwiederholungen der gleichen Versuchspersonen mit berÃ¼cksichtigt
werden.</p>
<p>Hierzu wird die Versuchsperson selbst als Faktor mit Haupteffekt
eingefÃ¼hrt und es findet eine weitere Quadratsummenzerlegung statt:</p>
<p><span class="math display">\[QS_{zw} = QS_{zwA} +
QS_{zwP}\]</span></p>
<p><span class="math inline">\(QS_{zwA}\)</span>: Quadratsumme der
Variation zwischen den Stufen des Faktors <span class="math inline">\(A\)</span></p>
<p><span class="math inline">\(QS_{zwP}\)</span>: Quadratsumme der
Variation zwischen Versuchspersonen</p>
<p><span class="math inline">\(QS_{res}\)</span> bezeichnet die
verbleibende residuale Quadratsumme, die auch die Variation zwischen
Messzeitpunkten der jeweils gleichen Versuchsperson enthÃ¤lt.</p>
<p>Das partielle <span class="math inline">\(\hat{\eta}^2_p\)</span>
gibt dann Auskunft darÃ¼ber, welcher Anteil der Gesamt Varianz NUR durch
den Faktor <span class="math inline">\(A\)</span> aufgeklÃ¤rt wird:</p>
<p><span class="math display">\[\hat{\eta}^2_p =
\frac{QS_{zwA}}{QS_{zwA} + QS_{res}}\]</span></p>
<p>Messwiederholung ist sowohl auf einfaktorielle als auch
zweifaktorielle ANOVA anwendbar.</p>
</div>
<div id="populationsmodell-der-varianzanalyse" class="section level2">
<h2>Populationsmodell der Varianzanalyse</h2>
<p>In der Population ergibt sich der Messwert aus dem Gesamtmittelwert
addiert mit allen Haupt- und Interaktionseffekten, sowie dem
Residuum:</p>
<p><span class="math display">\[x_{mjk} = \mu + \tau_{a_j} + \tau_{b_k}
+ \tau_{(A \times B)_{jk}} + \epsilon_{mjk}\]</span></p>
<p><span class="math inline">\(\rightarrow\)</span> Grundlage fÃ¼r
allgemeines lineares Modell!</p>
</div>
</div>
<div id="allgemeines-lineares-modell" class="section level1">
<h1>Allgemeines Lineares Modell</h1>
<ul>
<li>Oberbegriff fÃ¼r eine generisches statistisches Modell zur Prognose
bzw. ErklÃ¤rung von metrischen abhÃ¤ngigen Variablen</li>
</ul>
<p>Student-T-Test und Varianzanalyse sind z.B. SonderfÃ¤lle dieses
Modells.</p>
<div id="einfache-lineare-regression" class="section level2">
<h2>Einfache lineare Regression</h2>
<p>Bei der linearen Regression wird versucht, eine Gerade so zu legen,
dass deren mittlerer Abstand zu den empirischen Messwerten mÃ¶glichst
gering ist.</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-68-1.png" width="768" style="display: block; margin: auto;"></p>
<p><strong>Modellgleichung mit einer unabhÃ¤ngigen
Variablen:</strong></p>
<p>In einer Stichprobe:</p>
<p><span class="math display">\[Y = b_0 + b_1 \cdot X_1 + E\]</span></p>
<p>In der Population:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 \cdot X_1 +
\epsilon\]</span></p>
<ul>
<li>
<span class="math inline">\(b_0\)</span>/<span class="math inline">\(\beta_0\)</span>: Regressionskonstante,
Schnittpunkt mit der Y-Achse, âInterceptâ</li>
<li>
<span class="math inline">\(b_1\)</span>/<span class="math inline">\(\beta_1\)</span>: Regressionsgewicht, Steigung der
Regressionsgeraden, âSlopeâ</li>
</ul>
<p>Der Abstand der Messpunkte zur Regressionsgeraden sind die
Residuen:</p>
<pre class="r"><code>samples %&gt;% ggplot(aes(x = x, y = y - y_fit)) +
  geom_point() +
  geom_segment(aes(xend = x, yend = 0), color = colors[1], alpha = 0.4) +
  labs(y = "Residuum") +
  theme_custom</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-69-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Der Mittelwert der Residuen ist immer 0.</p>
<p>Die Varianz der Residuen wird auch als <strong>Fehlervarianz</strong>
bezeichnet, da die angibt, wie weit die empirischen Werte um die
Regressionsgerade streuen und damit, wie ungenau die Vorhersagen des
Modells sind.</p>
<p>Die Standardabweichung der Residuen ist der
<strong>StandardschÃ¤tzfehler</strong>. Sie ist in der Stichprobe
allerdings kein erwartungstreuer SchÃ¤tzer des StandardschÃ¤tzfehlers in
der Population.</p>
<div id="bestimmung-der-regressionskoeffizienten" class="section level3">
<h3>Bestimmung der Regressionskoeffizienten</h3>
<p>Die Bedingung, dass der Abstand der Messpunkte zur Regressionsgeraden
minimal sein soll, ist am besten erfÃ¼llt wenn <span class="math inline">\(b1\)</span> aus der Produkt-Moment-Korrelation der
beiden Variablen sowie ihrer Stichprobenstandardabweichungen <span class="math inline">\(s_X\)</span> und <span class="math inline">\(z_Y\)</span> bestimmt wird:</p>
<p><span class="math display">\[b_1 = r_{XY} \cdot
\frac{s_Y}{s_X}\]</span></p>
<p><span class="math display">\[r_{XY} = \frac{1}{n} \cdot \sum_{m =
1}^n{z_X \cdot z_Y}\]</span> <em><span class="math inline">\(z_X\)</span> und <span class="math inline">\(z_Y\)</span> sind die Z-transformierten Werte der
Variablen.</em></p>
<p>Bei zwei Z-standardisierten Variablen ist das Regressionsgewicht
gleich der Produkt-Moment-Korrelation, weil die
Stichprobenstandardabweichungen beide 1 sind.</p>
<p>Die Regressionskonstante <span class="math inline">\(b_0\)</span>
ergibt sich dann wie folgt:</p>
<p><span class="math display">\[b_0 = \overline{y} - b_1 \cdot
\overline{x}\]</span></p>
</div>
<div id="standardfehler-der-modellparameter" class="section level3">
<h3>Standardfehler der Modellparameter</h3>
<p><strong>Erwartungsstreuer SchÃ¤tzer des
StandardschÃ¤tzfehlers:</strong></p>
<p><span class="math display">\[\hat{\sigma}_e = \sqrt{\frac{1}{n-2}
\cdot \sum{(y_m - \hat{y}_m)^2}}\]</span> <span class="math inline">\(y_m - \hat{y}_m\)</span> ist die Abweichung des
tatsÃ¤chlichen Messwertes vom modellierten Wert, also das Residuum.</p>
<p><strong>SchÃ¤tzer der Standardfehler der
Regressionskoeffizienten:</strong></p>
<p><span class="math display">\[\hat{\sigma}_{\beta_0} = \hat{\sigma}_e
\cdot \sqrt{\frac{1}{n} + \frac{\overline{x}^2}{n \cdot
s^2_X}}\]</span></p>
<p><span class="math display">\[\hat{\sigma}_{\beta_1} =
\sqrt{\frac{\hat{\sigma_e}^2}{n \cdot s_X^2}}\]</span></p>
</div>
<div id="alternative-wege-zur-bestimmung-der-regressionskoeffizienten" class="section level3">
<h3>Alternative Wege zur Bestimmung der Regressionskoeffizienten</h3>
<div id="kriterium-der-kleinsten-quadrate" class="section level4">
<h4>Kriterium der kleinsten Quadrate</h4>
<p>Die Regressionskoeffizienten werden so geschÃ¤tzt, dass die Summe der
quadrierten Abweichungen der tatsÃ¤chlichen Messwerte von den
modellierten Werten minimal wird.</p>
<p><span class="math display">\[\sum_{m=1}^n{(y_m - \hat{y}_m)^2}
\rightarrow min\]</span></p>
</div>
<div id="likelihood-maximierung" class="section level4">
<h4>Likelihood-Maximierung</h4>
<p>Die Grundannahme, dass die abhÃ¤ngige Variable in der Population
normalverteilt ist, fÃ¼hrt dazu, dass sie wie folgt modelliert werden
kann:</p>
<p><span class="math display">\[y \sim Normal(\beta_0 + \beta_1 \cdot
x_m, \sigma_e^2)\]</span></p>
<p>Die tatsÃ¤chliche AusprÃ¤gung folgt einer Normalverteilung, bei der der
Mittelwert der Vorhersagewert des linearen Modells und die
Standardabweichung der StandardschÃ¤tzfehler ist.</p>
<p>FÃ¼r diese Normalverteilung kann die Likelihood der empirisch
beobachteten Daten bestimmt werden.</p>
<p>Es werden dann die Regressionskoeffizienten gesucht, fÃ¼r die die
Likelihood bzw. Log(Likelihood) maximal werden.</p>
<p><strong>Sowohl die Likelihood-Maximierung, als auch das Kriterium der
kleinsten Quadrate sind Optimierungsprobleme, die sich kaum von Hand
lÃ¶sen lassen und durch Computer numerisch gelÃ¶st werden
mÃ¼ssen.</strong></p>
</div>
</div>
<div id="hypothesenprÃ¼fung-bei-einfacher-linearer-regression" class="section level3">
<h3>HypothesenprÃ¼fung bei einfacher linearer Regression</h3>
<p><span class="math inline">\(H_{00}\)</span>: <span class="math inline">\(\beta_1 = 0\)</span>, <span class="math inline">\(H_{01}\)</span>: <span class="math inline">\(\beta_1 \neq 0\)</span></p>
<p><span class="math display">\[t = \frac{b_1 -
\beta_{10}}{\hat{\sigma}_{b_1}} \sim Student(df = n - 2)\]</span></p>
<p>(<span class="math inline">\(\beta_{10} = 0\)</span> bei spezieller
Nullhypothese <span class="math inline">\(H_0: \beta_1 = 0\)</span>)</p>
<p><span class="math inline">\(H_{10}\)</span>: <span class="math inline">\(\beta_0 = \beta_{00}\)</span>, <span class="math inline">\(H_{11}\)</span>: <span class="math inline">\(\beta_0 \neq \beta_{00}\)</span></p>
<p><span class="math display">\[t = \frac{b_0 -
\beta_{00}}{\hat{\sigma}_{b_0}} \sim Student(df = n - 2)\]</span></p>
</div>
<div id="konfidenzintervalle-fÃ¼r-regressionskoeffizienten" class="section level3">
<h3>Konfidenzintervalle fÃ¼r Regressionskoeffizienten</h3>
<p><span class="math display">\[b_1 \pm t_{(1-\frac{\alpha}{2}; n-2)}
\cdot \hat{\sigma}_{b_1}\]</span></p>
<p><span class="math display">\[b_0 \pm t_{(1-\frac{\alpha}{2}; n-2)}
\cdot \hat{\sigma}_{b_0}\]</span></p>
</div>
<div id="einfache-lineare-regression-in-r" class="section level3">
<h3>Einfache lineare Regression in R</h3>
<pre class="r"><code>lm(y ~ x, samples) -&gt; lm1

summary(lm1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = samples)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7060 -0.9742 -0.4539  0.9479  3.0728 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  7.25267    1.35524   5.352 4.37e-05 ***
## x            0.30451    0.05124   5.943 1.27e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.625 on 18 degrees of freedom
## Multiple R-squared:  0.6624, Adjusted R-squared:  0.6437 
## F-statistic: 35.32 on 1 and 18 DF,  p-value: 1.267e-05</code></pre>
<p>Extraktion der Koeffizienten:</p>
<pre class="r"><code>coef(lm1)</code></pre>
<pre><code>## (Intercept)           x 
##    7.252667    0.304506</code></pre>
<p>Konfidenzintervalle der Koeffizienten:</p>
<pre class="r"><code>confint(lm1, level = 0.95)</code></pre>
<pre><code>##                 2.5 %     97.5 %
## (Intercept) 4.4054111 10.0999220
## x           0.1968588  0.4121532</code></pre>
<p>Residuen:</p>
<pre class="r"><code>resid(lm1)</code></pre>
<pre><code>##            1            2            3            4            5            6 
## -0.810005726 -1.669324066 -0.782480228  1.163274890  0.924972643  0.005258351 
##            7            8            9           10           11           12 
## -1.220609279 -0.634036491  3.072819146  1.016600629 -0.523908529 -1.250597374 
##           13           14           15           16           17           18 
##  0.222625960 -2.706005447 -0.383962449 -0.892032207  3.008439197  2.631282829 
##           19           20 
##  0.436793706 -1.609105554</code></pre>
<p>Modellierte(âfittedâ) Werte:</p>
<pre class="r"><code>fitted(lm1)</code></pre>
<pre><code>##        1        2        3        4        5        6        7        8 
## 11.83282 17.67453 13.81424 13.29164 15.79802 15.81898 11.43628 12.98896 
##        9       10       11       12       13       14       15       16 
## 15.57430 16.06184 14.97508 14.91121 15.17624 15.38830 18.22633 17.87727 
##       17       18       19       20 
## 11.31583 16.72605 18.49644 12.85313</code></pre>
</div>
</div>
<div id="multiple-lineare-regression" class="section level2">
<h2>Multiple lineare Regression</h2>
<ul>
<li><p>Vorhersage von metrischen Endpunkten bei mehreren unabhÃ¤ngigen
Variablen</p></li>
<li><p>Kontrolle von StÃ¶rvariablen</p></li>
<li>
<p>BerÃ¼cksichtigung von Redundanzen zwischen Merkmalen</p>
<p>z.B. Wenn UVs nicht unabhÃ¤ngig voneinander sind</p>
</li>
</ul>
<div id="modellgleichung" class="section level3">
<h3>Modellgleichung</h3>
<p>In der Stichprobe:</p>
<p><span class="math display">\[Y = b_0 + b_1 \cdot X_1 + b_2 \cdot X_2
+ \dots + b_j \cdot X_j + E\]</span></p>
<p>In der Population:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 \cdot X_1 +
\beta_2 \cdot X_2 + \dots + \beta_j \cdot X_J + \epsilon\]</span></p>
</div>
<div id="bestimmung-der-regressionskoeffizienten-1" class="section level3">
<h3>Bestimmung der Regressionskoeffizienten</h3>
<p>Ãhnlich wie bei einfacher linearer Regression werden die
Koeffizienten so geschÃ¤tzt, dass die Summer der quadrierten Abweichungen
von den modellierten Werten minimal wird:</p>
<p><span class="math display">\[\sum_{m=1}^n{(y_m - \hat{y}_m)^2}
\rightarrow min\]</span> Geometrische Sicht:</p>
<p>Bei zwei unabhÃ¤ngigen Variablen erzeugt das Regressionsmodell eine
Ebene (statt einer Geraden bei einfacher Regression). Die Ebene wird so
platziert, dass der AbstÃ¤nde aller empirischen Messpunkte zur Ebene
minimal werden.</p>
<p>Die Regressionskoeffizienten kÃ¶nnen auch analog zur einfacher
Regression berechnet werden, was aber unÃ¼blich ist. (siehe EGS Kapitel
19.3.3)</p>
<p>Stattdessen erfolgt die Bestimmung bei multipler Regression eher
numerisch.</p>
</div>
<div id="kompensatorisches-modell" class="section level3">
<h3>Kompensatorisches Modell</h3>
<p>Mehrere Kombinationen vom UVs kÃ¶nnen in der multiplen Regression zur
gleichen AusprÃ¤gung der AV fÃ¼hren.</p>
<p>Beispiel:</p>
<ul>
<li><span class="math inline">\(\beta_0 = 10\)</span></li>
<li><span class="math inline">\(\beta_1 = 2\)</span></li>
<li><span class="math inline">\(\beta_2 = 1\)</span></li>
</ul>
<p><span class="math display">\[10 + 2 \cdot 2 + 1 \cdot 0.5 = 10 + 2
\cdot 1 + 1 \cdot 2.5 = 14.5\]</span></p>
<p>FÃ¼r <span class="math inline">\(X_1 = 2; X_2 = 0.5\)</span> sowie fÃ¼r
<span class="math inline">\(X_1 = 1; X_2 = 2.5\)</span> ergibt sich das
gleiche <span class="math inline">\(Y = 14.5\)</span>.</p>
<p>Die UVs kÃ¶nnen also ihre EinflÃ¼sse gegenseitig kompensieren.</p>
</div>
<div id="dummy-kodierung" class="section level3">
<h3>Dummy Kodierung</h3>
<p>Bei UVs, die mehr als zwei Faktorstufen beinhalten, wird jede eine
Referenzkategorie definiert und alle anderen Stufen als
âDummyâ-Variablen kodiert die jeweils AusprÃ¤gungen 0 oder 1 haben.</p>
<div id="schritte-der-dummy-kodieruung" class="section level4">
<h4>Schritte der Dummy-Kodieruung</h4>
<ol style="list-style-type: decimal">
<li>
<p>Referenzkategorie zuweisen (vollkommen willkÃ¼rlich)</p>
<p>Die Faktorstufe der Referenzkategorie hat auf allen Dummy-Variablen
den Wert 0.</p>
</li>
<li>
<p>Allen anderen Kategorien der unabhÃ¤ngigen Faktorvariablen werden
Dummy-Werte zugewiesen, so dass:</p>
<ul>
<li>jede Kategorie in nur einer Dummy-Variablen den Wert 1 hat</li>
<li>jede Dummy-Variable nur fÃ¼r eine Kategorie den Wert 1 hat und sonst
Ã¼berall 0</li>
</ul>
</li>
</ol>
</div>
</div>
<div id="interpretation-von-multiplen-regressionsgewichten" class="section level3">
<h3>Interpretation von multiplen Regressionsgewichten</h3>
<div id="als-regressionsgewicht-einer-bedingten-einfacher-regression." class="section level4">
<h4>Als Regressionsgewicht einer bedingten einfacher Regression.</h4>
<p>Alle UVs bis auf eine werden konstant gehalten.</p>
<p>Nur noch eine UV und ihr Regressionsgewicht haben Einfluss auf <span class="math inline">\(Y\)</span>.</p>
<p>Entspricht dem Modell fÃ¼r eine Subgruppe an Personen, die
hinsichtlich aller UVs bis auf eine identisch sind.</p>
</div>
<div id="als-regressionsgewicht-zweier-regressionsredsiduen" class="section level4">
<h4>Als Regressionsgewicht zweier Regressionsredsiduen</h4>
<p>Es werden zwei Residuen von einfachen Regressionen gebildet:</p>
<ul>
<li>Residuum von <span class="math inline">\(Y(X_2)\)</span> (<span class="math inline">\(Y\)</span> in AbhÃ¤ngigkeit von <span class="math inline">\(X_2\)</span>
</li>
<li>Residuum von <span class="math inline">\(X_1(X_2)\)</span> (<span class="math inline">\(X_1\)</span> in AbhÃ¤ngigkeit von <span class="math inline">\(X_2\)</span>
</li>
</ul>
<p>Diese Residuen werden dann als unabhÃ¤ngige und abhÃ¤ngige Variable in
einer weiteren einfacher Regression verwendet.</p>
<p>Dadurch werden die betrachtete UV und die AV von AbhÃ¤ngigkeiten zu
anderen UVs bereinigt. Das Regressionsgewicht quantifiziert den Einfluss
der betrachteten UV, der nicht bereits durch andere UVs erklÃ¤rt
wird.</p>
</div>
</div>
<div id="inkrementelle-varianzaufklÃ¤rung" class="section level3">
<h3>Inkrementelle VarianzaufklÃ¤rung</h3>
<p>Der Determinationskoeffizient <span class="math inline">\(R^2\)</span> ist wie in der einfacher Regression
ein MaÃ dafÃ¼r, wie prÃ¤zise die Vorhersagen des Modells sind.</p>
<p>Mit zumessender Anzahl UVs wird das Modell prÃ¤ziser:</p>
<p><span class="math display">\[R^2_{Y|X_1} \lt R^2_{Y|X_1,X_2} \lt
R^2_{Y|X_1, X_2, X_3}\]</span></p>
</div>
<div id="punktschÃ¤tzung-der-varianzaufklÃ¤rung" class="section level3">
<h3>PunktschÃ¤tzung der VarianzaufklÃ¤rung</h3>
<p><strong><span class="math inline">\(R^2\)</span> ist kein
erwartungstreuer SchÃ¤tzer der VarianzaufklÃ¤rung in der Population <span class="math inline">\(\rho^2\)</span>.</strong></p>
<p>Beispiel: 100 Stichproben zu je <span class="math inline">\(n
=10\)</span> Messpunkten von drei komplett unabhÃ¤ngigen Variablen <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span> und <span class="math inline">\(Y\)</span>. Alle Variablen sind zufÃ¤llig generiert
und normalverteilt.</p>
<p>Korrelationsplot der ersten 20 Stichproben (200 Messwerte):</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-75-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Es sollte also keine Korrelation zwischen den Variablen geben und
damit auch keine VarianzaufklÃ¤rung. Entsprechend sollte in jeder
Stichprobe <span class="math inline">\(R^2 \approx 0\)</span>
gelten.</p>
<pre class="r"><code>samples %&gt;% group_by(stichprobe) %&gt;% mutate(
  Rsq = summary(lm(Y ~ X1 + X2))$r.squared
) -&gt; samples</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-77-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Durchschnittlicher Determinationskoeffizient, <span class="math inline">\(\overline{R}^2\)</span>:</p>
<pre><code>## [1] 0.2174016</code></pre>
<p>Es muss eine Adjustierung vorgenommen werden, damit <span class="math inline">\(\rho^2\)</span> nicht Ã¼berschÃ¤tzt wird.</p>
<div id="wherry-1-adjustierung" class="section level4">
<h4>Wherry-1-Adjustierung</h4>
<p><span class="math display">\[\hat{\rho}^2 = 1 - \frac{n-1}{n-k-1}
\cdot (1-R^2)\]</span> (<span class="math inline">\(n\)</span>:
StichprobengrÃ¶Ãe, <span class="math inline">\(k\)</span>: Anzahl der
Regressionsgewichte)</p>
<p>Diese wird standardmÃ¤Ãig in R verwendet.</p>
<pre class="r"><code>samples %&gt;% group_by(stichprobe) %&gt;% mutate(
  Rsq_adj = summary(lm(Y ~ X1 + X2))$adj.r.squared
) -&gt; samples</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-80-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Durchschnittlicher adjustierter Determinationskoeffizient, <span class="math inline">\(\overline{R}_{Wherry-1}^2\)</span>:</p>
<pre><code>## [1] -0.006197947</code></pre>
</div>
<div id="adjustierung-nach-olkin-pratt-2017" class="section level4">
<h4>Adjustierung nach Olkin &amp; Pratt (2017)</h4>
<p><span class="math display">\[\hat{\rho}^2 = 1= \frac{n-3}{n-k-1}
\cdot ((1-R^2) + \frac{2}{n-k-1} \cdot (1-R^2))\]</span></p>
<p>In R kann die Olkin-Pratt-Adjustierung mit dem Paket
<code>semEff</code> berechnet werden:</p>
<pre class="r"><code>library(semEff)</code></pre>
<pre><code>## 
## Attaching package: 'semEff'</code></pre>
<pre><code>## The following object is masked from 'package:lme4':
## 
##     getData</code></pre>
<pre class="r"><code># Berechnung ist sehr langsam, daher hier nur fÃ¼r erste Stichprobe
samples %&gt;% filter(stichprobe == 1) %&gt;% mutate(
  Rsq_OP = R2(lm(Y ~ X1 + X2, data = .), adj.type = "olkin-pratt")[2]
) -&gt; samples</code></pre>
<p>Durchschnittlicher adjustierter Determinationskoeffizient, <span class="math inline">\(\overline{R}_{Olkin-Pratt}^2\)</span>:</p>
<pre class="r"><code>mean(samples$Rsq_OP)</code></pre>
<pre><code>## [1] 0</code></pre>
</div>
</div>
<div id="hypothesenprÃ¼fung-mit-multipler-linearer-regression" class="section level3">
<h3>HypothesenprÃ¼fung mit multipler linearer Regression</h3>
<div id="hypothesen-zum-gesamtmodell-globale-hypothesen" class="section level4">
<h4>Hypothesen zum Gesamtmodell, globale Hypothesen</h4>
<p><span class="math display">\[H_0: \beta_1 = \beta_2 = \dots = \beta_k
= 0 \rightarrow H_o: \rho^2 = 0\]</span></p>
<p>Alle Regressionsgewichte sind null, also wird keine Varianz durch die
unabhÃ¤ngigen Variablen aufgeklÃ¤rt.</p>
<p><span class="math display">\[H_1: \beta_j \ne 0 \rightarrow \rho^2
\ne 0\]</span></p>
<p>Mindestens eines der Regressionsgewichte <span class="math inline">\(\beta_j\)</span> ist nicht null, also wird ein
Teil der Varianz aufgeklÃ¤rt.</p>
<p>Verteilung der PrÃ¼fgrÃ¶Ãe unter der Nullhypothese:</p>
<p><span class="math display">\[F = \frac{n-k-1}{k} \cdot
\frac{R^2}{1-R^2} \sim F(df_1 = k, df_2 = n-k-1)\]</span></p>
</div>
<div id="hypothesen-Ã¼ber-einzelne-regressionsgewichte" class="section level4">
<h4>Hypothesen Ã¼ber einzelne Regressionsgewichte</h4>
<p><span class="math display">\[H_0 : \beta_j = 0\]</span></p>
<p>Verteilung der PrÃ¼fgrÃ¶Ãe unter <span class="math inline">\(H_0\)</span>:</p>
<p><span class="math display">\[T =
\frac{\hat{\beta}_j}{\hat{\sigma}_{\beta_j}} \sim Student(df =
n-k-1)\]</span></p>
<p>Das geschÃ¤tzte Regressionsgewicht <span class="math inline">\(\hat\beta_j\)</span> wird am <a href="#standardfehler-der-modellparameter">geschÃ¤tzten
Standardfehler</a> <span class="math inline">\(\hat\sigma_{\beta_j}\)</span> standardisiert und
folgt dann eine Student-T-Verteilung.</p>
</div>
<div id="hypothesen-Ã¼ber-modellvergleiche" class="section level4">
<h4>Hypothesen Ã¼ber Modellvergleiche</h4>
<p>Die âNÃ¼tzlichkeitâ einer oder mehrerer unabhÃ¤ngiger Variablen kann
durch den Vergleich eines uneingeschrÃ¤nkten Modells, welches alle UVs
enthÃ¤lt, mit einem eingeschrÃ¤nkten Modell, in dem eine oder mehrere UV
fehlen, bestimmt werden.</p>
<p>Indem UVs entfernt werden, verschwindet ihre VarianzaufklÃ¤rung im nun
grÃ¶Ãeren Residuum.</p>
<p>Verglichen werden letztendlich die Determinationskoeffizienten der
Modelle <span class="math inline">\(R_u^2\)</span> (uneingeschrÃ¤nkt) und
<span class="math inline">\(R_e^2\)</span> (eingeschrÃ¤nkt).</p>
<p>Verteilung unter der Nullhypothese <span class="math inline">\(H_0:
\rho_u^2 - \rho_y^2 = 0\)</span>:</p>
<p><span class="math display">\[F = \frac{n-k_u-1}{k_u - k_e} \cdot
\frac{R_u^2 - R_e^2}{1-R_u^2} \sim F(df_1 = k_u - k_e, df_2 =
n-k_u-1)\]</span></p>
<p>Sonderfall, wenn nur eine UV entfernt wird:</p>
<p><span class="math display">\[F = (n-k_u-1) \cdot
\frac{R_u^2-R_e^2}{1-R_u^2} \sim F(df_1 = 1, df_2 = n - k_u
-1)\]</span></p>
<p>Dieser F-Wert (fÃ¼r nur eine entfernte UV) entspricht dem quadrierten
T-Wert aus der <a href="#hypothesen-%C3%BCber-einzelne-regressionsgewichte">HypothesenprÃ¼fung
Ã¼ber einzelne Regressionsgewichte</a>. Beide AnsÃ¤tze sind
Ã¤quivalent.</p>
</div>
</div>
<div id="modellvergleiche-in-r" class="section level3">
<h3>Modellvergleiche in R</h3>
<p>Beispiel:</p>
<ul>
<li>Stichprobe mit <span class="math inline">\(n=20\)</span>
</li>
<li>2 unabhÃ¤ngige, normalverteilte Variablen</li>
<li>
<span class="math inline">\(Y\)</span> korreliert mit <span class="math inline">\(X_1\)</span> leicht positiv und mit <span class="math inline">\(X_2\)</span> leicht negativ</li>
<li>im Datensatz ist ein simulierter Interaktionseffekt vorhanden</li>
<li>normalverteiltes Residuum</li>
</ul>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-84-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Vergleich von uneingeschrÃ¤nktem Modell (mit Interaktion) und
eingeschrÃ¤nktem (ohne Interaktion):</p>
<pre class="r"><code>lm_u &lt;- lm(Y ~ X1 * X2, samples)
lm_e &lt;- lm(Y ~ X1 + X2, samples)

anova(lm_u, lm_e)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Y ~ X1 * X2
## Model 2: Y ~ X1 + X2
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    196 3165.1                                  
## 2    197 3395.8 -1   -230.69 14.286 0.0002084 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<p>Das uneingeschrÃ¤nkte Modell klÃ¤rt signifikant mehr Varianz auf als
das eingeschrÃ¤nkte. Es gibt also einen Interaktionseffekt.</p>
<p>Vergleich der Determinationskoeffizienten:</p>
<pre class="r"><code>R_u &lt;- summary(lm_u)$adj.r.squared
R_e &lt;- summary(lm_e)$adj.r.squared

dR &lt;- R_u - R_e

dR</code></pre>
<pre><code>## [1] 0.0442245</code></pre>
<div id="likelihood-quotienten-test" class="section level4">
<h4>Likelihood-Quotienten-Test</h4>
<p>Wilksâ <span class="math inline">\(\Lambda\)</span>: Quotient der
Likelihoods der empirischen Daten unter dem eingeschrÃ¤nkten und dem
uneingeschrÃ¤nkten Modell.</p>
<p><span class="math display">\[\Lambda =
\frac{Lik(Y_e)}{Lik(Y_u)}\]</span></p>
<p>PrÃ¼fgrÃ¶Ãe des Likelihood-Quotienten-Tests:</p>
<p><span class="math display">\[-2 \cdot log(\Lambda) = -2 \cdot
log(Lik(Y_e) + 2 \cdot log(Lik(Y_u))\]</span></p>
<p>Unter der Nullhypothese <span class="math inline">\(H_0: \rho^2_u -
\rho^2_e = 0\)</span> gilt asymptotisch (also bei ausreichend groÃen
Stichproben):</p>
<p><span class="math display">\[-2 \cdot log(\Lambda) \sim \chi^2(df =
k_u - k_e)\]</span></p>
</div>
</div>
<div id="interaktionseffekte-bei-mutlipler-linearer-regression" class="section level3">
<h3>Interaktionseffekte bei mutlipler linearer Regression</h3>
<p><span class="math display">\[Y = \beta_0 + \beta_1 \cdot X_1 +
\beta_2 \cdot X_2 + \beta_3 \cdot X_1 \cdot X_2 + \epsilon\]</span></p>
<p><span class="math inline">\(\beta_3 \cdot X_1 \cdot X_2\)</span> ist
der Interaktionsterm. <span class="math inline">\(\beta_3\)</span> ist
das Regressionsgewicht des Interaktionseffektes.</p>
<p>Durch Modellvergleiche mit eingeschrÃ¤nkten Modellen, die den
Interaktionsterm nicht enthalten, kann bestimmt werden, welcher Anteil
der Varianz durch die Interaktion aufgeklÃ¤rt wird.</p>
<p>Beispielhypothese:</p>
<p><span class="math display">\[Y_u = \beta_0 + \beta_1 \cdot X_1 +
\beta_2 \cdot X_2 + \beta_3 \cdot X_1 \cdot X_2 + \epsilon\]</span>
<span class="math display">\[Y_e = \beta_0 + \beta_1 \cdot X_1 + \beta_2
\cdot X_2 + \epsilon\]</span> <span class="math inline">\(H_0: \rho^2_u
- \rho^2_e = 0\)</span>, die Interaktion von <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span> klÃ¤rt keine zusÃ¤tzliche Varianz
auf.</p>
</div>
</div>
<div id="annahmen-des-allgemeinen-linearen-modells" class="section level2">
<h2>Annahmen des allgemeinen linearen Modells</h2>
<ul>
<li>Messfehlerfreiheit der UVs</li>
<li>korrekte Spezifikation des Modells (LinearitÃ¤t)</li>
<li>HomoskedastizitÃ¤t</li>
<li>UnabhÃ¤ngigkeit der Residuen</li>
<li>Normalverteilung der Residuen</li>
</ul>
<div id="korrekte-spezifikation-linearitÃ¤t" class="section level3">
<h3>Korrekte Spezifikation, LinearitÃ¤t</h3>
<p><strong>Underfitting</strong>: relevante UVs fehlen im Modell</p>
<p><strong>Overfitting</strong>: irrelevante UVs, die keine Varianz
aufklÃ¤ren, sind im Modell enthalten.</p>
<p>Form der Abbilddung der AV auf die UVs muss korrekt sein.</p>
<p>Bei Verletzung der Annahmen:</p>
<ul>
<li>verzerrte SchÃ¤tzer der Regressionsgewichte</li>
<li>erhÃ¶hter Prognosefehler</li>
<li>verringerte TeststÃ¤rke</li>
<li>falsche Schlussfolgerungen</li>
</ul>
<div id="prÃ¼fung-der-linearitÃ¤t" class="section level4">
<h4>PrÃ¼fung der LinearitÃ¤t</h4>
<p>Plot der Residuen gegenÃ¼ber den vorhergesagten (fitted) Werten</p>
<p><strong>EingeschrÃ¤nktes Modell:</strong></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-87-1.png" width="768" style="display: block; margin: auto;"></p>
<p><strong>UneingeschrÃ¤nktes Modell:</strong></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-88-1.png" width="768" style="display: block; margin: auto;"></p>
<p><strong>Die durchschnittlichen Residuen aller Kombinationen der UVs
sollten einer Geraden mit Steigung 0 folgen, wenn LinearitÃ¤t gegeben
ist.</strong></p>
</div>
</div>
<div id="prÃ¼fung-der-homoskedastizitÃ¤t" class="section level3">
<h3>PrÃ¼fung der HomoskedastizitÃ¤t</h3>
<div id="breusch-pagan-test-in-r" class="section level4">
<h4>Breusch-Pagan-Test in R</h4>
<p>(mit Paket <code>lmtest</code>)</p>
<pre class="r"><code>library(lmtest)</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: 'zoo'</code></pre>
<pre><code>## The following objects are masked from 'package:base':
## 
##     as.Date, as.Date.numeric</code></pre>
<pre class="r"><code>bptest(lm_u)</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  lm_u
## BP = 3.351, df = 3, p-value = 0.3406</code></pre>
<p>Wenn <span class="math inline">\(p \ge 0.05\)</span>, dann kann die
Nullhypothese, dass HomoskedastizitÃ¤t vorliegt, akzeptiert werden.</p>
<p><strong>Der Breusch-Pagan-Test ist auch sensitiv fÃ¼r eine Verletzung
der UnabhÃ¤ngigkeit der Residuen.</strong></p>
</div>
<div id="visuelle-prÃ¼fung-der-heteroskedastizitÃ¤t" class="section level4">
<h4>Visuelle PrÃ¼fung der HeteroskedastizitÃ¤t</h4>
<p>Plot der Residuen gegenÃ¼ber den vorhergesagten (fitted) Werten.</p>
<pre class="r"><code>samples %&gt;%
  ggplot(aes(x = fit_u, y = res_u)) +
  geom_point() +
  labs(x = "Vorhersage", y = "Residuum") +
  theme_custom</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-90-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Es sind keine offensichtlichen Unterschieden in der Varianz der
Residuen erkennbar. Damit liegt vermutlich HomoskedastizitÃ¤t vor, sollte
aber dennoch genau getestet werden.</p>
</div>
</div>
<div id="normalverteilung-der-residuen" class="section level3">
<h3>Normalverteilung der Residuen</h3>
<div id="shapiro-wilk-test" class="section level4">
<h4>Shapiro-Wilk-Test</h4>
<ul>
<li>testet beliebige Werte auf Normalverteilung</li>
</ul>
<pre class="r"><code>shapiro.test(samples$res_u)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  samples$res_u
## W = 0.99108, p-value = 0.2553</code></pre>
<p>Wenn <span class="math inline">\(p \ge 0.05\)</span>, dann kann
Normalverteilung der Residuen angenommen werden.</p>
</div>
<div id="visuelle-prÃ¼fung-der-normalverteilung" class="section level4">
<h4>Visuelle PrÃ¼fung der Normalverteilung</h4>
<p><strong>Histogram der Residuen</strong></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-92-1.png" width="768" style="display: block; margin: auto;"></p>
<p><strong>Q-Q-Plot, Quantil-Quantil-Diagramm</strong></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-93-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Wenn die Residuumswerte nah an der theoretischen Normalverteilung
(entlang der diagonalen Geraden) liegen, liegt vermutlich
Normalverteilung vor, sollte aber noch genau getestet werden.</p>
</div>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->



  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->


<div class="post-nav">
  <span>
    
  </span>
  <span>
    
  </span>
</div>
  </section>


    </main>
    


<footer class="background" style="--image: url('/images/lines-21.png')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    
  </div>

  <div>
    Â© 2024
    PHB
    Â  | Â  Erstellt mit
    <a href="https://github.com/greenelab/lab-website-template">
      Lab Website Template
    </a>
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
