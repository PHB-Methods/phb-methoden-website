<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  



























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>B.Sc. Psychologie Statisik II | Psychologische Methodenlehre | PHB</title>

<link rel="icon" href="">

<meta name="title" content="B.Sc. Psychologie Statisik II | Psychologische Methodenlehre | PHB">
<meta name="description" content="Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin">

<meta property="og:title" content="B.Sc. Psychologie Statisik II | Psychologische Methodenlehre | PHB">
<meta property="og:site_title" content="PHB">
<meta property="og:description" content="Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin">
<meta property="og:url" content="http://methodenlehre.phb.de">
<meta property="og:image" content="/images/share.jpg">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="B.Sc. Psychologie Statisik II">
<meta property="twitter:description" content="Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin">
<meta property="twitter:url" content="http://methodenlehre.phb.de">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/images/share.jpg">


  <meta name="author" content="Esther Weidauer">
  <meta property="og:type" content="article">
  <meta property="og:updated_time" content="2024-10-01T10:57:29+00:00">
  <meta property="article:published_time" content="">
  <meta property="article:modified_time" content="2024-10-01T10:57:29+00:00">
  <meta name="revised" content="2024-10-01T10:57:29+00:00">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "BlogPosting",
      "author": { "@type": "Person", "name": "B.Sc. Psychologie Statisik II" },
      "datePublished": "",
      "dateModified": "2024-10-01T10:57:29+00:00",
    
    "name": "B.Sc. Psychologie Statisik II",
    "description": "Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin",
    "headline": "B.Sc. Psychologie Statisik II",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "" }
    },
    "url": "http://methodenlehre.phb.de"
  }
</script>

<link rel="alternate" type="application/rss+xml" href="http://methodenlehre.phb.de/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet" media="none" onload="this.removeAttribute('media'); this.onload = null;">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/_styles/all.css" rel="stylesheet">
  

  
    <link href="/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/_styles/background.css" rel="stylesheet">
  

  
    <link href="/_styles/body.css" rel="stylesheet">
  

  
    <link href="/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/_styles/button.css" rel="stylesheet">
  

  
    <link href="/_styles/card.css" rel="stylesheet">
  

  
    <link href="/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/_styles/code.css" rel="stylesheet">
  

  
    <link href="/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/_styles/float.css" rel="stylesheet">
  

  
    <link href="/_styles/font.css" rel="stylesheet">
  

  
    <link href="/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/_styles/form.css" rel="stylesheet">
  

  
    <link href="/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/_styles/header.css" rel="stylesheet">
  

  
    <link href="/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/_styles/image.css" rel="stylesheet">
  

  
    <link href="/_styles/link.css" rel="stylesheet">
  

  
    <link href="/_styles/list.css" rel="stylesheet">
  

  
    <link href="/_styles/main.css" rel="stylesheet">
  

  
    <link href="/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/_styles/section.css" rel="stylesheet">
  

  
    <link href="/_styles/table.css" rel="stylesheet">
  

  
    <link href="/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/_scripts/anchors.js"></script>

  <script src="/_scripts/dark-mode.js"></script>

  <script src="/_scripts/fetch-tags.js"></script>

  <script src="/_scripts/search.js"></script>

  <script src="/_scripts/site-search.js"></script>

  <script src="/_scripts/table-wrap.js"></script>

  <script src="/_scripts/tooltip.js"></script>


<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

  <body>
    







<header class="background" style="--image: url('/images/lines-7.png')" data-dark="true">
  <a href="/" class="home">
    
      <span class="logo">
        
          <img src="/images/logo.png" alt="logo">
        
      </span>
    
    
      <span class="title-text" data-tooltip="Home">
        
          <span class="title">PHB</span>
        
        
          <span class="subtitle">Psychologische Methodenlehre</span>
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/team/" data-tooltip="Unser Team">
          Team
        </a>
      
    
      
        <a href="/lehre/" data-tooltip="Methodenausbildung">
          Lehre
        </a>
      
    
      
        <a href="/beratung/" data-tooltip="Beratung zu Methodenfragen">
          Beratung
        </a>
      
    
      
        <a href="/forschung/" data-tooltip="Forschungsprojekte">
          Forschung
        </a>
      
    
      
        <a href="/aktuelles/" data-tooltip="Neuigkeiten und Ankündigungen">
          Aktuelles
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - filter out blank sections
-->






  
  
  

  <section class="background" data-size="1">
    <!--
  background: ;
  dark: ;
  size: 1;
-->


<h1 class="center">B.Sc. Psychologie Statisik II</h1>

<div class="post-info">
  
    
    
      <span data-tooltip="Author">
        <i class="icon fa-solid fa-feather-pointed"></i>
        <span>Esther Weidauer</span>
      </span>
    
  

  
  

  

  
    <span data-tooltip="Last updated on">
      <i class="icon fa-solid fa-clock-rotate-left"></i>
      <span>October 01, 2024</span>
    </span>
  
</div>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->









<div id="TOC">
<ul>
<li><a href="#einleitung" id="toc-einleitung">Einleitung</a></li>
<li>
<a href="#stichprobenkennwerte-verteilung" id="toc-stichprobenkennwerte-verteilung">Stichprobenkennwerte-Verteilung</a>
<ul>
<li><a href="#beispiel-mittelwert" id="toc-beispiel-mittelwert">Beispiel: Mittelwert</a></li>
<li><a href="#standardfehler-des-mittelwertes" id="toc-standardfehler-des-mittelwertes">Standardfehler des
Mittelwertes</a></li>
<li><a href="#berechnung-des-standardfehlers-des-mittelwertes" id="toc-berechnung-des-standardfehlers-des-mittelwertes">Berechnung des
Standardfehlers des Mittelwertes</a></li>
<li><a href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes" id="toc-schätzung-des-standardfehlers-des-mittelwertes">Schätzung des
Standardfehlers des Mittelwertes</a></li>
<li><a href="#zentraler-grenzwertsatz" id="toc-zentraler-grenzwertsatz">Zentraler Grenzwertsatz</a></li>
</ul>
</li>
<li>
<a href="#punktsch%C3%A4tzung-von-populationsparametern" id="toc-punktschätzung-von-populationsparametern">Punktschätzung von
Populationsparametern</a>
<ul>
<li><a href="#g%C3%BCtekriterien-f%C3%BCr-parametersch%C3%A4tzung" id="toc-gütekriterien-für-parameterschätzung">Gütekriterien für
Parameterschätzung</a></li>
<li><a href="#punktsch%C3%A4tzung-des-mittelwertes" id="toc-punktschätzung-des-mittelwertes">Punktschätzung des
Mittelwertes</a></li>
<li><a href="#punktsch%C3%A4tzung-der-varianz" id="toc-punktschätzung-der-varianz">Punktschätzung der Varianz</a></li>
</ul>
</li>
<li>
<a href="#intervallsch%C3%A4tzung-von-populationsparametern" id="toc-intervallschätzung-von-populationsparametern">Intervallschätzung
von Populationsparametern</a>
<ul>
<li>
<a href="#konfidenzintervall-des-mittelwertes" id="toc-konfidenzintervall-des-mittelwertes">Konfidenzintervall des
Mittelwertes</a>
<ul>
<li><a href="#konfidenzintervall-pro-stichprobe" id="toc-konfidenzintervall-pro-stichprobe">Konfidenzintervall pro
Stichprobe</a></li>
</ul>
</li>
<li><a href="#sch%C3%A4tzung-des-konfidenzintervalls-des-mittelwertes" id="toc-schätzung-des-konfidenzintervalls-des-mittelwertes">Schätzung
des Konfidenzintervalls des Mittelwertes</a></li>
<li><a href="#konfidenzintervall-abg%C3%A4ngig-von-stichprobengr%C3%B6%C3%9Fe" id="toc-konfidenzintervall-abgängig-von-stichprobengröße">Konfidenzintervall
abgängig von Stichprobengröße</a></li>
</ul>
</li>
<li>
<a href="#statistische-hypothesenpr%C3%BCfung" id="toc-statistische-hypothesenprüfung">Statistische
Hypothesenprüfung</a>
<ul>
<li>
<a href="#signifikanztests" id="toc-signifikanztests">Signifikanztests</a>
<ul>
<li><a href="#einseitiger-signifikanztest" id="toc-einseitiger-signifikanztest">Einseitiger
Signifikanztest</a></li>
<li><a href="#zweiseitiger-signifikanztest" id="toc-zweiseitiger-signifikanztest">Zweiseitiger
Signifikanztest</a></li>
<li><a href="#standardisierte-pr%C3%BCfgr%C3%B6%C3%9Fen" id="toc-standardisierte-prüfgrößen">Standardisierte Prüfgrößen</a></li>
<li><a href="#signifikanztest-mit-empirischen-daten" id="toc-signifikanztest-mit-empirischen-daten">Signifikanztest mit
empirischen Daten</a></li>
</ul>
</li>
<li>
<a href="#hypothesentests" id="toc-hypothesentests">Hypothesentests</a>
<ul>
<li><a href="#standardisierter-effekt-cohens-delta" id="toc-standardisierter-effekt-cohens-delta">Standardisierter Effekt:
Cohen’s <span class="math inline">\(\delta\)</span></a></li>
<li><a href="#konfidenzintervalle-f%C3%BCr-cohens-delta" id="toc-konfidenzintervalle-für-cohens-delta">Konfidenzintervalle für
Cohen’s <span class="math inline">\(\delta\)</span></a></li>
<li><a href="#einstichproben-gauss-test" id="toc-einstichproben-gauss-test">Einstichproben-Gauss-Test</a></li>
<li><a href="#einstichproben-t-test" id="toc-einstichproben-t-test">Einstichproben T-Test</a></li>
<li><a href="#einstichproben-t-test-f%C3%BCr-abh%C3%A4ngige-beobachtungen" id="toc-einstichproben-t-test-für-abhängige-beobachtungen">Einstichproben
T-Test für abhängige Beobachtungen</a></li>
<li><a href="#einstichproben-binomialtest" id="toc-einstichproben-binomialtest">Einstichproben
Binomialtest</a></li>
<li><a href="#zweistichproben-t-test" id="toc-zweistichproben-t-test">Zweistichproben T-Test</a></li>
</ul>
</li>
<li>
<a href="#power-und-stichprobenplanung" id="toc-power-und-stichprobenplanung">Power und Stichprobenplanung</a>
<ul>
<li><a href="#stichprobenplanung-in-r" id="toc-stichprobenplanung-in-r">Stichprobenplanung in R</a></li>
</ul>
</li>
<li>
<a href="#tests-f%C3%BCr-kategoriale-merkmale" id="toc-tests-für-kategoriale-merkmale">Tests für Kategoriale
Merkmale</a>
<ul>
<li><a href="#chi2-statistik" id="toc-chi2-statistik"><span class="math inline">\(\chi^2\)</span>-Statistik</a></li>
<li><a href="#cramers-v" id="toc-cramers-v">Cramer’s <span class="math inline">\(V\)</span></a></li>
<li><a href="#chi2-test" id="toc-chi2-test"><span class="math inline">\(\chi^2\)</span>-Test</a></li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#multiplizit%C3%A4t" id="toc-multiplizität">Multiplizität</a>
<ul>
<li><a href="#bonferroni-korrektur" id="toc-bonferroni-korrektur">Bonferroni-Korrektur</a></li>
<li><a href="#holm-bonferroni-korrektur" id="toc-holm-bonferroni-korrektur">Holm-Bonferroni-Korrektur</a></li>
<li><a href="#fallback-prozedur" id="toc-fallback-prozedur">Fallback-Prozedur</a></li>
</ul>
</li>
<li>
<a href="#varianzanalyse-anova" id="toc-varianzanalyse-anova">Varianzanalyse (ANOVA)</a>
<ul>
<li><a href="#voraussetzungen" id="toc-voraussetzungen">Voraussetzungen</a></li>
<li>
<a href="#einfaktorielle-varianzanalyse" id="toc-einfaktorielle-varianzanalyse">Einfaktorielle Varianzanalyse</a>
<ul>
<li><a href="#messwertezerlegung" id="toc-messwertezerlegung">Messwertezerlegung</a></li>
<li><a href="#quadratsummenzerlegung" id="toc-quadratsummenzerlegung">Quadratsummenzerlegung</a></li>
<li><a href="#effektgr%C3%B6%C3%9Fensch%C3%A4tzer-hateta2" id="toc-effektgrößenschätzer-hateta2">Effektgrößenschätzer <span class="math inline">\(\hat{\eta}^2\)</span></a></li>
<li><a href="#effektgr%C3%B6%C3%9Fensch%C3%A4tzer-hatomega2" id="toc-effektgrößenschätzer-hatomega2">Effektgrößenschätzer <span class="math inline">\(\hat{\omega}^2\)</span></a></li>
<li><a href="#effektgr%C3%B6%C3%9Fe-phi2-signal-rausch-verh%C3%A4ltnis" id="toc-effektgröße-phi2-signal-rausch-verhältnis">Effektgröße <span class="math inline">\(\phi^2\)</span>, Signal-Rausch-Verhältnis</a></li>
<li><a href="#effektgr%C3%B6%C3%9Fe-phi" id="toc-effektgröße-phi">Effektgröße
<span class="math inline">\(\phi\)</span></a></li>
<li><a href="#effektgr%C3%B6%C3%9Fe-lambda" id="toc-effektgröße-lambda">Effektgröße <span class="math inline">\(\lambda\)</span></a></li>
<li><a href="#beziehungen-zwischen-effektgr%C3%B6%C3%9Fensch%C3%A4tzern" id="toc-beziehungen-zwischen-effektgrößenschätzern">Beziehungen zwischen
Effektgrößenschätzern</a></li>
<li><a href="#konfidenzintervalle-der-effektgr%C3%B6%C3%9Fen" id="toc-konfidenzintervalle-der-effektgrößen">Konfidenzintervalle der
Effektgrößen</a></li>
<li><a href="#sch%C3%A4tzung-der-populationsparameter" id="toc-schätzung-der-populationsparameter">Schätzung der
Populationsparameter</a></li>
</ul>
</li>
<li>
<a href="#hypothesenpr%C3%BCfung-in-der-varianzanalyse" id="toc-hypothesenprüfung-in-der-varianzanalyse">Hypothesenprüfung in
der Varianzanalyse</a>
<ul>
<li><a href="#f-test" id="toc-f-test">F-Test</a></li>
<li><a href="#automatische-durchf%C3%BChrung-in-r" id="toc-automatische-durchführung-in-r">Automatische Durchführung in
R</a></li>
</ul>
</li>
<li>
<a href="#zweifaktorielle-varianzanalyze" id="toc-zweifaktorielle-varianzanalyze">Zweifaktorielle
Varianzanalyze</a>
<ul>
<li><a href="#nicht-partiielles-effektst%C3%A4rkenma%C3%9F-hateta2" id="toc-nicht-partiielles-effektstärkenmaß-hateta2">Nicht-partiielles
Effektstärkenmaß: <span class="math inline">\(\hat{\eta}^2\)</span></a></li>
<li><a href="#partielles-effektgr%C3%B6%C3%9Fenma%C3%9F-hateta_p2" id="toc-partielles-effektgrößenmaß-hateta_p2">Partielles Effektgrößenmaß
<span class="math inline">\(\hat{\eta}_p^2\)</span></a></li>
<li><a href="#sch%C3%A4tzung-der-haupteffekte" id="toc-schätzung-der-haupteffekte">Schätzung der Haupteffekte</a></li>
<li><a href="#sch%C3%A4tzung-des-residuums" id="toc-schätzung-des-residuums">Schätzung des Residuums</a></li>
<li><a href="#sch%C3%A4tzung-der-populationsresidualvarianz" id="toc-schätzung-der-populationsresidualvarianz">Schätzung der
Populationsresidualvarianz</a></li>
<li><a href="#hypothesenpr%C3%BCfung-bei-zweifaktorieller-varianzanalyse" id="toc-hypothesenprüfung-bei-zweifaktorieller-varianzanalyse">Hypothesenprüfung
bei zweifaktorieller Varianzanalyse</a></li>
</ul>
</li>
<li><a href="#varianzanalyse-mit-messwiederholung" id="toc-varianzanalyse-mit-messwiederholung">Varianzanalyse mit
Messwiederholung</a></li>
<li><a href="#populationsmodell-der-varianzanalyse" id="toc-populationsmodell-der-varianzanalyse">Populationsmodell der
Varianzanalyse</a></li>
</ul>
</li>
<li>
<a href="#allgemeines-lineares-modell" id="toc-allgemeines-lineares-modell">Allgemeines Lineares Modell</a>
<ul>
<li>
<a href="#einfache-lineare-regression" id="toc-einfache-lineare-regression">Einfache lineare Regression</a>
<ul>
<li><a href="#bestimmung-der-regressionskoeffizienten" id="toc-bestimmung-der-regressionskoeffizienten">Bestimmung der
Regressionskoeffizienten</a></li>
<li><a href="#standardfehler-der-modellparameter" id="toc-standardfehler-der-modellparameter">Standardfehler der
Modellparameter</a></li>
<li><a href="#alternative-wege-zur-bestimmung-der-regressionskoeffizienten" id="toc-alternative-wege-zur-bestimmung-der-regressionskoeffizienten">Alternative
Wege zur Bestimmung der Regressionskoeffizienten</a></li>
<li><a href="#hypothesenpr%C3%BCfung-bei-einfacher-linearer-regression" id="toc-hypothesenprüfung-bei-einfacher-linearer-regression">Hypothesenprüfung
bei einfacher linearer Regression</a></li>
<li><a href="#konfidenzintervalle-f%C3%BCr-regressionskoeffizienten" id="toc-konfidenzintervalle-für-regressionskoeffizienten">Konfidenzintervalle
für Regressionskoeffizienten</a></li>
<li><a href="#einfache-lineare-regression-in-r" id="toc-einfache-lineare-regression-in-r">Einfache lineare Regression in
R</a></li>
</ul>
</li>
<li>
<a href="#multiple-lineare-regression" id="toc-multiple-lineare-regression">Multiple lineare Regression</a>
<ul>
<li><a href="#modellgleichung" id="toc-modellgleichung">Modellgleichung</a></li>
<li><a href="#bestimmung-der-regressionskoeffizienten-1" id="toc-bestimmung-der-regressionskoeffizienten-1">Bestimmung der
Regressionskoeffizienten</a></li>
<li><a href="#kompensatorisches-modell" id="toc-kompensatorisches-modell">Kompensatorisches Modell</a></li>
<li><a href="#dummy-kodierung" id="toc-dummy-kodierung">Dummy
Kodierung</a></li>
<li><a href="#interpretation-von-multiplen-regressionsgewichten" id="toc-interpretation-von-multiplen-regressionsgewichten">Interpretation
von multiplen Regressionsgewichten</a></li>
<li><a href="#inkrementelle-varianzaufkl%C3%A4rung" id="toc-inkrementelle-varianzaufklärung">Inkrementelle
Varianzaufklärung</a></li>
<li><a href="#punktsch%C3%A4tzung-der-varianzaufkl%C3%A4rung" id="toc-punktschätzung-der-varianzaufklärung">Punktschätzung der
Varianzaufklärung</a></li>
<li><a href="#hypothesenpr%C3%BCfung-mit-multipler-linearer-regression" id="toc-hypothesenprüfung-mit-multipler-linearer-regression">Hypothesenprüfung
mit multipler linearer Regression</a></li>
<li><a href="#modellvergleiche-in-r" id="toc-modellvergleiche-in-r">Modellvergleiche in R</a></li>
<li><a href="#interaktionseffekte-bei-mutlipler-linearer-regression" id="toc-interaktionseffekte-bei-mutlipler-linearer-regression">Interaktionseffekte
bei mutlipler linearer Regression</a></li>
</ul>
</li>
<li>
<a href="#annahmen-des-allgemeinen-linearen-modells" id="toc-annahmen-des-allgemeinen-linearen-modells">Annahmen des
allgemeinen linearen Modells</a>
<ul>
<li><a href="#korrekte-spezifikation-linearit%C3%A4t" id="toc-korrekte-spezifikation-linearität">Korrekte Spezifikation,
Linearität</a></li>
<li><a href="#pr%C3%BCfung-der-homoskedastizit%C3%A4t" id="toc-prüfung-der-homoskedastizität">Prüfung der
Homoskedastizität</a></li>
<li><a href="#normalverteilung-der-residuen" id="toc-normalverteilung-der-residuen">Normalverteilung der
Residuen</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>

<div id="einleitung" class="section level1">
<h1>Einleitung</h1>
<p>Statistik II umfasst hauptsächlich Inferenzstatistik und
hypothesen-prüfende Tests sowie Verfahren zur Behandlung von
Fehlerwahrscheinlichkeiten in wissenschaftlichen Studien.</p>
<p>Diese Zusammenfassung basiert auf der Vorlesung Statistik II im
Sommersemester 2024 an der PHB bei Professor Robert Miller, sowie dem
Lehrbuch “Statistik und Forschungsmethoden” von Eid, Gollwitzer und
Schmitt (5.Auflage).</p>
</div>
<div id="stichprobenkennwerte-verteilung" class="section level1">
<h1>Stichprobenkennwerte-Verteilung</h1>
<div id="beispiel-mittelwert" class="section level2">
<h2>Beispiel: Mittelwert</h2>
<p><span class="math display">\[\overline{x} = \frac{1}{k}
\sum_{i=1}^{k}\overline{x}_i\]</span></p>
<ul>
<li>
<span class="math inline">\(k\)</span>: Anzahl gezogener
Stichproben</li>
<li>
<span class="math inline">\(\overline{x}_{i}\)</span>: Mittelwerte
innerhalb der Stichproben</li>
<li>
<span class="math inline">\(\overline{x}\)</span>:
durchschnittlicher Mittelwerte der Stichproben</li>
</ul>
<p>Erwartungswert des durchschnittlichen Mittelwertes der Stichproben
ist der Mittelwert der Population:</p>
<p><span class="math display">\[E(\overline{x}) = \mu\]</span></p>
</div>
<div id="standardfehler-des-mittelwertes" class="section level2">
<h2>Standardfehler des Mittelwertes</h2>
<p>Die Standardabweichung der Stichprobenkennwert-Verteilung wird
<em>Standardfehler</em> genannt, z.B. Standardfehler des Mittelwertes:
<span class="math inline">\(\sigma_{\overline{x}}\)</span></p>
</div>
<div id="berechnung-des-standardfehlers-des-mittelwertes" class="section level2">
<h2>Berechnung des Standardfehlers des Mittelwertes</h2>
<ul>
<li>wird anhand der Standardabweichung der Population <span class="math inline">\(\sigma\)</span> berechnet</li>
</ul>
<p>Bei <span class="math inline">\(n &lt; 5\%\)</span> der
Populationsgröße N:</p>
<p><span class="math display">\[\sigma_{\overline{x}} =
\frac{\sigma}{\sqrt{n}}\]</span></p>
<p>Bei <span class="math inline">\(n \ge 5\%\)</span> der
Populationsgröße N wird die “Finite Population”-Korrektur
eingeführt:</p>
<p><span class="math display">\[\sigma_{\overline{x}} =
\frac{\sigma}{\sqrt{n}} \cdot
\color{red}{\sqrt{\frac{N-n}{N-1}}}\]</span></p>
<p>Je größer die einzelnen Stichprobengrößen, umso geringer wird der
Standardfehler:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-1-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
<div id="schätzung-des-standardfehlers-des-mittelwertes" class="section level2">
<h2>Schätzung des Standardfehlers des Mittelwertes</h2>
<p>Wenn die Varianz der Population <span class="math inline">\(\sigma^2\)</span> nicht bekannt ist, wird er
geschätzte Standardfehler <span class="math inline">\(\hat{\sigma}_{\overline{x}}\)</span> aus der
empirischen Varianz <span class="math inline">\(s^{2*}\)</span>
bestimmt:</p>
<p><span class="math display">\[\hat{\sigma}_{\overline{x}} =
\sqrt{\frac{\hat\sigma^2_x}{n}} = \sqrt{\frac{s^{2*}_x}{n - 1}}\]</span>
Wichtig: die empirische Varianz <span class="math inline">\(s^{2*}\)</span> ist <strong>nicht</strong> gleich
der Stichprobenvarianz <span class="math inline">\(s^2\)</span>, siehe
<a href="#punktsch%C3%A4tzung-der-varianz">Punktschätzung der Varianz</a>.
Die Stichprobenvarianz <span class="math inline">\(s^2\)</span> enthält
bereits die Bessel-Korrektur <span class="math inline">\(n-1\)</span>
und muss entsprechend nicht nochmals in der Berechnung des geschätzten
Standardfehlers korrigiert werden:</p>
<p><span class="math display">\[\hat{\sigma}_{\overline{x}} =
\sqrt{\frac{s^2_x}{n}}\]</span></p>
<p>Die Stichprobenkennwerte-Verteilung folgt dann <strong>nicht
mehr</strong> der Normalverteilung sondern nach Standardisierung einer
Student-t-Verteilung mit <span class="math inline">\(n - 1\)</span>
Freiheitsgraden:</p>
<p><span class="math display">\[\frac{\overline{x} -
\mu}{\hat{\sigma}_{\overline{x}}} \sim Student(df = n -1)\]</span></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-2-1.png" width="768" style="display: block; margin: auto;"></p>
<ul>
<li>
<span class="math inline">\(Normal(\mu = 0, \sigma = 1)\)</span>
(blaue Kurve): Verteilung in der Population</li>
<li>
<span class="math inline">\(Student(df = n-1)\)</span> (grüne
Kurve): geschätzte Populationsverteilung</li>
</ul>
<p>Mit steigendem <span class="math inline">\(n\)</span> nähern sich die
beiden Verteilungen immer weiter an.</p>
</div>
<div id="zentraler-grenzwertsatz" class="section level2">
<h2>Zentraler Grenzwertsatz</h2>
<p>Die Stichprobenkennwerteverteilung der Mittelwerte nähert sich mit
zunehmender Stichprobengröße der Normalverteilung an, unabhängig davon,
wie das Merkmal in der Population verteilt ist.</p>
<p>1 Sample (<span class="math inline">\(n = 1000\)</span>) mit
uniformer Verteilung:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Mittelwerteverteilung von <span class="math inline">\(k =
500\)</span> Samples mit je <span class="math inline">\(n =
1000\)</span>:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Verteilung nähert sich sichtbar der Normalverteilung an.</p>
</div>
</div>
<div id="punktschätzung-von-populationsparametern" class="section level1">
<h1>Punktschätzung von Populationsparametern</h1>
<p>Populationsparameter sind meist unbekannt, daher werden sie auf Basis
der Statistiken (Verteilungskennwerte) einer einzelnen Stichprobe
geschätzt. (“Punktschätzung”, weil ein Punktwert und kein Intervall
geschätzt wird)</p>
<p><strong>Populationsparameter</strong>: Kennwert einer theoretisch
unendlich großen Population</p>
<p><strong>Stichprobenstatistik</strong>: Kennwert einer Verteilung
tatsächlicher, empirischer Stichproben</p>
<p><strong>Schätzer</strong>: Inferenz von der Stichprobe auf die
Population</p>
<table>
<colgroup>
<col width="30%">
<col width="17%">
<col width="27%">
<col width="24%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th align="right">Population</th>
<th align="right">Stichprobenstatistik</th>
<th align="right">Schätzer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Arithmetisches Mittel</td>
<td align="right"><span class="math inline">\(\mu\)</span></td>
<td align="right"><span class="math inline">\(\overline{x}\)</span></td>
<td align="right"><span class="math inline">\(\hat{\mu}\)</span></td>
</tr>
<tr class="even">
<td>Standardabweichung (SD)</td>
<td align="right"><span class="math inline">\(\sigma\)</span></td>
<td align="right"><span class="math inline">\(s\)</span></td>
<td align="right"><span class="math inline">\(\hat{\sigma}\)</span></td>
</tr>
<tr class="odd">
<td>Varianz</td>
<td align="right"><span class="math inline">\(\sigma^{2}\)</span></td>
<td align="right"><span class="math inline">\(s^{2}\)</span></td>
<td align="right"><span class="math inline">\(\hat{\sigma}^{2}\)</span></td>
</tr>
<tr class="even">
<td>Korrelation</td>
<td align="right"><span class="math inline">\(\rho\)</span></td>
<td align="right"><span class="math inline">\(r\)</span></td>
<td align="right"><span class="math inline">\(\hat{\rho}\)</span></td>
</tr>
<tr class="odd">
<td>Regressionsgewicht</td>
<td align="right"><span class="math inline">\(\beta\)</span></td>
<td align="right"><span class="math inline">\(b\)</span></td>
<td align="right"><span class="math inline">\(\hat{\beta}\)</span></td>
</tr>
</tbody>
</table>
<div id="gütekriterien-für-parameterschätzung" class="section level2">
<h2>Gütekriterien für Parameterschätzung</h2>
<ol style="list-style-type: decimal">
<li>
<p><strong>Erwartungstreue</strong></p>
<p>Erwartungswert des Stichprobenkennwertes entspricht dem
Populationsparameter</p>
</li>
<li>
<p><strong>Konsistenz</strong></p>
<p>Stichprobenkennwert nähert sich mit wachsender Stichprobe dem
Populationsparameter</p>
</li>
<li>
<p><strong>Effizienz</strong></p>
<p>Stichprobenkennwert hat den geringsten Standardfehler unter allen
erwartungstreuen Schätzern für einen Populationsparameter</p>
</li>
<li>
<p><strong>Suffizienz</strong></p>
<p>Stichprobenkennwert basiert auf alles in den Daten enthaltenen
Informationen</p>
</li>
</ol>
</div>
<div id="punktschätzung-des-mittelwertes" class="section level2">
<h2>Punktschätzung des Mittelwertes</h2>
<p><span class="math inline">\(k = 100\)</span> Stichproben einer
uniform verteilten Merkmals <span class="math inline">\(x\)</span> mit
jeweils <span class="math inline">\(n = 100\)</span> Messungen.</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Der Mittelwert der Stichprobenverteilung <span class="math inline">\(\hat{\mu}\)</span> (rote Linie) nähert sich mit
steigender Stichprobenzahl (<span class="math inline">\(i\)</span>) dem
Populationsmittelwert <span class="math inline">\(\mu\)</span> (blaue
Linie) immer weiter an.</p>
<p>Der Mittelwert der Stichprobenverteilung <span class="math inline">\(\hat{\mu}\)</span> ist also ein erwartungstreuer
und konsistenter Schätzer des Populationsmittelwertes <span class="math inline">\(\mu\)</span>.</p>
</div>
<div id="punktschätzung-der-varianz" class="section level2">
<h2>Punktschätzung der Varianz</h2>
<table>
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<thead>
<tr class="header">
<th align="center">empirische Varianz</th>
<th align="center">Stichprobenvarianz</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(s^{2*} = \frac{1}{n}
\sum_{i = 1}^{n}(x_i - \overline{x})^2\)</span></td>
<td align="center"><span class="math inline">\(s^2 = \frac{1}{n - 1}
\sum_{i = 1}^{n}(x_i - \overline{x})^2\)</span></td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(k = 100\)</span> Stichproben mit je <span class="math inline">\(n = 100\)</span> Messungen eines normalverteilten
Merkmals:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-6-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Die empirische Varianz <span class="math inline">\(s^{2*}\)</span>
(rote Linie) weicht stärker vom wahren Kennwert der Population <span class="math inline">\(\sigma^{2}\)</span> (blaue Linie) ab als die
Stichproben-Varianz <span class="math inline">\(s^2\)</span> (grüne
Linie).</p>
<p>Die empirische Varianz ist kein erwartungstreuer Schätzer der
Populationsvarianz, die Stichproben-Varianz dagegen schon.</p>
<p><strong>Aber:</strong> <span class="math inline">\(\sqrt{s^2}\)</span>
(Stichproben-Standardabweichung <span class="math inline">\(s\)</span>)
ist <strong>KEIN</strong> erwartungstreuer Schätzer der
Populations-Standardabweichung <span class="math inline">\(\sigma\)</span>!</p>
</div>
</div>
<div id="intervallschätzung-von-populationsparametern" class="section level1">
<h1>Intervallschätzung von Populationsparametern</h1>
<p><strong>Konfidenzintervall</strong>: Intervall um den geschätzten
Parameter, in dem mit Wahrscheinlichkeit <span class="math inline">\(1-\alpha\)</span> der wahre Populationsparameter
liegt.</p>
<div id="konfidenzintervall-des-mittelwertes" class="section level2">
<h2>Konfidenzintervall des Mittelwertes</h2>
<p>Nach dem <a href="#zentraler-grenzwertsatz">zentralem
Grenzwertsatz</a> folgen die Mittelwerte der Stichproben <span class="math inline">\(\overline{x}\)</span> einer Normalverteilung mit
den Parametern Populationsmittelwert <span class="math inline">\(\mu\)</span> und Standardfehler der
Stichprobenmittelwerte <span class="math inline">\(\sigma_{\overline{x}}\)</span>:</p>
<p><span class="math display">\[\overline{x} \sim Normal(\mu,
\sigma_{\overline{x}})\]</span></p>
<p>Entsprechend folgen die z-standardisierten Mittelwerte der
Stichproben der Standard-Normalverteilung:</p>
<p><span class="math display">\[\frac{\overline{x} -
\mu}{\sigma_{\overline{x}}} \sim Normal(0,1)\]</span></p>
<p>Die Fläche <span class="math inline">\(1 - \alpha = 0.95\)</span>
liegt im Intervall <span class="math inline">\(z = [-1.96,
1.96]\)</span> der Standard-Normalverteilung.</p>
<p><span class="math inline">\(1-\alpha\)</span> wird auch
Konfidenzkoeffizient genannt.</p>
<p>Beispiel: Stichprobe mit <span class="math inline">\(n = 100\)</span>
Messungen eines normalverteilten Merkmals:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-7-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Der Populationsparameter <span class="math inline">\(\mu\)</span>
liegt im Intervall um den Stichprobenmittelwert <span class="math inline">\(\overline{x}\)</span> (grüne Linie), das 95% der
Fläche der Kennwertverteilung (pink) abdeckt.</p>
<p>Da es ein zweiseitiges Konfidenzintervall ist, wird an beidem Seiten
der Verteilung 2.5% abgeschnitten damit insgesamt <span class="math inline">\(\alpha = 5\%\)</span> gilt.</p>
<div id="konfidenzintervall-pro-stichprobe" class="section level3">
<h3>Konfidenzintervall pro Stichprobe</h3>
<p><span class="math inline">\(k = 100\)</span> Stichproben zu je <span class="math inline">\(n = 1000\)</span> normalverteilten Messungen, mit
zweiseitigem Konfidenzintervall <span class="math inline">\(\alpha =
0.05\)</span>:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-8-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Prozentsatz der Mittelwerte die mit ihrem Konfidenzintervall
<strong>nicht</strong> den Populationsmittelwert abdecken, entspricht in
etwa dem Fehlerniveau <span class="math inline">\(\alpha = 5\%\)</span>.
4 Stichproben von <span class="math inline">\(k = 100\)</span> decken
nicht den Populationsmittelwert in ihrem Konfidenzintervall ab.</p>
<pre class="r"><code>samples %&gt;%
  filter(
    x.mean.lower &gt; mu | x.mean.upper &lt; mu
  ) %&gt;% summarize(p = n() / k)</code></pre>
<pre><code>## # A tibble: 1 × 1
##       p
##   &lt;dbl&gt;
## 1  0.04</code></pre>
</div>
</div>
<div id="schätzung-des-konfidenzintervalls-des-mittelwertes" class="section level2">
<h2>Schätzung des Konfidenzintervalls des Mittelwertes</h2>
<p>Wenn die Standardabweichung <span class="math inline">\(\sigma\)</span> der Population nicht bekannt ist,
der Standardfehler also nicht daraus abgeleitet werden kann, wird das
Konfidenzintervall anhand des <a href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes">geschätzten
Standardfehlers</a> berechnet.</p>
<p><span class="math display">\[\overline{x} \pm t(1- \frac{\alpha}{2},
n - 1) \cdot \hat\sigma_{\overline{x}}\]</span></p>
<p>Stichprobe von <span class="math inline">\(n = 10\)</span> Messungen
eines normalverteilten Merkmals:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-10-1.png" width="768" style="display: block; margin: auto;"></p>
<p><em>Es ist gleichgültig ob das Konfidenzintervall um den
Populationsmittelwert oder den Stichprobenmittelwert gelegt wird.
Wichtig ist, dass beide Werte im Intervall liegen. Bei t-Verteilungen
ist es einfacher, das Intervall um den 0-Punkt zu legen und alle Werte
entsprechend zu standardisieren.</em></p>
</div>
<div id="konfidenzintervall-abgängig-von-stichprobengröße" class="section level2">
<h2>Konfidenzintervall abgängig von Stichprobengröße</h2>
<p>Sowohl der Standardfehler <span class="math inline">\(\sigma_{\overline{x}}\)</span> als auch der
geschätzte Standardfehler <span class="math inline">\(\hat{\sigma}_{\overline{x}}\)</span> hängen von
der Stichprobengröße ab und werden kleiner, je größer die Stichprobe
ist. Entsprechend verändert sich auch das Konfidenzintervall.</p>
<p>Zwei Stichproben mit <span class="math inline">\(n_1 = 20\)</span>
(grau) und <span class="math inline">\(n_2 = 40\)</span> (pink)
Messungen des gleichen normalverteilten Merkmals, sowie
Populationsmittelwert (blau):</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-11-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Die größere Stichprobe <span class="math inline">\(n_2 = 40\)</span>
hat ein deutlich schmaleres Konfidenzintervall.</p>
</div>
</div>
<div id="statistische-hypothesenprüfung" class="section level1">
<h1>Statistische Hypothesenprüfung</h1>
<div id="signifikanztests" class="section level2">
<h2>Signifikanztests</h2>
<p><strong>Nullhypothese <span class="math inline">\(H_0\)</span>:</strong> Annahme, dass kein
Unterschied zwischen zwei Parametern besteht.</p>
<p><strong>p-Wert:</strong> Wahrscheinlichkeit, dass ein beobachteter
Effekt trotz Annahme der <span class="math inline">\(H_0\)</span>
zufällig auftritt.</p>
<ul>
<li>Bedingte Wahrscheinlichkeit <span class="math inline">\(Pr(\overline{x} | H_0)\)</span>, also eine Aussage
über die Wahrscheinlichkeit des beobachteten Stichprobenmittelwertes
<span class="math inline">\(Pr(\overline{x})\)</span> unter der
Voraussetzung dass die Nullhypothese <span class="math inline">\(H_0\)</span> wahr ist, <strong>NICHT</strong> über
die Wahrscheinlichkeit, dass die Nullhypothese <span class="math inline">\(H_0\)</span> an sich zutrifft.</li>
</ul>
<p><strong>“Signifikant”</strong> ist ein Effekt, wenn der
<strong>p-Wert</strong> unter einem zuvor festgelegten
Signifikanz-Niveau <span class="math inline">\(\alpha\)</span> liegt,
oft 5%.</p>
<div id="einseitiger-signifikanztest" class="section level3">
<h3>Einseitiger Signifikanztest</h3>
<p>Population mit <span class="math inline">\(\mu = 100\)</span> und
<span class="math inline">\(\sigma = 55\)</span>, Stichprobe mit <span class="math inline">\(n = 200\)</span>.</p>
<p>Liegt eine Stichprobe mit <span class="math inline">\(\overline{x} =
107\)</span> (blaue Linie) in den oberen 5% der
Wahrscheinlichkeitsmasse? D.h. ist die Wahrscheinlichkeit für solch eine
Stichprobe unter dem Signifikanz-Niveau?</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-12-1.png" width="768" style="display: block; margin: auto;"></p>
<p><strong>Die Parameter der Dichtefunktion sind hier
Populationsmittelwert und Standardfehler <span class="math inline">\(\sigma_{\overline{x}}\)</span>, errechnet aus der
Standardabweichung <span class="math inline">\(\sigma\)</span> der
Population und der Stichprobengröße <span class="math inline">\(n\)</span>. (siehe <a href="#berechnung-des-standardfehlers-des-mittelwertes">Berechnung des
Standardfehlers</a>)</strong></p>
</div>
<div id="zweiseitiger-signifikanztest" class="section level3">
<h3>Zweiseitiger Signifikanztest</h3>
<p>Population mit <span class="math inline">\(\mu = 100\)</span> und
<span class="math inline">\(\sigma = 55\)</span>, Stichprobe mit <span class="math inline">\(n = 200\)</span>.</p>
<p>Beim zweiseitigen Signifikanztest wird das Signifikanz-Niveau auf
beide Seiten aufgeteilt, da es die Wahrscheinlichkeit betrifft mit der
eine Stichprobe in einem der beiden Extrembereiche liegt, egal in
welchem.</p>
<p>Liegt eine Stichprobe mit <span class="math inline">\(\overline{x} =
107\)</span> (blaue Linie) außerhalb der zentralen 95% der
Wahrscheinlichkeitsmasse?</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-13-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
<div id="standardisierte-prüfgrößen" class="section level3">
<h3>Standardisierte Prüfgrößen</h3>
<p>Oft werden Daten zur Hypothesenprüfung standardisiert:</p>
<p><span class="math display">\[z_{\overline{x}} = \frac{\overline{x} -
\mu}{\sigma_{\overline{x}}}\]</span> Die Verteilung der
Stichprobenkennwerte in der Population ist dann auf <span class="math inline">\(\mu = 0\)</span> zentriert und hat einen
Standardfehler <span class="math inline">\(\sigma_{\overline{x}} =
1.0\)</span>.</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-14-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
<div id="signifikanztest-mit-empirischen-daten" class="section level3">
<h3>Signifikanztest mit empirischen Daten</h3>
<p><strong>One-Sample-T-Test:</strong> gibt für gegebene Samples und
Populationsmittelwert den p-Wert aus. Verglichen wird eine Stichprobe
(daher “one sample”) mit der Gesamtpopulation.</p>
<p>Da die Standardabweichung der Population nicht bekannt ist, wird der
Standardfehler mittels der T-Verteilung geschätzt. (siehe <a href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes">Schätzung
des Standardfehlers</a>)</p>
<p>Samples:</p>
<pre><code>## # A tibble: 10 × 1
##        x
##    &lt;dbl&gt;
##  1 168. 
##  2  88.7
##  3 171. 
##  4 169. 
##  5 126. 
##  6  28.0
##  7  58.6
##  8  90.3
##  9 105. 
## 10 225.</code></pre>
<p>Einseitiger One-Sample-T-Test:</p>
<pre class="r"><code>mu &lt;- 100
alpha &lt;- 0.05

# alternative = "greater" -  &gt; Einseitiger Test in positiver Richtung
# alternative = "less"      -&gt; Einseitiger Test in negativer Richtung
# alternative = "two.sided" -&gt; Zweiseitiger Test
t.test(samples, mu = mu, alternative = "greater", conf.level = 1 - alpha)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  samples
## t = 1.204, df = 9, p-value = 0.1296
## alternative hypothesis: true mean is greater than 100
## 95 percent confidence interval:
##  88.01066      Inf
## sample estimates:
## mean of x 
##  122.9462</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-17-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
</div>
<div id="hypothesentests" class="section level2">
<h2>Hypothesentests</h2>
<p><strong>Nullhypothese <span class="math inline">\(H_0\)</span>:</strong> Annahme, dass ein
bestimmter bedeutsamer Effekt nicht existiert.</p>
<p><strong>Alternativhypothese <span class="math inline">\(H_1\)</span>:</strong> Annahme, dass ein
bestimmter bedeutsamer Effekt existiert</p>
<p><strong>Die Nullhypothese ist niemals wirklich wahr. Mit
ausreichender Stichprobengröße lässt sich ein beliebig kleiner Effekt
zeigen.</strong></p>
<p><strong>Irrtumswahrscheinlichkeit <span class="math inline">\(\alpha\)</span>:</strong> Wahrscheinlichkeit, dass
ein Test in einer Stichprobe einen bedeutsamen Effekt zufällig anzeigt,
der eigentlich in der Population nicht existiert, also dass die
Nullhypothese <span class="math inline">\(H_0\)</span> fälschlicherweise
abgelehnt wird. (<span class="math inline">\(\alpha\)</span>-Fehler,
False-Positive)</p>
<p><strong>Irrtumswahrscheinlichkeit <span class="math inline">\(\beta\)</span>:</strong> Wahrscheinlichkeit, dass
ein Effekt, der in der Population vorhanden ist, zufällig in der
getesteten Stichprobe nicht auftaucht, also dass die Nullhypothese <span class="math inline">\(H_0\)</span> fälschlicherweise angenommen wird.
(<span class="math inline">\(\beta\)</span>-Fehler, False-Negative)</p>
<p><strong>Teststärke/Power:</strong> <span class="math inline">\(1 -
\beta\)</span>, je höher die Power, umso unwahrscheinlicher werden <span class="math inline">\(\beta\)</span>-Fehler</p>
<p><strong>parametrische vs. nicht-parametrische Tests:</strong>
parametrische Tests setzen voraus, dass Merkmale in der Population
normalverteilt sind (z.B. Gauss-Test, T-Test). Nicht-parametrische Tests
machen diese Annahme nicht (Gegenstand im M.Sc.-Studium).</p>
<p>Ein Test kann zwar einen p-Wert unter <span class="math inline">\(\alpha\)</span>-Niveau (0.05) liefern, aber
trotzdem einen sehr großer <span class="math inline">\(\beta\)</span>-Fehler haben:</p>
<ul>
<li>grüne Linie: <span class="math inline">\(\mu\)</span>
</li>
<li>blaue Linie: <span class="math inline">\(\overline{x}\)</span>
</li>
<li>rosa Fläche: <span class="math inline">\(\alpha\)</span>
</li>
<li>blaue Fläche: <span class="math inline">\(\beta\)</span>
</li>
<li>gestrichelte Linie: kritischer Wert</li>
</ul>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-18-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Mit niedrigerem <span class="math inline">\(\alpha\)</span>-Niveau
(0.01) wird der <span class="math inline">\(\beta\)</span>-Fehler sogar
noch größer.</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-19-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Um den <span class="math inline">\(\beta\)</span>-Fehler zu
reduzieren, müsste ein stärkerer Effekt (<span class="math inline">\(\overline{x} - \mu\)</span>) vorhanden sein:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-20-1.png" width="768" style="display: block; margin: auto;"></p>
<div id="standardisierter-effekt-cohens-delta" class="section level3">
<h3>Standardisierter Effekt: Cohen’s <span class="math inline">\(\delta\)</span>
</h3>
<p><em>(Manchmal auch: “Cohen’s d”)</em></p>
<p><span class="math display">\[\delta = \frac{\overline{x} -
\mu}{\sigma}\]</span></p>
<ul>
<li>
<span class="math inline">\(\overline{x}\)</span>:
Stichproben-Mittelwert</li>
<li>
<span class="math inline">\(\mu\)</span>: Populationsmittelwert</li>
<li>
<span class="math inline">\(\sigma\)</span>: Standardabweichung der
Population</li>
</ul>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-21-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
<div id="konfidenzintervalle-für-cohens-delta" class="section level3">
<h3>Konfidenzintervalle für Cohen’s <span class="math inline">\(\delta\)</span>
</h3>
<p>Die Stichprobenkennwerte-Verteilung von <span class="math inline">\(\overline{x}\)</span> ist normalverteilt (siehe <a href="#zentraler-grenzwertsatz">Zentraler Grenzwertsatz</a>)</p>
<p>Der Erwartungswert von <span class="math inline">\(\delta\)</span>
entspricht der standardisierten Differenz zwischen Stichprobenmittelwert
und Populationsmittelwert.</p>
<p><span class="math display">\[E_{\delta} = \frac{\overline{x} -
\mu}{\sigma}\]</span></p>
<p>Die Streuung <span class="math inline">\(\sigma_{\delta}\)</span> ist
der Standardfehler wobei dieser hier vereinfacht <span class="math inline">\(\frac{1}{\sqrt{n}}\)</span> ist weil
Standardisierung bereits erfolgt ist (die Standardabweichung von
standardisierten Größen ist 1):</p>
<p><span class="math display">\[\sigma_{\delta} = \sigma_{\overline{x}}
= \frac{1}{\sqrt{n}}\]</span></p>
<p><span class="math display">\[\delta \sim  Normal(E_{\delta} =
\frac{\overline{x} - \mu}{\sigma}, \sigma_{\delta} =
\frac{1}{\sqrt{n}})\]</span></p>
<p>Damit lassen sich die Konfidenzintervalle für ein gegebenes <span class="math inline">\(\alpha\)</span>-Niveau berechnen:</p>
<p><span class="math display">\[\delta \pm z(1-\frac{\alpha}{2}) \cdot
\sigma_{\delta} = \frac{\overline{x} - \mu}{\sigma}
\pm  z(1-\frac{\alpha}{2}) \cdot \frac{1}{\sqrt{n}}\]</span></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-22-1.png" width="768" style="display: block; margin: auto;">
Konventionen für Effektinterpretationen für <span class="math inline">\(\delta\)</span> nach Cohen:</p>
<ul>
<li>
<span class="math inline">\(|d|  \approx 0.14\)</span>: “kleiner”
Effekt</li>
<li>
<span class="math inline">\(|d|  \approx 0.35\)</span>: “mittlerer”
Effekt</li>
<li>
<span class="math inline">\(|d|  \approx 0.57\)</span>: “großer”
Effekt</li>
</ul>
</div>
<div id="einstichproben-gauss-test" class="section level3">
<h3>Einstichproben-Gauss-Test</h3>
<p>Voraussetzungen:</p>
<ul>
<li>Merkmal ist in der Population normalverteilt
<ul>
<li>
<p>alternativ: bei nicht-normalverteiltem Merkmal <span class="math inline">\(x\)</span> ist der Stichproben Mittelwert ab ca.
<span class="math inline">\(n = 30\)</span> nahezu normalverteilt.
(Siehe <a href="#zentraler-grenzwertsatz">zentraler
Grenzwertsatz</a>)</p>
<p>Der z-Test ist dann allerdings nicht mehr exakt.</p>
</li>
</ul>
</li>
<li>Standardabweichung <span class="math inline">\(\sigma\)</span> in
der Population ist bekannt</li>
</ul>
<p>Gauss-Test, auch “z-Test” genannt, ist geeignet, wenn die
Standardabweichung <span class="math inline">\(\sigma\)</span> der
Population bekannt ist, und damit der Standardfehler <span class="math inline">\(\sigma_{\overline{x}}\)</span> berechnet werden
kann. (Siehe <a href="#berechnung-des-standardfehlers-des-mittelwertes">Berechnung des
Standardfehlers des Mittelwertes</a>)</p>
<p>Prüfgröße: <span class="math inline">\(z_{\overline{x} -
\mu}\)</span>, z-standardisierte Differenz von Stichprobenmittelwert und
Populationsmittelwert</p>
<p><span class="math display">\[z_{\overline{x} - \mu} =
\frac{\overline{x} - \mu}{\sigma_{\overline{x}}}\]</span></p>
<p>Kritischer Wert: Wert für <span class="math inline">\(\overline{x}\)</span> der über- bzw.
unterschritten werden muss damit <span class="math inline">\(p \le
0.05\)</span> eingehalten wird.</p>
<p><span class="math inline">\(Q(p)\)</span> ist hier die
Quantilsfunktion der Normalverteilung, die bestimmt welcher Wert eine
Wahrscheinlichkeit von <span class="math inline">\(p\)</span> oder
weniger hat.</p>
<p>Die Nullhypothese <span class="math inline">\(H_0\)</span> wird
abgelehnt wenn:</p>
<ul>
<li>
<p>bei einseitigem Test in positiver Richtung</p>
<p><span class="math inline">\(z_{\overline{x} - \mu} \ge Q(1 -
\alpha)\)</span></p>
</li>
<li>
<p>bei einseitigem Test in negativer Richtung</p>
<p><span class="math inline">\(z_{\overline{x} - \mu} \le
Q(\alpha)\)</span></p>
</li>
<li>
<p>bei zweiseitigem Test</p>
<p><span class="math inline">\(z_{\overline{x} - \mu} \le
Q(\frac{\alpha}{2}) \cup z_{\overline{x} - \mu} \ge Q(1 -
\frac{\alpha}{2})\)</span></p>
<p>(<span class="math inline">\(\cup\)</span>: “oder”)</p>
</li>
</ul>
<p>Siehe auch: <a href="#signifikanztests">Signifikanztests</a></p>
<div id="einstichproben-gauss-test-in-r" class="section level4">
<h4>Einstichproben-Gauss-Test in R</h4>
<p>Samples mit <span class="math inline">\(\mu = 0.5\)</span>, <span class="math inline">\(\sigma = 1.0\)</span>, und <span class="math inline">\(n = 20\)</span></p>
<pre><code>##  [1]  1.76295428  0.17376664  1.82979926  1.77242932  0.91464143 -1.03995004
##  [7] -0.42856703  0.20527955  0.49423283  2.90465339  1.26359346 -0.29900925
## [13] -0.64765701  0.21053843  0.20078488  0.08848917  0.75222345 -0.39192113
## [19]  0.93568330 -0.73753842</code></pre>
<pre class="r"><code># Paket: BSDA

z.test(samples, mu = 0, sigma.x = 1, conf.level = 0.95, alternative = "greater")</code></pre>
<pre><code>## 
##  One-sample z-Test
## 
## data:  samples
## z = 2.2281, p-value = 0.01294
## alternative hypothesis: true mean is greater than 0
## 95 percent confidence interval:
##  0.1304209        NA
## sample estimates:
## mean of x 
## 0.4982213</code></pre>
</div>
</div>
<div id="einstichproben-t-test" class="section level3">
<h3>Einstichproben T-Test</h3>
<p>Voraussetzungen:</p>
<ul>
<li>Merkmal ist in der Population normalverteilt
<ul>
<li>alternativ: bei nicht-normalverteiltem Merkmal <span class="math inline">\(x\)</span> ist der Stichproben Mittelwert ab ca.
<span class="math inline">\(n = 30\)</span> nahezu normalverteilt.
(Siehe <a href="#zentraler-grenzwertsatz">zentraler
Grenzwertsatz</a>)</li>
</ul>
</li>
<li>Stichprobengröße ist bekannt (zur Schätzung des
Standardfehlers)</li>
</ul>
<p><em>Der T-Test ist wenn möglich dem Gauss-Test vorzuziehen, da er
auch ohne bekannte Standardabweichung der Population exakter
ist.</em></p>
<p>Schätzung des Standardfehlers <span class="math inline">\(\hat{\sigma}_{\overline{x}}\)</span></p>
<ul>
<li>
<span class="math inline">\(\hat{\sigma}^2_{x}\)</span>: geschätzte
Populations-Varianz</li>
<li>
<span class="math inline">\(s^2_{x}\)</span>:
Stichproben-Varianz</li>
<li>
<span class="math inline">\(s^{2*}\)</span>: empirische Varianz</li>
</ul>
<p><span class="math display">\[\hat{\sigma}_{\overline{x}} =
\sqrt{\frac{\hat{\sigma}^2_{x}}{n}} = \sqrt{\frac{s^2_{x}}{n}} =
\sqrt{\frac{s^{2*}_{x}}{n-1}}\]</span></p>
<p>Prüfgröße: <span class="math inline">\(t_{\overline{x} -
\mu}\)</span></p>
<p><span class="math display">\[t_{\overline{x} - \mu} =
\frac{\overline{x} - \mu}{\hat{\sigma}_{\overline{x}}}\]</span></p>
<p>Kritischer Wert: Analog zum <a href="#einstichproben-gauss-test">Einstichproben Gauss-Test</a></p>
<p><span class="math inline">\(Q(p)\)</span> ist beim t-Test die
Quantilsfunktion der Student-T-Verteilung mit <span class="math inline">\(n-1\)</span> Freiheitsgraden, denn die Verteilung
von <span class="math inline">\(t_{\overline{x} - \mu}\)</span> folgt
dieser Student-T-Verteilung:</p>
<p><span class="math display">\[t_{\overline{x} - \mu} \sim Student(df =
n -1 )\]</span></p>
<p>Beispiel: Zwei T-Tests mit entsprechenden Student-T-Verteilungen für
<span class="math inline">\(n=10\)</span> und <span class="math inline">\(n=100\)</span>.</p>
<p>Die Prüfgröße fällt bei <span class="math inline">\(n=10\)</span>
nicht über den kritischen Wert für <span class="math inline">\(p \le
\alpha\)</span>, bei <span class="math inline">\(n=100\)</span> aber
schon, da der geschätzte Standardfehler geringer wird, d.h. der Test
wird genauer.</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-26-1.png" width="768" style="display: block; margin: auto;"></p>
<div id="einstichproben-t-test-in-r" class="section level4">
<h4>Einstichproben T-Test in R</h4>
<p>Samples mit <span class="math inline">\(\mu = 0.5\)</span>, <span class="math inline">\(\sigma = 1.0\)</span>, und <span class="math inline">\(n = 20\)</span></p>
<pre><code>##  [1] 0.8525909 0.5347533 0.8659599 0.8544859 0.6829283 0.2920100 0.4142866
##  [8] 0.5410559 0.5988466 1.0809307 0.7527187 0.4401982 0.3704686 0.5421077
## [15] 0.5401570 0.5176978 0.6504447 0.4216158 0.6871367 0.3524923</code></pre>
<pre class="r"><code>t.test(samples, alternative = "greater", mu = 0.5, conf.level = 0.95)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  samples
## t = 2.1812, df = 19, p-value = 0.02097
## alternative hypothesis: true mean is greater than 0.5
## 95 percent confidence interval:
##  0.5206532       Inf
## sample estimates:
## mean of x 
## 0.5996443</code></pre>
</div>
</div>
<div id="einstichproben-t-test-für-abhängige-beobachtungen" class="section level3">
<h3>Einstichproben T-Test für abhängige Beobachtungen</h3>
<p>T-Test für abhängige Messungen in einer Stichprobe. z.B. wenn die
gleiche Stichprobe von Versuchspersonen vor und nach einem Treatment die
gleiche Messung durchläuft.</p>
<p>Stichprobengröße ist hier die Anzahl der Messwertpaare, nicht die
Anzahl aller Messungen.</p>
<p>Es wird eine neue Variable <span class="math inline">\(\overline{x}_D\)</span> eingeführt, der Mittelwert
der Differenz der beiden Messungen von jeweils der gleichen
Versuchsperson.</p>
<ul>
<li>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\overline{x}_D = 0\)</span>
</li>
<li>
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(\overline{x}_D \neq 0\)</span> (zweiseitiger
Test)</li>
</ul>
<p><em>Es ist egal ob zuerst die Differenzen der Messungen für jede
Versuchsperson gebildet und dann gemittelt werden, oder ob die Differenz
der Mittelwerte beider Messungen gebildet wird. Das Ergebnis ist das
gleiche</em></p>
<p>Der Rest der Tests verläuft wie beim Einstichproben T-Test.</p>
<div id="einstichproben-t-test-für-abhängige-beobachtungen-t-test-in-r" class="section level4">
<h4>Einstichproben T-Test für abhängige Beobachtungen T-Test in R</h4>
<p><span class="math inline">\(n=20\)</span> Samples,</p>
<pre class="r"><code>samples</code></pre>
<pre><code>## # A tibble: 10 × 2
##       m1    m2
##    &lt;dbl&gt; &lt;dbl&gt;
##  1 163.  164. 
##  2  83.7  81.6
##  3 166.  164. 
##  4 164.  163. 
##  5 121.  120. 
##  6  23.0  21.7
##  7  53.6  53.6
##  8  85.3  83.0
##  9  99.7 100. 
## 10 220.  217.</code></pre>
<pre class="r"><code>xd = samples$m2 - samples$m1
t.test(xd, mu = 0, alternative = "two.sided", conf.level = 0.95)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  xd
## t = -2.853, df = 9, p-value = 0.019
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -2.1962337 -0.2536916
## sample estimates:
## mean of x 
## -1.224963</code></pre>
<p>Alternativ kann die Funktion <code>t.test</code> auch die paarweisen
Differenzen automatisch bestimmen:</p>
<pre class="r"><code>t.test(x = samples$m2, y = samples$m1,
       paired = TRUE,
       mu = 0,
       alternative = "two.sided",
       conf.level = 0.95)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  samples$m2 and samples$m1
## t = -2.853, df = 9, p-value = 0.019
## alternative hypothesis: true mean difference is not equal to 0
## 95 percent confidence interval:
##  -2.1962337 -0.2536916
## sample estimates:
## mean difference 
##       -1.224963</code></pre>
</div>
</div>
<div id="einstichproben-binomialtest" class="section level3">
<h3>Einstichproben Binomialtest</h3>
<p>Test für ein dichotomes Merkmal <span class="math inline">\(x\)</span> (Merkmal mit zwei möglichen
Ausprägungen): <span class="math inline">\(x \in \{0,1\}\)</span></p>
<p><span class="math inline">\(\pi_0\)</span>: Wahrscheinlichkeit in der
Population für <span class="math inline">\(x = 1\)</span></p>
<p><span class="math inline">\(\pi\)</span>: Wahrscheinlichkeit in der
Stichprobe für <span class="math inline">\(x = 1\)</span></p>
<p>Hypothesenpaare:</p>
<ul>
<li>ungerichtet
<ul>
<li>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\pi_0 = \pi\)</span>
</li>
<li>
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(\pi_0 \ne \pi\)</span>
</li>
</ul>
</li>
<li>gerichtet, positiv
<ul>
<li>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\pi_0 \ge \pi\)</span>
</li>
<li>
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(\pi_0 \lt \pi\)</span>
</li>
</ul>
</li>
<li>gerichtet, negativ
<ul>
<li>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\pi_0 \le \pi\)</span>
</li>
<li>
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(\pi_0 \gt \pi\)</span>
</li>
</ul>
</li>
</ul>
<p>Aus <span class="math inline">\(\pi_0\)</span> und <span class="math inline">\(\pi\)</span> ergeben sich zwei
Binomialverteilungen über <span class="math inline">\(n\)</span>
Ziehungen, mit <span class="math inline">\(\alpha\)</span>-Fehler analog
zu anderen Tests.</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-34-1.png" width="768" style="display: block; margin: auto;"></p>
<div id="binomialtest-in-r" class="section level4">
<h4>Binomialtest in R</h4>
<pre class="r"><code>binom.test(39, 60, p = 0.5, conf.level = 0.95, alternative = "greater")</code></pre>
<pre><code>## 
##  Exact binomial test
## 
## data:  39 and 60
## number of successes = 39, number of trials = 60, p-value = 0.01367
## alternative hypothesis: true probability of success is greater than 0.5
## 95 percent confidence interval:
##  0.5363726 1.0000000
## sample estimates:
## probability of success 
##                   0.65</code></pre>
</div>
</div>
<div id="zweistichproben-t-test" class="section level3">
<h3>Zweistichproben T-Test</h3>
<p>Wird angewendet beim Vergleich von 2 unabhängigen Stichproben (z.B.
Studienarme).</p>
<p>Voraussetzungen:</p>
<ul>
<li>normalverteiltes Merkmal</li>
<li>Messwerte in beiden Stichproben unabhängig</li>
<li>Varianzhomogenität zwischen den Stichproben</li>
</ul>
<p>Prüfgröße:</p>
<p><span class="math display">\[T = t_{\overline{x}_1} -
t_{\overline{x}_2} = \frac{\overline{x}_1 - \overline{x}_2}
{\hat{\sigma}_{\overline{x}_1 - \overline{x}_2}}\]</span></p>
<p><span class="math inline">\(T\)</span> folgt der Student-T-Verteilung
mit <span class="math inline">\(df = n_1 + n_2 - 2\)</span>$
Freiheitsgraden</p>
<p><span class="math display">\[T \sim Student(0, 1, n_1 + n_2 -
2)\]</span></p>
<p>Standardfehler hängt hier von den Größen beider Stichproben ab, da
diese nicht unbedingt gleich groß sind.</p>
<p><span class="math display">\[\hat{\sigma}_{\overline{x}_1 -
\overline{x}_2} = \sqrt{\frac{\hat{\sigma}^2_{inn}} {n_1} +
\frac{\hat{\sigma}^2_{inn}}{n_2}}\]</span></p>
<p>Geteilte/Gepoolte Innerhalb-Varianz <span class="math inline">\(\hat{\sigma}^2_{inn}\)</span> wird aus den
geschätzten Varianzen der Stichproben (<span class="math inline">\(\hat{\sigma}^2_1\)</span>, <span class="math inline">\(\hat{\sigma}^2_2\)</span>) berechnet (siehe auch
<a href="#punktsch%C3%A4tzung-der-varianz">Punktschätzung der
Varianz</a>):</p>
<p><span class="math display">\[\hat{\sigma}^2_{inn} =
\frac{\hat{\sigma}^2_1 \cdot (n_1 -1) + \hat{\sigma}^2_2 \cdot (n_2 -1)}
{(n_1 - 1) + (n_2 - 1)}\]</span></p>
<p>Beispiel: Stichproben aus zwei Studienarmen mit jeweils <span class="math inline">\(n = 100\)</span></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-36-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Verteilung der Prüfgröße <span class="math inline">\(T\)</span>:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-37-1.png" width="768" style="display: block; margin: auto;"></p>
<div id="zweistichproben-t-test-in-r" class="section level4">
<h4>Zweistichproben T-Test in R</h4>
<pre class="r"><code>t.test(samples2$x, y = samples1$x, alternative = "greater", conf.level = 0.95) -&gt; t.result
t.result</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  samples2$x and samples1$x
## t = 2.5715, df = 193.31, p-value = 0.005438
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  6.070815      Inf
## sample estimates:
## mean of x mean of y 
##  118.1253  101.1334</code></pre>
<p>Bestimmung der Konfidenzintervalle des Effekts (Cohen’s <span class="math inline">\(d\)</span>):</p>
<pre class="r"><code># Paket: MBESS

ci.smd(t.result$statistic,
       n.1 = length(samples1),
       n.2 = length(samples2),
       conf.level = 0.95)</code></pre>
<pre><code>## $Lower.Conf.Limit.smd
## [1] -0.5441647
## 
## $smd
##        t 
## 2.571521 
## 
## $Upper.Conf.Limit.smd
## [1] 5.534741</code></pre>
</div>
</div>
</div>
<div id="power-und-stichprobenplanung" class="section level2">
<h2>Power und Stichprobenplanung</h2>
<p><strong>Power: <span class="math inline">\(1-\beta\)</span></strong></p>
<p><span class="math inline">\(\beta\)</span> und Power hängen vom
Standardfehler und damit von der Stichprobengröße ab.</p>
<p>Beispiel <span class="math inline">\(n = 20\)</span>, <span class="math inline">\(\beta\)</span>-Fehler ist gering:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-40-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Bei <span class="math inline">\(n = 7\)</span> ist der <span class="math inline">\(\beta\)</span>-Fehler deutlich höher und die Power
daher geringer, während <span class="math inline">\(\alpha\)</span>-Niveau weiterhin unterschritten
wird:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-41-1.png" width="768" style="display: block; margin: auto;"></p>
<p><span class="math inline">\(\beta\)</span> ist ebenfalls vom Effekt
abhängig. Zur Planung der Stichprobengröße müssen <span class="math inline">\(\alpha\)</span>-Niveau und der minimale als
signifikant akzeptierte Effekt bekannt sein.</p>
<div id="stichprobenplanung-in-r" class="section level3">
<h3>Stichprobenplanung in R</h3>
<pre class="r"><code># Paket: pwr

# post-hoc Power-Analyse für einseitigen Gauss-Test/Z-Test
# - Stichproben-Signifikanztest
# - Normalverteilte Merkmale
# - bekannter Standardabweichung
pwr.norm.test(0.5, n = 10, sig.level = 0.05, alternative = "greater")</code></pre>
<pre><code>## 
##      Mean power calculation for normal distribution with known variance 
## 
##               d = 0.5
##               n = 10
##       sig.level = 0.05
##           power = 0.4745987
##     alternative = greater</code></pre>
<pre class="r"><code># bei Test in negativer Richtung: alternative = "lesser"
# bei zweiseitigem Test: alternative = "two.sided"</code></pre>
<pre class="r"><code># a priori Power Analyse für Zweistichproben-T-Test
# n ist noch nicht bekannt, aber alpha-Niveau, Effekt und Power sind gegeben
pwr.t.test(d = 0.5, sig.level = 0.05, power = 0.9, type = "two.sample")</code></pre>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 85.03128
##               d = 0.5
##       sig.level = 0.05
##           power = 0.9
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>Plot von Power in Abhängigkeit von Stichprobengröße:</p>
<p>Effekt <span class="math inline">\(d = 0.7\)</span>, <span class="math inline">\(\alpha_1 = 5\%\)</span> (blau), <span class="math inline">\(\alpha_2 = 1\%\)</span> (pink)</p>
<pre class="r"><code># Funktion die einen einseitigen Z-Test ausführt
# und den Power-Wert aus dem Ergebnis extrahiert
power &lt;- function(n, d = 1, alpha = 0.05) {
  test &lt;- pwr.norm.test(d, n = n, sig.level = alpha, alternative = "greater")
  
  return(test[[4]])
}

# Plot der Funktion über Stichprobengrößen 1-75
# Effekt d = 0.7
# alpha = 0.05 und alpha = 0.01
tibble(
  n = 1:50,
  power5 = power(n, d = 0.7, alpha = 0.05),
  power1 = power(n, d = 0.7, alpha = 0.01),
  ) %&gt;% ggplot(aes(x = n, y = power)) +
  geom_col(aes(y = power5), fill = colors[2]) +
  geom_col(aes(y = power1), fill = colors[1]) +
  annotate("text", label = "alpha[1] == 0.05", parse = TRUE, x = 2, y = 0.95, color = colors[2]) +
  annotate("text", label = "alpha[2] == 0.01", parse = TRUE, x = 2, y = 0.90, color = colors[1]) +
  xlab("Stichprobengröße") +
  ylab("Power") +
  theme_custom</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-44-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Für ein strengeres <span class="math inline">\(\alpha_2 =
1\%\)</span> ist gegenüber <span class="math inline">\(\alpha_1 =
5\%\)</span> eine größere Stichrobe nötig, um die gleiche Power zu
erreichen.</p>
</div>
</div>
<div id="tests-für-kategoriale-merkmale" class="section level2">
<h2>Tests für Kategoriale Merkmale</h2>
<p>Kategoriale Merkmale:</p>
<ul>
<li>nominalskalierte Merkmale</li>
<li>ordinalskalierte Merkmale
<ul>
<li>auch geschichtete metrische Merkmale</li>
</ul>
</li>
</ul>
<div id="chi2-statistik" class="section level3">
<h3>
<span class="math inline">\(\chi^2\)</span>-Statistik</h3>
<p><span class="math display">\[\chi^2 =
\sum_{i=1}^r{\sum_{j=1}^c{\frac{(f_{ij} -
e_{ij})^2}{e_{ij}}}}\]</span></p>
<ul>
<li><p><span class="math inline">\(r\)</span>: Anzahl Zeilen</p></li>
<li><p><span class="math inline">\(c\)</span>: Anzahl Spalten</p></li>
<li><p><span class="math inline">\(f_{ij}\)</span>: beobachtete
Häufigkeiten</p></li>
<li>
<p><span class="math inline">\(e_{ij}\)</span>: erwartete
Häufigkeiten</p>
<p><span class="math inline">\(e_{ij} = \frac{Zeilensumme \cdot
Spaltensumme}{Stichprobenumfang}\)</span></p>
</li>
</ul>
</div>
<div id="cramers-v" class="section level3">
<h3>Cramer’s <span class="math inline">\(V\)</span>
</h3>
<p><span class="math display">\[V = \sqrt{\frac{\chi^2}{n \cdot (m -
1)}}\]</span></p>
<ul>
<li><p><span class="math inline">\(n\)</span>:
Stichprobenumfang</p></li>
<li>
<p><span class="math inline">\(m\)</span>: Merkmalsausprägungen</p>
<p><span class="math inline">\(m = min(r, c)\)</span></p>
</li>
</ul>
</div>
<div id="chi2-test" class="section level3">
<h3>
<span class="math inline">\(\chi^2\)</span>-Test</h3>
<ul>
<li>
<span class="math inline">\(V\)</span>: Effektstärke</li>
<li>
<span class="math inline">\(\chi^2\)</span>: Prüfgröße</li>
</ul>
<p>Nullhypothese <span class="math inline">\(H_0\)</span>: <span class="math inline">\(V = 0\)</span>, es existiert kein Effekt</p>
<p>Die Prüfgröße folgt einer <span class="math inline">\(\chi^2\)</span>-Verteilung mit Freiheitsgraden
<span class="math inline">\(df = (r-1) \cdot (c-1)\)</span>.</p>
<div id="chi2-test-in-r" class="section level4">
<h4>
<span class="math inline">\(\chi^2\)</span>-Test in R</h4>
<p>Beispieldaten:</p>
<pre><code>##      A   B   C
## I  125 108 125
## II 127  93 230</code></pre>
<pre class="r"><code>chisq.test(samples)</code></pre>
<pre><code>## 
##  Pearson's Chi-squared test
## 
## data:  samples
## X-squared = 22.002, df = 2, p-value = 1.669e-05</code></pre>
</div>
<div id="kontinuitätskorrektur" class="section level4">
<h4>Kontinuitätskorrektur</h4>
<p>Zellen mit <span class="math inline">\(f_{ij} \lt 5\)</span> gelten
als “unterbesetzt”. Der <span class="math inline">\(\chi^2\)</span>-Test
reagiert dann progressiv, das <span class="math inline">\(\alpha\)</span>-Fehlerniveau wird unterschritten
und die Wahrscheinlichkeit, die <span class="math inline">\(H_1\)</span>
anzunehmen steigt.</p>
<p>Die Prüfgröße muss in diesem Fall adjustiert werden:</p>
<p><span class="math display">\[\chi^2_{adj} =
\sum_{i=1}^r{\sum_{j=1}^c{\frac{(|f_{ij} - e_{ij}| -
0.5)^2}{e_{ij}}}}\]</span></p>
<p>In R erfolgt die Korrektur automatisch, kann aber auch mit der
<code>correct</code>-Option explizit aktiviert oder deaktiviert
werden:</p>
<pre><code>##     A  B
## I  10  8
## II  4 16</code></pre>
<p>Ohne Korrektur wird <span class="math inline">\(\alpha =
0.05\)</span> unterschritten:</p>
<pre class="r"><code>chisq.test(samples, correct = FALSE)</code></pre>
<pre><code>## 
##  Pearson's Chi-squared test
## 
## data:  samples
## X-squared = 5.1471, df = 1, p-value = 0.02329</code></pre>
<p>Mit Korrektur wird <span class="math inline">\(\alpha = 0.05\)</span>
nicht unterschritten:</p>
<pre class="r"><code>chisq.test(samples, correct = TRUE)</code></pre>
<pre><code>## 
##  Pearson's Chi-squared test with Yates' continuity correction
## 
## data:  samples
## X-squared = 3.7325, df = 1, p-value = 0.05336</code></pre>
</div>
</div>
</div>
</div>
<div id="multiplizität" class="section level1">
<h1>Multiplizität</h1>
<p>Wenn mit erhobenen Daten mehrere Tests durchgeführt werden, gilt für
jeden Test (“Endpunkt”) ein eigenes <span class="math inline">\(\alpha\)</span>-Fehlerniveau (“Per-Comparison
Error Rate”, PCER).</p>
<p><span class="math display">\[\alpha_1 = \alpha_2 = \ldots = \alpha_k
= 0.05\]</span></p>
<p>Insgesamt bilden diese dann die “Family-Wise Error Rate” (FWER), die
deutlich höher ausfallen kann, da die Wahrscheinlichkeiten <span class="math inline">\(1-\alpha_i\)</span>, also dafür, sich
korrekterweise für <span class="math inline">\(H_0\)</span> zu
entscheiden, entsprechend der Kettenregel multipliziert werden.</p>
<p><span class="math display">\[(1-\alpha_1) \cdot (1-\alpha_2) \cdot
\ldots \cdot (1-\alpha_k) = (1-\alpha_i)^k\]</span></p>
<p>Bei <span class="math inline">\(\alpha = 0.05\)</span> und 5
Endpunkten:</p>
<p><span class="math display">\[(1 - 0.05)^5 = 0.95^5 \approx
0.774\]</span> <span class="math display">\[1-0.774 = 0.226 =
\alpha_{FWER}\]</span></p>
<p>Bei 14 Endpunkten und <span class="math inline">\(\alpha =
0.05\)</span> wird eine FWER von 50% überschritten:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-50-1.png" width="768" style="display: block; margin: auto;"></p>
<div id="bonferroni-korrektur" class="section level2">
<h2>Bonferroni-Korrektur</h2>
<ul>
<li>bestimmt <span class="math inline">\(\alpha_i\)</span>, so dass
<span class="math inline">\(\alpha_{FWER} \le 0.05\)</span> wird.</li>
</ul>
<p>Für <span class="math inline">\(k\)</span> unabhängige Endpunkte:</p>
<p><span class="math display">\[\alpha_i =
\frac{\alpha_{FWER}}{k}\]</span> <strong>Beispiel: <span class="math inline">\(\alpha_{FWER} = 0.05\)</span> und <span class="math inline">\(k = 3\)</span></strong></p>
<p><span class="math display">\[\alpha_i = \frac{0.05}{3} \approx 0.0167
\]</span></p>
<p><span class="math display">\[1 - (1- 0.0167)^3 \approx 0.049 \le
0.05\]</span></p>
<p><strong>Beispiel: Zwei Endpunkte in Form von zwei gerichteten
Alternativhypothesen <span class="math inline">\(H_{1,1}\)</span> und
<span class="math inline">\(H_{1,2}\)</span> gegenüber Nullhypothese
<span class="math inline">\(H_{0,1}\)</span></strong></p>
<p><em>(analog zu einer ungerichteten <span class="math inline">\(H_1\)</span>, wo <span class="math inline">\(\alpha\)</span> ebenfalls auf beide Seiten
aufgeteilt wird. Siehe <a href="#zweiseitiger-signifikanztest">Zweiseitiger
Signifikanztest</a>)</em></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-51-1.png" width="768" style="display: block; margin: auto;"></p>
<p><span class="math inline">\(\overline{x}_1\)</span> liegt über dem
kritischen Wert für <span class="math inline">\(\alpha_i =
0.025\)</span> in positiver Richtung während <span class="math inline">\(\overline{x}_2\)</span> nicht unterhalb des
kritischen Wertes in negativer Richtung liegt.</p>
<p><span class="math inline">\(H_{1,1}\)</span> kann also akzeptiert
werden, <span class="math inline">\(H_{1,2}\)</span> jedoch nicht.</p>
</div>
<div id="holm-bonferroni-korrektur" class="section level2">
<h2>Holm-Bonferroni-Korrektur</h2>
<p><span class="math inline">\(k\)</span> Unabhängige Endpunkte werden
aufsteigend nach p-Wert sortiert.</p>
<p><span class="math display">\[\alpha_i = \frac{\alpha_{FWER}}{k - (i -
1)}\]</span></p>
<p><span class="math display">\[\alpha_1 = \frac{\alpha_{FWER}}{k},
\alpha_2 = \frac{\alpha_{FWER}}{k - 1}, \alpha_3 =
\frac{\alpha_{FWER}}{k - 2}, \dots, \alpha_k =
\frac{\alpha_{FWER}}{1}\]</span></p>
</div>
<div id="fallback-prozedur" class="section level2">
<h2>Fallback-Prozedur</h2>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(k\)</span> unabhängige Endpunkte werde
<em>a priori</em> nach Wichtigkeit sortiert.</li>
<li>
<span class="math inline">\(\alpha\)</span> Fehler (z.B.) 5% wird
frei auf Endpunkte verteilt.</li>
<li>Endpunkte werden der Reihe nach getestet</li>
</ol>
<ul>
<li><p><span class="math inline">\(p_i &gt; \alpha_i \rightarrow
\alpha_i = 0\)</span>, nicht signifikant</p></li>
<li>
<p><span class="math inline">\(p_i \le \alpha_i \rightarrow
\alpha^*_{i + 1} = \alpha_{i + 1} + \alpha_{i}\)</span></p>
<p>“unverbrauchter” <span class="math inline">\(\alpha\)</span>-Fehler
wird an folgenden Test vererbt</p>
</li>
</ul>
<p>Beispiel:</p>
<pre><code>## # A tibble: 5 × 5
##   Endpunkt alpha     p `alpha*` signifikant
##      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;lgl&gt;      
## 1        1 0.03  0.01     0.03  TRUE       
## 2        2 0.01  0.03     0.04  TRUE       
## 3        3 0.005 0.05     0.045 FALSE      
## 4        4 0.003 0.002    0.003 TRUE       
## 5        5 0.002 0.004    0.005 TRUE</code></pre>
<p>Durch die “Vererbung” des <span class="math inline">\(\alpha\)</span>-Fehlers werden einige Tests
signifikant, die bei einfacher Aufteilung der Fehlerwahrscheinlichkeit
nicht als signifikant gelten könnten. Insgesamt beleibt aber <span class="math inline">\(\alpha_{FWER} \le 5\%\)</span>.</p>
</div>
</div>
<div id="varianzanalyse-anova" class="section level1">
<h1>Varianzanalyse (ANOVA)</h1>
<p>Zweck der ANOVA ist es, aufzuklären, ob die Variation zwischen
Stichproben, z.B. Versuchsarmen (Kontrollgruppe vs. Treatment-Gruppe),
auf die experimentelle Manipulation zurückzuführen ist, oder zufällige
Variation ist, die auch auftreten würde, wenn mehrere Zufallsstichproben
aus der gleichen Population gezogen würden.</p>
<div id="voraussetzungen" class="section level2">
<h2>Voraussetzungen</h2>
<ul>
<li>
<p><strong>unabhängige Variable in Faktorstufen</strong></p>
<p>UV muss in diskreten Faktorstufen vorliegen, damit sich eindeutige
Gruppen bilden lassen.</p>
</li>
<li>
<p><strong>Homooskedastizität</strong></p>
<p>Die Varianzen der einzelnen Gruppen dürfen sich nicht
unterscheiden</p>
<p>In R mittels <code>leveneTest</code> im Paket
<code>car</code></p>
</li>
<li><p><strong>Normalverteilung der Residuen</strong></p></li>
</ul>
</div>
<div id="einfaktorielle-varianzanalyse" class="section level2">
<h2>Einfaktorielle Varianzanalyse</h2>
<div id="messwertezerlegung" class="section level3">
<h3>Messwertezerlegung</h3>
<ul>
<li><p>Messwert eines Merkmals einer Versuchsperson <span class="math inline">\(m\)</span>, unter Versuchsbedingung <span class="math inline">\(j\)</span>: <span class="math inline">\(x_{mj}\)</span></p></li>
<li><p>Durchschnittlicher Messwert aller VP unter Bedingung <span class="math inline">\(j\)</span>: <span class="math inline">\(\overline{x}_j\)</span></p></li>
<li>
<p>Abweichung vom Durchschnitt der Bedingungsgruppe <span class="math inline">\(j\)</span>: <span class="math inline">\(\overline{x}_j - x_{jm} = e_{mj}\)</span></p>
<p><span class="math inline">\(e\)</span>: Fehlerwert, auch Residuum
genannt: die Variation von Messwerten, die übrig bleibt, nachdem alle
systematischen Anteile der Variation entfernt wurden</p>
</li>
</ul>
<p><span class="math display">\[x_{mj}=\overline{x}_j +
e_{mj}\]</span></p>
<p>Der Messwert <span class="math inline">\(x_{mj}\)</span> wird zerlegt
in den Gruppenmittelwert <span class="math inline">\(\overline{x}_j\)</span> und das Residuum <span class="math inline">\(e_{mj}\)</span>.</p>
<div id="effekt-von-faktorstufen" class="section level4">
<h4>Effekt von Faktorstufen</h4>
<p>Der Effekt <span class="math inline">\(t_j\)</span> jeder Faktorstufe
(Bedingung) ist die Abweichung des jeweiligen Gruppenmittelwertes <span class="math inline">\(\overline{x}_j\)</span> vom Gesamtmittelwert <span class="math inline">\(\overline{x}\)</span>:</p>
<p><span class="math display">\[t_j = \overline{x}_j -
\overline{x}\]</span> Der Effekt <span class="math inline">\(t_j\)</span> ist <em>nur bedingt
interpretierbar</em>, da er sowohl eine systematische Abhängigkeit von
der Faktorstufe <span class="math inline">\(j\)</span> haben kann, aber
auch durch Stichprobenfehler entstehen kann.</p>
<p>Der Messwert <span class="math inline">\(x_{mj}\)</span> einer
einzelnen Versuchsperson <span class="math inline">\(m\)</span> unter
Bedingung <span class="math inline">\(j\)</span> wird also zerlegt in
den Gesamtmittelwert <span class="math inline">\(\overline{x}\)</span>
(Grundniveau), den Effekt der Bedingung <span class="math inline">\(t_j\)</span> und das Residuum der Person selbst
<span class="math inline">\(e_{mj}\)</span>:</p>
<p><span class="math display">\[x_{mj} = \overline{x} + t_j +
e_{mj}\]</span></p>
</div>
</div>
<div id="quadratsummenzerlegung" class="section level3">
<h3>Quadratsummenzerlegung</h3>
<p><strong>Quadratsumme</strong>: Maß der Variation (analog zur Varianz,
nur ohne Einfluss der Stichprobengröße)</p>
<p><span class="math display">\[QS_{total} =
\sum_{j=1}^{J}{\sum_{m=1}^{n_j}{(x_{mj} - \overline{x})^2}}\]</span></p>
<p><span class="math inline">\(J\)</span>: Anzahl der Faktorstufen</p>
<p><span class="math inline">\(n_j\)</span>: Anzahl Individuen in der
jeweiligen Faktorgruppe</p>
<p><strong>Quadratsumme zwischen der Gruppen:</strong></p>
<p><span class="math display">\[QS_{zw} =
\sum_{j=1}^{J}{\sum_{m=1}^{n_j}{(\overline{x}_{j} -
\overline{x})^2}}\]</span></p>
<p>In <span class="math inline">\((\overline{x}_{j} -
\overline{x})\)</span> kommt <span class="math inline">\(m\)</span>
nicht mehr vor. <span class="math inline">\(QS_{zw}\)</span> ist also
unabhängig von der Variation die nur durch die einzelnen
Versuchspersonen verursacht wird. Also lässt sich <span class="math inline">\(QS_{zw}\)</span> vereinfachen als, weil <span class="math inline">\((\overline{x}_{j} - \overline{x})\)</span> jeweils
für jedes <span class="math inline">\(m\)</span> gleich ist:</p>
<p><span class="math display">\[QS_{zw} = \sum_{j=1}^{J}{n_j \cdot
(\overline{x}_{j} - \overline{x})^2}\]</span></p>
<p><strong>Quadratsumme innerhalb der Gruppen:</strong></p>
<p><span class="math display">\[QS_{inn} =
\sum_{j=1}^{J}{\sum_{m=1}^{n_j}{(x_{mj} -
\overline{x}_{j})^2}}\]</span></p>
<p>Hier taucht <span class="math inline">\(\overline{x}\)</span> nicht
mehr auf und die Abweichungen der Faktorgruppen vom Gesamtmittelwert
haben keinen Einfluss mehr.</p>
<p><strong>Die Gesamtquadratsumme entspricht der Summe der
Teilquadratsummen:</strong></p>
<p><span class="math display">\[QS_{total} = QS_{zw} +
QS_{inn}\]</span></p>
<p>Die Teilquadratsummen stellen ein Maß dafür dar, wie viel Varianz
durch den Effekt des jeweiligen Faktors bzw. die Residuen individuellen
Versuchspersonen erklärt werden.</p>
<p><span class="math inline">\(QS_{zw}\)</span>: Quadratsumme des
Effektes</p>
<p><span class="math inline">\(QS_{inn}\)</span>: Quadratsumme der
Residuen</p>
</div>
<div id="effektgrößenschätzer-hateta2" class="section level3">
<h3>Effektgrößenschätzer <span class="math inline">\(\hat{\eta}^2\)</span>
</h3>
<p><span class="math inline">\(\eta\)</span>: Eta</p>
<p>Das Verhältnis der Effekt-Quadratsumme zur Gesamtquadratsumme stellt
dar, welcher Anteil der Gesamtvarianz durch den Effekt aufgeklärt
wird.</p>
<p><span class="math display">\[\hat{\eta}^2 =
\frac{QS_{zw}}{QS_{total}}\]</span></p>
<p><span class="math inline">\(\hat{\eta}^2\)</span> kann auch direkt
aus dem empirischen F-Wert berechnet werden (siehe <a href="#f-test">F-Test</a>):</p>
<p><span class="math display">\[\hat{\eta}^2 = \frac{F \cdot df_{zw}}{F
\cdot df_{zw} + df_{inn}}\]</span></p>
<p><span class="math inline">\(\hat{\eta}^2 = 0\)</span>: Variation
entsteht komplett aus den Residuen und es gibt keinen gemessenen
Effekt.</p>
<p><span class="math inline">\(\hat{\eta}^2 = 1\)</span>: Variation
stammt vollständig vom Effekt, keine Residuen.</p>
</div>
<div id="effektgrößenschätzer-hatomega2" class="section level3">
<h3>Effektgrößenschätzer <span class="math inline">\(\hat{\omega}^2\)</span>
</h3>
<p><span class="math inline">\(\omega\)</span>: Omega</p>
<p><span class="math inline">\(\hat{\eta}^2\)</span> ist kein
erwartungstreuer Schätzer für <span class="math inline">\(\eta^2\)</span>, da die zugrundeliegende
Zählerquadratsumme <span class="math inline">\(QS_{zw}\)</span>
Stichprobenfehler enthält.</p>
<p><span class="math inline">\(\hat{\omega}^2\)</span> enthält diese
Überschätzung von <span class="math inline">\(\eta^2\)</span> nicht.</p>
<p><span class="math display">\[\hat{\omega}^2 = \frac{QS_{zw} - (J - 1)
\cdot MQS_{inn}}{QS_{total} + MQS_{inn}}\]</span></p>
</div>
<div id="effektgröße-phi2-signal-rausch-verhältnis" class="section level3">
<h3>Effektgröße <span class="math inline">\(\phi^2\)</span>,
Signal-Rausch-Verhältnis</h3>
<p><span class="math inline">\(\phi\)</span>: Phi</p>
<p>In der Population ist <span class="math inline">\(\phi^2\)</span> der
Quotient aus Effektvarianz und Residualvarianz:</p>
<p><span class="math display">\[\phi^2 =
\frac{\sigma_{\tau}^2}{\sigma_{\epsilon}^2}\]</span></p>
<p><span class="math inline">\(\phi^2\)</span> lässt sich auch aus <span class="math inline">\(\eta^2\)</span> berechnen:</p>
<p><span class="math display">\[\phi^2 = \frac{\eta^2}{1 -
\eta^2}\]</span></p>
<p>Analog gilt für den Schätzer <span class="math inline">\(\hat{\phi}^2\)</span>:</p>
<p><span class="math display">\[\hat{\phi}^2 = \frac{\hat{\eta}^2}{1 -
\hat{\eta}^2}\]</span></p>
<div id="konventionen-für-phi2" class="section level4">
<h4>Konventionen für <span class="math inline">\(\phi^2\)</span>:</h4>
<ul>
<li>
<span class="math inline">\(\phi^2 \approx 0.01\)</span>: kleiner
Effekt</li>
<li>
<span class="math inline">\(\phi^2 \approx 0.0625\)</span>:
mittlerer Effekt</li>
<li>
<span class="math inline">\(\phi^2 \approx 0.16\)</span>: großer
Effekt</li>
</ul>
</div>
</div>
<div id="effektgröße-phi" class="section level3">
<h3>Effektgröße <span class="math inline">\(\phi\)</span>
</h3>
<p>Auch <span class="math inline">\(f\)</span> genannt</p>
<p><span class="math display">\[\phi = f = \sqrt{\phi^2}\]</span></p>
<p><span class="math inline">\(\phi\)</span> ist leichter
interpretierbar als <span class="math inline">\(\phi^2\)</span>, da es
Vielfache der Standardabweichung <span class="math inline">\(\sigma\)</span> des Merkmals angibt.</p>
</div>
<div id="effektgröße-lambda" class="section level3">
<h3>Effektgröße <span class="math inline">\(\lambda\)</span>
</h3>
<p><span class="math inline">\(\lambda\)</span>: Lambda</p>
<p><span class="math inline">\(\lambda\)</span> ist der
Nicht-Zentralitäts-Parameter der F-Verteilung. Je größer <span class="math inline">\(\lambda\)</span>, umso weiter nach rechts
verschoben und flacher ist die Dichtefunktion der F-Verteilung:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-53-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Die Kurve für <span class="math inline">\(\lambda = 0\)</span>
(“zentrale F-Verteilung”) ist die Verteilung unter der Nullhypothese dar
während die Kurve mit <span class="math inline">\(\lambda \gt 0\)</span>
die Alternativhypothese unter Annahme eines Effektes darstellt.</p>
<p><span class="math display">\[\lambda = n \cdot
\frac{\sigma_{\tau}^2}{\sigma_{\epsilon}^2} = n \cdot
\phi^2\]</span></p>
</div>
<div id="beziehungen-zwischen-effektgrößenschätzern" class="section level3">
<h3>Beziehungen zwischen Effektgrößenschätzern</h3>
<p><span class="math display">\[\hat{\lambda} = n \cdot \hat{\phi}^2 = n
\cdot \frac{\hat{\eta}^2}{1 - \hat{\eta}^2}\]</span></p>
<p><span class="math display">\[\hat{\eta}^2 =
\frac{\hat{\lambda}}{\hat{\lambda} + n}\]</span></p>
<p><span class="math display">\[\hat{\phi}^2 =
\frac{\hat{\lambda}}{n}\]</span> Für die Effektgrößen in der Population
gelten die Formeln analog ohne Schätzer.</p>
</div>
<div id="konfidenzintervalle-der-effektgrößen" class="section level3">
<h3>Konfidenzintervalle der Effektgrößen</h3>
<p>Es wird meistens das Konfidenzintervall für eine Effektgröße
berechnet und dann je nach Bedarf in eine der anderen Effektgrößen
umgerechnet.</p>
<p>Das Konfidenzintervall für <span class="math inline">\(\hat{\eta}^2\)</span> kann in R mit der Funktion
<code>ci.pvaf</code> (Paket MBESS) ermittelt werden.</p>
<p><em>(CI: confidence interval, PVAF: proportion of variance accounted
for)</em></p>
<pre class="r"><code>df1 &lt;- 2
df2 &lt;- 20
n &lt;- 100
f_v &lt;- 6

ci.pvaf(F.value = f_v, df.1 = df1, df.2 = df2, N = n, conf.level = 0.95) -&gt; ci_result
ci_result</code></pre>
<pre><code>## $Lower.Limit.Proportion.of.Variance.Accounted.for
## [1] 0.007685688
## 
## $Probability.Less.Lower.Limit
## [1] 0.025
## 
## $Upper.Limit.Proportion.of.Variance.Accounted.for
## [1] 0.2357811
## 
## $Probability.Greater.Upper.Limit
## [1] 0.025
## 
## $Actual.Coverage
## [1] 0.95</code></pre>
<p>Dargestellt als F-Verteilungen mit <span class="math inline">\(\lambda\)</span>-Konfidenzintervall:</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-55-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
<div id="schätzung-der-populationsparameter" class="section level3">
<h3>Schätzung der Populationsparameter</h3>
<div id="schätzung-des-populationsmittelwertes" class="section level4">
<h4>Schätzung des Populationsmittelwertes</h4>
<p><span class="math display">\[\hat{\mu} = \overline{x} =
\frac{\sum_{j=1}^J{\sum_{m=1}^{n_j}{x_{mj}}}}{n}\]</span></p>
<p>Der Gesamtmittelwert aller Messungen <span class="math inline">\(x_{mj}\)</span> ist der Schätzer für den
Mittelwert der Population <span class="math inline">\(\hat{\mu}\)</span>.</p>
</div>
<div id="schätzung-des-effektes-tau_j" class="section level4">
<h4>Schätzung des Effektes <span class="math inline">\(\tau_j\)</span>
</h4>
<p><span class="math display">\[\hat{\tau_j} = t_j = x_{mj} -
\overline{x}\]</span></p>
</div>
<div id="schätzung-der-varianz-der-residuen-in-der-population" class="section level4">
<h4>Schätzung der Varianz der Residuen in der Population</h4>
<p>Die geschätzte Varianz der Residuen in der Population <span class="math inline">\(\hat{\sigma}_\epsilon^2\)</span> entspricht der
mittleren Quadratsumme <span class="math inline">\(MQS_{inn}\)</span>
innerhalb der einzelnen Bedingungen <span class="math inline">\(MQS_{j}\)</span>:</p>
<p><span class="math display">\[MQS_{j} =
\frac{\sum_{m-1}^{n_j}{(x_{mj}-\overline{x})^2}}{n_j - 1}\]</span></p>
<p><span class="math display">\[\hat{\sigma}_\epsilon^2 = MQS_{inn} =
\frac{\sum_{j=1}^{J}{MQS_j}}{J}\]</span></p>
<p>Beim unterschiedlich großen Gruppen wird ein gewichtetes
arithmetisches Mittel der <span class="math inline">\(MQS_j\)</span>
berechnet:</p>
<p><span class="math display">\[\hat{\sigma}_\epsilon^2 = MQS_{inn} =
\frac{\sum_{j=1}^{J}{MQS_j \cdot (n_j -
1)}}{\sum_{j=1}^J{n_j-1}}\]</span></p>
<p>Das lässt sich vereinfachen als:</p>
<p><span class="math display">\[\hat{\sigma}_\epsilon^2 = MQS_{inn} =
\frac{QS_{inn}}{n-J}\]</span></p>
</div>
</div>
</div>
<div id="hypothesenprüfung-in-der-varianzanalyse" class="section level2">
<h2>Hypothesenprüfung in der Varianzanalyse</h2>
<p>Wenn <span class="math inline">\(H_0\)</span> gilt, und kein Effekt
zwischen den Faktorgruppen besteht, so sind <span class="math inline">\(MQS_{zw}\)</span> und <span class="math inline">\(MQS_{inn}\)</span> beides erwartungstreue Schätzer
der Varianz der Residuen in der Population <span class="math inline">\(\hat{\sigma}^2_\epsilon\)</span>, da außer den
Residuen keine andere Quelle für Varianz vorhanden ist.</p>
<p>Je mehr <span class="math inline">\(MQS{zw}\)</span> von <span class="math inline">\(MQS_{inn}\)</span> abweicht, umso mehr spricht das
dafür, dass die Nullhypothese nicht haltbar ist.</p>
<p><span class="math display">\[MQS_{zw} =
\frac{QS_{zw}}{J-1}\]</span></p>
<div id="f-test" class="section level3">
<h3>F-Test</h3>
<p>Die F-Statistik ist ein Maß dafür, wie stark <span class="math inline">\(MQS_{zw}\)</span> von <span class="math inline">\(MQS_{inn}\)</span> abweicht:</p>
<p><span class="math display">\[F =
\frac{MQS_{zw}}{MQS_{inn}}\]</span></p>
<p><span class="math inline">\(F\)</span> folgt der F-Verteilung. Diese
hat zwei Parameter:</p>
<ul>
<li>
<p>Freiheitsgrade des Kennwertes im Zähler, hier <span class="math inline">\(MQS_{zw}\)</span></p>
<p><span class="math inline">\(df_{zw} = J-1\)</span></p>
</li>
<li>
<p>Freiheitsgrade des Kennwertes in Nenner, hier <span class="math inline">\(MQS_{inn}\)</span></p>
<p><span class="math inline">\(df_{inn} = n-J\)</span></p>
</li>
</ul>
<p>Geprüft wird der empirische F-Wert also gegen die Verteilung <span class="math inline">\(F(df_{zw}; df_{inn})\)</span>. Wenn der kritische
F-Wert für das festgelegte <span class="math inline">\(\alpha\)</span>-Niveau erreicht wird, ist die
Nullhypothese zu verwerfen.</p>
<p>Der F-Test <strong>prüft nur die globale Nullhypothese</strong>, also
dass ALLE Effekte <span class="math inline">\(\tau_j\)</span> in der
Population 0 sind. Er gibt keine Auskunft darüber, welche
Mittelwertunterschiede zwischen welchen Faktorstufen signifikant
sind.</p>
<div id="beispiel-für-f-test" class="section level4">
<h4>Beispiel für F-Test</h4>
<p>Zwei Faktorgruppen (Studienarme), je 10 Versuchspersonen, <span class="math inline">\(J = 2, n_j = 10\)</span></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-56-1.png" width="768" style="display: block; margin: auto;"></p>
<p><strong>Gesamtquadratsumme <span class="math inline">\(QS_{total}\)</span>:</strong></p>
<pre class="r"><code>samples %&gt;%
  summarize(
    QS_total= sum( (x - mean(x))^2 )
  ) %&gt;% pull(1) -&gt; QS_total

QS_total</code></pre>
<pre><code>## [1] 41.86613</code></pre>
<p><strong>Quadratsumme zwischen den Faktorgruppen <span class="math inline">\(QS_{zw}\)</span>:</strong></p>
<pre class="r"><code>samples %&gt;% group_by(j) %&gt;%
  mutate(
    x_j = mean(x),
  ) %&gt;% ungroup() %&gt;%
  summarize(
    QS_zw = sum( (x_j - mean(x))^2 )
  ) %&gt;% pull(1) -&gt; QS_zw

QS_zw</code></pre>
<pre><code>## [1] 16.27101</code></pre>
<p><strong>Quadratsumme innerhalb der Gruppen <span class="math inline">\(QS_{inn}\)</span>:</strong></p>
<pre class="r"><code>samples %&gt;% group_by(j) %&gt;%
  mutate(
    x_j = mean(x)
  ) %&gt;% ungroup() %&gt;%
  summarize(
    QS_inn = sum( (x - x_j)^2 )
  ) %&gt;% pull(1) -&gt; QS_inn

QS_inn</code></pre>
<pre><code>## [1] 25.59512</code></pre>
<p><strong>Additivität der Quadratsummen:</strong></p>
<pre class="r"><code>QS_total == QS_zw + QS_inn</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p><strong>Varianzaufklärung <span class="math inline">\(\eta^2\)</span>:</strong></p>
<pre class="r"><code>eta_sq = QS_zw / QS_total
eta_sq</code></pre>
<pre><code>## [1] 0.3886438</code></pre>
<p>Der Effekt zwischen den Faktorstufen klärt 38.9% der Varianz auf.</p>
<p><strong>Hypothesenprüfung:</strong></p>
<pre class="r"><code>MQS_zw &lt;- QS_zw / (J - 1)
MQS_zw</code></pre>
<pre><code>## [1] 16.27101</code></pre>
<pre class="r"><code>MQS_inn &lt;- QS_inn / (n_total - J)
MQS_inn</code></pre>
<pre><code>## [1] 1.421951</code></pre>
<p>Empirischer F-Wert:</p>
<pre class="r"><code>f_emp &lt;- MQS_zw / MQS_inn
f_emp</code></pre>
<pre><code>## [1] 11.44274</code></pre>
<p>Freiheitsgrade:</p>
<pre class="r"><code>df_zw &lt;- J - 1
df_inn &lt;- n_total - J
list(df_zw = df_zw, df_inn = df_inn)</code></pre>
<pre><code>## $df_zw
## [1] 1
## 
## $df_inn
## [1] 18</code></pre>
<p>F-Verteilung und Vergleich mit kritischem F-Wert bei <span class="math inline">\(\alpha = 0.05\)</span>:</p>
<pre class="r"><code>f_crit &lt;- qf(0.95, df1 = df_zw, df2 = df_inn)

ggplot() +
  xlim(2.5, 13) +
  geom_function(fun = df, args = list(df1 = df_zw, df2 = df_inn)) +
  stat_function(fun = df, args = list(df1 = df_zw, df2 = df_inn),
                geom = "area",
                fill = colors[1], alpha = 0.3,
                xlim = c(f_crit, 13)) +
  geom_vline(xintercept = f_emp, color = colors[2]) +
  annotate("text", label = paste("F =", round(f_emp,2)), x = 10, y = 0.025, hjust = 0, color = colors[2]) +
  labs(x = "F-Wert", y = "Wahrscheinlichkeitsdichte") +
  theme_custom</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-66-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Der empirische F-Wert überschreitet den kritischen F-Wert für <span class="math inline">\(\alpha = 0.05\)</span>. Die Nullhypothese wird
also verworfen. Es besteht ein signifikanter Unterschied zwischen den
Faktorgruppen, der sich nicht durch zufällige Variation erklären
lässt.</p>
</div>
</div>
<div id="automatische-durchführung-in-r" class="section level3">
<h3>Automatische Durchführung in R</h3>
<p>Die <code>aov()</code> Funktion ist standardmäßig verfügbar.</p>
<p>Es muss eine Formel angegeben werden, die den Zusammenhang zwischen
unabhängigen und abhängigen Variablen beschreibt, hier z.B.
<code>x ~ j</code> (Messwert <span class="math inline">\(x\)</span> in
Abhängigkeit von Faktor <span class="math inline">\(j\)</span>).</p>
<pre class="r"><code>aov(x ~ j, data = samples) %&gt;% summary</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value  Pr(&gt;F)   
## j            1  16.27  16.271   11.44 0.00332 **
## Residuals   18  25.59   1.422                   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<div id="zweifaktorielle-varianzanalyze" class="section level2">
<h2>Zweifaktorielle Varianzanalyze</h2>
<p>Zusätzlich zum ersten Faktor <span class="math inline">\(A\)</span>
und einem zweiten Faktor <span class="math inline">\(B\)</span>, die die
Haupteffekte verursachen können, kommt noch die Interaktion <span class="math inline">\(A \times B\)</span> hinzu. Die Gesamtquadratsumme
$QS_{total} wird bei zwei Faktoren zerlegt in:</p>
<ul>
<li><span class="math inline">\(QS_A\)</span></li>
<li><span class="math inline">\(QS_B\)</span></li>
<li><span class="math inline">\(QS_{A \times B}\)</span></li>
<li><span class="math inline">\(QS_{inn}\)</span></li>
</ul>
<p>Für die Quadratsummen der Haupteffekte werden die Abweichungen der
Mittelwerte in ALLEN Gruppen der gleichen Faktorstufe auf dem jeweiligen
Faktor vom Gesamtmittelwert bestimmt.</p>
<p>Für Faktor <span class="math inline">\(A\)</span> mit <span class="math inline">\(j\)</span> Stufen:</p>
<p><span class="math display">\[QS_A =
\sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{(\overline{x}_j -
\overline{x})^2}}}\]</span></p>
<p>Vereinfacht, da Variation der <span class="math inline">\(n_{Zelle}\)</span> Messwerte in jeder Zelle
gemittelt werden:</p>
<p><em>(Vorausgesetzt alle Zellen enthalten gleich viele
Messwerte)</em></p>
<p><span class="math display">\[QS_A = n_{Zelle} \cdot K
\cdot\sum_{j=1}^J{}{(\overline{x}_j - \overline{x})^2}\]</span></p>
<p>Für Faktor <span class="math inline">\(B\)</span> analog:</p>
<p><span class="math display">\[QS_B =
\sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{(\overline{x}_k -
\overline{x})^2}}} = n_{Zelle} \cdot J
\cdot\sum_{k=1}^K{}{(\overline{x}_k - \overline{x})^2} \]</span></p>
<p>Die Quadratsumme des Interaktionseffektes <span class="math inline">\(QS_{A \times B}\)</span> ergibt sich, indem die
Mittelwertabweichungen der Haupteffekte <span class="math inline">\(A\)</span> und <span class="math inline">\(B\)</span> von der Mittelwertabweichung in jeder
Zelle abgezogen werden:</p>
<p><span class="math display">\[QS_{A \times B} =
\sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{((\overline{x}_{jk} -
\overline x) - (\overline x_j - \overline x) - (\overline x_k -
\overline{x}))^2}}}\]</span></p>
<p>Auch hier lässt sich vereinfachen:</p>
<p><span class="math display">\[QS_{A \times B} = n_{Zelle} \cdot
\sum_{k=1}^K{\sum_{j=1}^J{((\overline{x}_{jk} - \overline x) -
(\overline x_j - \overline{x}) - (\overline x_k -
\overline{x}))^2}}\]</span></p>
<div id="nicht-partiielles-effektstärkenmaß-hateta2" class="section level3">
<h3>Nicht-partiielles Effektstärkenmaß: <span class="math inline">\(\hat{\eta}^2\)</span>
</h3>
<p>Genau wie in der einfaktoriellen Varianzanalyse ist <span class="math inline">\(\hat{\eta}^2\)</span> das Verhältnis von
Effektquadratsumme zu Gesamtquadratsumme.</p>
<p><span class="math display">\[\hat{\eta}_A^2 =
\frac{QS_A}{QS_{total}}\]</span> <span class="math display">\[\hat{\eta}_B^2 = \frac{QS_B}{QS_{total}}\]</span>
<span class="math display">\[\hat{\eta}_{A \times B}^2 = \frac{QS_{A
\times B}}{QS_{total}}\]</span></p>
<p>Das nicht-partielle <span class="math inline">\(\hat{\eta}^2\)</span>
hat das Problem, dass es nur Auskunft darüber gibt, wie viel der
Gesamtvarianz in einer konkreten Untersuchung ein Faktor oder eine
Interaktion aufklärt. Es ermöglicht keinen Vergleich mit anderen
Untersuchungen, die den gleichen Faktor enthalten aber zusätzlich noch
weitere, die nicht in beiden Untersuchungen vorhanden sind.</p>
</div>
<div id="partielles-effektgrößenmaß-hateta_p2" class="section level3">
<h3>Partielles Effektgrößenmaß <span class="math inline">\(\hat{\eta}_p^2\)</span>
</h3>
<p>Das partielle <span class="math inline">\(\hat{\eta}_p^2\)</span> ist
das Verhältnis einer Effektquadratsumme und einer Teilquadratsumme, die
Effekt und Residuum enthält:</p>
<p><span class="math display">\[\hat{\eta}_{pA}^2 = \frac{QS_{A}}{QS_{A}
+ QS_{inn}}\]</span></p>
<p><em>(analog für Effekte <span class="math inline">\(B\)</span> und
<span class="math inline">\(A \times B\)</span>)</em></p>
</div>
<div id="schätzung-der-haupteffekte" class="section level3">
<h3>Schätzung der Haupteffekte</h3>
<p><span class="math display">\[\tau_{b_j} = \hat{\tau}_{b_j} =
\overline{x}_j - \overline {x}\]</span></p>
<p><span class="math display">\[\tau_{b_k} = \hat{\tau}_{b_k} =
\overline{x}_k - \overline {x}\]</span></p>
<p><span class="math display">\[\tau_{b_{(A \times B)_{jk}}} =
\hat{\tau}_{b_k} = (\overline{x}_{jk} - \overline {x}) -
(\overline{x}_{j} - \overline {x}) - (\overline{x}_{k} - \overline
{x})\]</span></p>
</div>
<div id="schätzung-des-residuums" class="section level3">
<h3>Schätzung des Residuums</h3>
<p><span class="math display">\[\hat{\epsilon}_{mjk} = x_{mjk} -
\overline x_{jk}\]</span></p>
</div>
<div id="schätzung-der-populationsresidualvarianz" class="section level3">
<h3>Schätzung der Populationsresidualvarianz</h3>
<p><span class="math display">\[\hat{\sigma}^2_{\epsilon} =
\frac{\sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{(x_{mjk} -
\overline x_{jk})^2}}}}{J \cdot K \cdot (n_{Zelle} - 1)}\]</span></p>
</div>
<div id="hypothesenprüfung-bei-zweifaktorieller-varianzanalyse" class="section level3">
<h3>Hypothesenprüfung bei zweifaktorieller Varianzanalyse</h3>
<div id="zerlegung-der-freiheitsgrade" class="section level4">
<h4>Zerlegung der Freiheitsgrade</h4>
<p><span class="math display">\[df_{zw} = df_A + df_B + df_{A \times B}
= J \cdot K - 1\]</span></p>
<p><span class="math display">\[df_A = J - 1\]</span> <span class="math display">\[df_B = K - 1\]</span> <span class="math display">\[df_{inn} = J \cdot K \cdot (n_{Zelle} -
1)\]</span></p>
<p>daraus folgt:</p>
<p><span class="math display">\[df_{A \times B} = (J \cdot K - 1) - (J -
1) - (K - 1)\]</span> <span class="math display">\[df_{A \times B} = (J
- 1) \cdot (K - 1)\]</span></p>
<p><span class="math display">\[df_{total} = df_A + df_B + df_{A \times
B} +df_{inn}\]</span></p>
<p>Entsprechende mittlere Quadratsummen und F-Werte wie bei
einfaktorieller ANOVA:</p>
<p><span class="math display">\[MQS_{inn} =
\frac{QS_{inn}}{df_{inn}}\]</span></p>
<p><span class="math display">\[\begin{align*}
MQS_A &amp;= \frac{QS_A}{df_A} \\
F_A &amp;= \frac{MQS_A}{MQS_{inn}}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
MQS_B &amp;= \frac{QS_B}{df_B} \\
F_B &amp;= \frac{MQS_B}{MQS_{inn}}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
MQS_{A \times B} &amp;= \frac{QS_{A \times B}}{df_{A \times B}} \\
F_{A \times B} &amp;= \frac{MQS_{A \times B}}{MQS_{inn}}
\end{align*}\]</span></p>
<p>F-Tests und Konfidenzintervalle funktionieren genau wie bei der
einfaktoriellen Varianzanalyse.</p>
</div>
<div id="hypothesenpaare" class="section level4">
<h4>Hypothesenpaare</h4>
<ul>
<li>
<p>Haupteffekt <span class="math inline">\(A\)</span></p>
<p><span class="math inline">\(H_0: \mu_j - \mu = 0\)</span> bzw. <span class="math inline">\(\tau_{A_j} = 0\)</span></p>
<p><span class="math inline">\(H_1: \mu_j = \mu \neq 0\)</span> bzw.
<span class="math inline">\(\tau_{A_j} \neq 0\)</span></p>
</li>
<li>
<p>Haupteffekt <span class="math inline">\(B\)</span></p>
<p><span class="math inline">\(H_0: \mu_k - \mu = 0\)</span> bzw. <span class="math inline">\(\tau_{B_k} = 0\)</span></p>
<p><span class="math inline">\(H_1: \mu_k = \mu \neq 0\)</span> bzw.
<span class="math inline">\(\tau_{B_k} \neq 0\)</span></p>
</li>
<li>
<p>Interaktion <span class="math inline">\(A \times B\)</span></p>
<p><span class="math inline">\(H_0: \mu_{jk} - \mu_j - \mu_k =
0\)</span> bzw. <span class="math inline">\(\tau_{(A \times B)_{jk}} =
0\)</span></p>
<p><span class="math inline">\(H_1: \mu_{jk} - \mu_j - \mu_k \neq
0\)</span> bzw. <span class="math inline">\(\tau_{(A \times B)_{jk}}
\neq 0\)</span></p>
</li>
</ul>
</div>
</div>
</div>
<div id="varianzanalyse-mit-messwiederholung" class="section level2">
<h2>Varianzanalyse mit Messwiederholung</h2>
<p>Sowohl bei einfaktorieller als auch zweifaktorieller ANOVA können
Messwiederholungen der gleichen Versuchspersonen mit berücksichtigt
werden.</p>
<p>Hierzu wird die Versuchsperson selbst als Faktor mit Haupteffekt
eingeführt und es findet eine weitere Quadratsummenzerlegung statt:</p>
<p><span class="math display">\[QS_{zw} = QS_{zwA} +
QS_{zwP}\]</span></p>
<p><span class="math inline">\(QS_{zwA}\)</span>: Quadratsumme der
Variation zwischen den Stufen des Faktors <span class="math inline">\(A\)</span></p>
<p><span class="math inline">\(QS_{zwP}\)</span>: Quadratsumme der
Variation zwischen Versuchspersonen</p>
<p><span class="math inline">\(QS_{res}\)</span> bezeichnet die
verbleibende residuale Quadratsumme, die auch die Variation zwischen
Messzeitpunkten der jeweils gleichen Versuchsperson enthält.</p>
<p>Das partielle <span class="math inline">\(\hat{\eta}^2_p\)</span>
gibt dann Auskunft darüber, welcher Anteil der Gesamt Varianz NUR durch
den Faktor <span class="math inline">\(A\)</span> aufgeklärt wird:</p>
<p><span class="math display">\[\hat{\eta}^2_p =
\frac{QS_{zwA}}{QS_{zwA} + QS_{res}}\]</span></p>
<p>Messwiederholung ist sowohl auf einfaktorielle als auch
zweifaktorielle ANOVA anwendbar.</p>
</div>
<div id="populationsmodell-der-varianzanalyse" class="section level2">
<h2>Populationsmodell der Varianzanalyse</h2>
<p>In der Population ergibt sich der Messwert aus dem Gesamtmittelwert
addiert mit allen Haupt- und Interaktionseffekten, sowie dem
Residuum:</p>
<p><span class="math display">\[x_{mjk} = \mu + \tau_{a_j} + \tau_{b_k}
+ \tau_{(A \times B)_{jk}} + \epsilon_{mjk}\]</span></p>
<p><span class="math inline">\(\rightarrow\)</span> Grundlage für
allgemeines lineares Modell!</p>
</div>
</div>
<div id="allgemeines-lineares-modell" class="section level1">
<h1>Allgemeines Lineares Modell</h1>
<ul>
<li>Oberbegriff für eine generisches statistisches Modell zur Prognose
bzw. Erklärung von metrischen abhängigen Variablen</li>
</ul>
<p>Student-T-Test und Varianzanalyse sind z.B. Sonderfälle dieses
Modells.</p>
<div id="einfache-lineare-regression" class="section level2">
<h2>Einfache lineare Regression</h2>
<p>Bei der linearen Regression wird versucht, eine Gerade so zu legen,
dass deren mittlerer Abstand zu den empirischen Messwerten möglichst
gering ist.</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-68-1.png" width="768" style="display: block; margin: auto;"></p>
<p><strong>Modellgleichung mit einer unabhängigen
Variablen:</strong></p>
<p>In einer Stichprobe:</p>
<p><span class="math display">\[Y = b_0 + b_1 \cdot X_1 + E\]</span></p>
<p>In der Population:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 \cdot X_1 +
\epsilon\]</span></p>
<ul>
<li>
<span class="math inline">\(b_0\)</span>/<span class="math inline">\(\beta_0\)</span>: Regressionskonstante,
Schnittpunkt mit der Y-Achse, “Intercept”</li>
<li>
<span class="math inline">\(b_1\)</span>/<span class="math inline">\(\beta_1\)</span>: Regressionsgewicht, Steigung der
Regressionsgeraden, “Slope”</li>
</ul>
<p>Der Abstand der Messpunkte zur Regressionsgeraden sind die
Residuen:</p>
<pre class="r"><code>samples %&gt;% ggplot(aes(x = x, y = y - y_fit)) +
  geom_point() +
  geom_segment(aes(xend = x, yend = 0), color = colors[1], alpha = 0.4) +
  labs(y = "Residuum") +
  theme_custom</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-69-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Der Mittelwert der Residuen ist immer 0.</p>
<p>Die Varianz der Residuen wird auch als <strong>Fehlervarianz</strong>
bezeichnet, da die angibt, wie weit die empirischen Werte um die
Regressionsgerade streuen und damit, wie ungenau die Vorhersagen des
Modells sind.</p>
<p>Die Standardabweichung der Residuen ist der
<strong>Standardschätzfehler</strong>. Sie ist in der Stichprobe
allerdings kein erwartungstreuer Schätzer des Standardschätzfehlers in
der Population.</p>
<div id="bestimmung-der-regressionskoeffizienten" class="section level3">
<h3>Bestimmung der Regressionskoeffizienten</h3>
<p>Die Bedingung, dass der Abstand der Messpunkte zur Regressionsgeraden
minimal sein soll, ist am besten erfüllt wenn <span class="math inline">\(b1\)</span> aus der Produkt-Moment-Korrelation der
beiden Variablen sowie ihrer Stichprobenstandardabweichungen <span class="math inline">\(s_X\)</span> und <span class="math inline">\(z_Y\)</span> bestimmt wird:</p>
<p><span class="math display">\[b_1 = r_{XY} \cdot
\frac{s_Y}{s_X}\]</span></p>
<p><span class="math display">\[r_{XY} = \frac{1}{n} \cdot \sum_{m =
1}^n{z_X \cdot z_Y}\]</span> <em><span class="math inline">\(z_X\)</span> und <span class="math inline">\(z_Y\)</span> sind die Z-transformierten Werte der
Variablen.</em></p>
<p>Bei zwei Z-standardisierten Variablen ist das Regressionsgewicht
gleich der Produkt-Moment-Korrelation, weil die
Stichprobenstandardabweichungen beide 1 sind.</p>
<p>Die Regressionskonstante <span class="math inline">\(b_0\)</span>
ergibt sich dann wie folgt:</p>
<p><span class="math display">\[b_0 = \overline{y} - b_1 \cdot
\overline{x}\]</span></p>
</div>
<div id="standardfehler-der-modellparameter" class="section level3">
<h3>Standardfehler der Modellparameter</h3>
<p><strong>Erwartungsstreuer Schätzer des
Standardschätzfehlers:</strong></p>
<p><span class="math display">\[\hat{\sigma}_e = \sqrt{\frac{1}{n-2}
\cdot \sum{(y_m - \hat{y}_m)^2}}\]</span> <span class="math inline">\(y_m - \hat{y}_m\)</span> ist die Abweichung des
tatsächlichen Messwertes vom modellierten Wert, also das Residuum.</p>
<p><strong>Schätzer der Standardfehler der
Regressionskoeffizienten:</strong></p>
<p><span class="math display">\[\hat{\sigma}_{\beta_0} = \hat{\sigma}_e
\cdot \sqrt{\frac{1}{n} + \frac{\overline{x}^2}{n \cdot
s^2_X}}\]</span></p>
<p><span class="math display">\[\hat{\sigma}_{\beta_1} =
\sqrt{\frac{\hat{\sigma_e}^2}{n \cdot s_X^2}}\]</span></p>
</div>
<div id="alternative-wege-zur-bestimmung-der-regressionskoeffizienten" class="section level3">
<h3>Alternative Wege zur Bestimmung der Regressionskoeffizienten</h3>
<div id="kriterium-der-kleinsten-quadrate" class="section level4">
<h4>Kriterium der kleinsten Quadrate</h4>
<p>Die Regressionskoeffizienten werden so geschätzt, dass die Summe der
quadrierten Abweichungen der tatsächlichen Messwerte von den
modellierten Werten minimal wird.</p>
<p><span class="math display">\[\sum_{m=1}^n{(y_m - \hat{y}_m)^2}
\rightarrow min\]</span></p>
</div>
<div id="likelihood-maximierung" class="section level4">
<h4>Likelihood-Maximierung</h4>
<p>Die Grundannahme, dass die abhängige Variable in der Population
normalverteilt ist, führt dazu, dass sie wie folgt modelliert werden
kann:</p>
<p><span class="math display">\[y \sim Normal(\beta_0 + \beta_1 \cdot
x_m, \sigma_e^2)\]</span></p>
<p>Die tatsächliche Ausprägung folgt einer Normalverteilung, bei der der
Mittelwert der Vorhersagewert des linearen Modells und die
Standardabweichung der Standardschätzfehler ist.</p>
<p>Für diese Normalverteilung kann die Likelihood der empirisch
beobachteten Daten bestimmt werden.</p>
<p>Es werden dann die Regressionskoeffizienten gesucht, für die die
Likelihood bzw. Log(Likelihood) maximal werden.</p>
<p><strong>Sowohl die Likelihood-Maximierung, als auch das Kriterium der
kleinsten Quadrate sind Optimierungsprobleme, die sich kaum von Hand
lösen lassen und durch Computer numerisch gelöst werden
müssen.</strong></p>
</div>
</div>
<div id="hypothesenprüfung-bei-einfacher-linearer-regression" class="section level3">
<h3>Hypothesenprüfung bei einfacher linearer Regression</h3>
<p><span class="math inline">\(H_{00}\)</span>: <span class="math inline">\(\beta_1 = 0\)</span>, <span class="math inline">\(H_{01}\)</span>: <span class="math inline">\(\beta_1 \neq 0\)</span></p>
<p><span class="math display">\[t = \frac{b_1 -
\beta_{10}}{\hat{\sigma}_{b_1}} \sim Student(df = n - 2)\]</span></p>
<p>(<span class="math inline">\(\beta_{10} = 0\)</span> bei spezieller
Nullhypothese <span class="math inline">\(H_0: \beta_1 = 0\)</span>)</p>
<p><span class="math inline">\(H_{10}\)</span>: <span class="math inline">\(\beta_0 = \beta_{00}\)</span>, <span class="math inline">\(H_{11}\)</span>: <span class="math inline">\(\beta_0 \neq \beta_{00}\)</span></p>
<p><span class="math display">\[t = \frac{b_0 -
\beta_{00}}{\hat{\sigma}_{b_0}} \sim Student(df = n - 2)\]</span></p>
</div>
<div id="konfidenzintervalle-für-regressionskoeffizienten" class="section level3">
<h3>Konfidenzintervalle für Regressionskoeffizienten</h3>
<p><span class="math display">\[b_1 \pm t_{(1-\frac{\alpha}{2}; n-2)}
\cdot \hat{\sigma}_{b_1}\]</span></p>
<p><span class="math display">\[b_0 \pm t_{(1-\frac{\alpha}{2}; n-2)}
\cdot \hat{\sigma}_{b_0}\]</span></p>
</div>
<div id="einfache-lineare-regression-in-r" class="section level3">
<h3>Einfache lineare Regression in R</h3>
<pre class="r"><code>lm(y ~ x, samples) -&gt; lm1

summary(lm1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = samples)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7060 -0.9742 -0.4539  0.9479  3.0728 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  7.25267    1.35524   5.352 4.37e-05 ***
## x            0.30451    0.05124   5.943 1.27e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.625 on 18 degrees of freedom
## Multiple R-squared:  0.6624, Adjusted R-squared:  0.6437 
## F-statistic: 35.32 on 1 and 18 DF,  p-value: 1.267e-05</code></pre>
<p>Extraktion der Koeffizienten:</p>
<pre class="r"><code>coef(lm1)</code></pre>
<pre><code>## (Intercept)           x 
##    7.252667    0.304506</code></pre>
<p>Konfidenzintervalle der Koeffizienten:</p>
<pre class="r"><code>confint(lm1, level = 0.95)</code></pre>
<pre><code>##                 2.5 %     97.5 %
## (Intercept) 4.4054111 10.0999220
## x           0.1968588  0.4121532</code></pre>
<p>Residuen:</p>
<pre class="r"><code>resid(lm1)</code></pre>
<pre><code>##            1            2            3            4            5            6 
## -0.810005726 -1.669324066 -0.782480228  1.163274890  0.924972643  0.005258351 
##            7            8            9           10           11           12 
## -1.220609279 -0.634036491  3.072819146  1.016600629 -0.523908529 -1.250597374 
##           13           14           15           16           17           18 
##  0.222625960 -2.706005447 -0.383962449 -0.892032207  3.008439197  2.631282829 
##           19           20 
##  0.436793706 -1.609105554</code></pre>
<p>Modellierte(“fitted”) Werte:</p>
<pre class="r"><code>fitted(lm1)</code></pre>
<pre><code>##        1        2        3        4        5        6        7        8 
## 11.83282 17.67453 13.81424 13.29164 15.79802 15.81898 11.43628 12.98896 
##        9       10       11       12       13       14       15       16 
## 15.57430 16.06184 14.97508 14.91121 15.17624 15.38830 18.22633 17.87727 
##       17       18       19       20 
## 11.31583 16.72605 18.49644 12.85313</code></pre>
</div>
</div>
<div id="multiple-lineare-regression" class="section level2">
<h2>Multiple lineare Regression</h2>
<ul>
<li><p>Vorhersage von metrischen Endpunkten bei mehreren unabhängigen
Variablen</p></li>
<li><p>Kontrolle von Störvariablen</p></li>
<li>
<p>Berücksichtigung von Redundanzen zwischen Merkmalen</p>
<p>z.B. Wenn UVs nicht unabhängig voneinander sind</p>
</li>
</ul>
<div id="modellgleichung" class="section level3">
<h3>Modellgleichung</h3>
<p>In der Stichprobe:</p>
<p><span class="math display">\[Y = b_0 + b_1 \cdot X_1 + b_2 \cdot X_2
+ \dots + b_j \cdot X_j + E\]</span></p>
<p>In der Population:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 \cdot X_1 +
\beta_2 \cdot X_2 + \dots + \beta_j \cdot X_J + \epsilon\]</span></p>
</div>
<div id="bestimmung-der-regressionskoeffizienten-1" class="section level3">
<h3>Bestimmung der Regressionskoeffizienten</h3>
<p>Ähnlich wie bei einfacher linearer Regression werden die
Koeffizienten so geschätzt, dass die Summer der quadrierten Abweichungen
von den modellierten Werten minimal wird:</p>
<p><span class="math display">\[\sum_{m=1}^n{(y_m - \hat{y}_m)^2}
\rightarrow min\]</span> Geometrische Sicht:</p>
<p>Bei zwei unabhängigen Variablen erzeugt das Regressionsmodell eine
Ebene (statt einer Geraden bei einfacher Regression). Die Ebene wird so
platziert, dass der Abstände aller empirischen Messpunkte zur Ebene
minimal werden.</p>
<p>Die Regressionskoeffizienten können auch analog zur einfacher
Regression berechnet werden, was aber unüblich ist. (siehe EGS Kapitel
19.3.3)</p>
<p>Stattdessen erfolgt die Bestimmung bei multipler Regression eher
numerisch.</p>
</div>
<div id="kompensatorisches-modell" class="section level3">
<h3>Kompensatorisches Modell</h3>
<p>Mehrere Kombinationen vom UVs können in der multiplen Regression zur
gleichen Ausprägung der AV führen.</p>
<p>Beispiel:</p>
<ul>
<li><span class="math inline">\(\beta_0 = 10\)</span></li>
<li><span class="math inline">\(\beta_1 = 2\)</span></li>
<li><span class="math inline">\(\beta_2 = 1\)</span></li>
</ul>
<p><span class="math display">\[10 + 2 \cdot 2 + 1 \cdot 0.5 = 10 + 2
\cdot 1 + 1 \cdot 2.5 = 14.5\]</span></p>
<p>Für <span class="math inline">\(X_1 = 2; X_2 = 0.5\)</span> sowie für
<span class="math inline">\(X_1 = 1; X_2 = 2.5\)</span> ergibt sich das
gleiche <span class="math inline">\(Y = 14.5\)</span>.</p>
<p>Die UVs können also ihre Einflüsse gegenseitig kompensieren.</p>
</div>
<div id="dummy-kodierung" class="section level3">
<h3>Dummy Kodierung</h3>
<p>Bei UVs, die mehr als zwei Faktorstufen beinhalten, wird jede eine
Referenzkategorie definiert und alle anderen Stufen als
“Dummy”-Variablen kodiert die jeweils Ausprägungen 0 oder 1 haben.</p>
<div id="schritte-der-dummy-kodieruung" class="section level4">
<h4>Schritte der Dummy-Kodieruung</h4>
<ol style="list-style-type: decimal">
<li>
<p>Referenzkategorie zuweisen (vollkommen willkürlich)</p>
<p>Die Faktorstufe der Referenzkategorie hat auf allen Dummy-Variablen
den Wert 0.</p>
</li>
<li>
<p>Allen anderen Kategorien der unabhängigen Faktorvariablen werden
Dummy-Werte zugewiesen, so dass:</p>
<ul>
<li>jede Kategorie in nur einer Dummy-Variablen den Wert 1 hat</li>
<li>jede Dummy-Variable nur für eine Kategorie den Wert 1 hat und sonst
überall 0</li>
</ul>
</li>
</ol>
</div>
</div>
<div id="interpretation-von-multiplen-regressionsgewichten" class="section level3">
<h3>Interpretation von multiplen Regressionsgewichten</h3>
<div id="als-regressionsgewicht-einer-bedingten-einfacher-regression." class="section level4">
<h4>Als Regressionsgewicht einer bedingten einfacher Regression.</h4>
<p>Alle UVs bis auf eine werden konstant gehalten.</p>
<p>Nur noch eine UV und ihr Regressionsgewicht haben Einfluss auf <span class="math inline">\(Y\)</span>.</p>
<p>Entspricht dem Modell für eine Subgruppe an Personen, die
hinsichtlich aller UVs bis auf eine identisch sind.</p>
</div>
<div id="als-regressionsgewicht-zweier-regressionsredsiduen" class="section level4">
<h4>Als Regressionsgewicht zweier Regressionsredsiduen</h4>
<p>Es werden zwei Residuen von einfachen Regressionen gebildet:</p>
<ul>
<li>Residuum von <span class="math inline">\(Y(X_2)\)</span> (<span class="math inline">\(Y\)</span> in Abhängigkeit von <span class="math inline">\(X_2\)</span>
</li>
<li>Residuum von <span class="math inline">\(X_1(X_2)\)</span> (<span class="math inline">\(X_1\)</span> in Abhängigkeit von <span class="math inline">\(X_2\)</span>
</li>
</ul>
<p>Diese Residuen werden dann als unabhängige und abhängige Variable in
einer weiteren einfacher Regression verwendet.</p>
<p>Dadurch werden die betrachtete UV und die AV von Abhängigkeiten zu
anderen UVs bereinigt. Das Regressionsgewicht quantifiziert den Einfluss
der betrachteten UV, der nicht bereits durch andere UVs erklärt
wird.</p>
</div>
</div>
<div id="inkrementelle-varianzaufklärung" class="section level3">
<h3>Inkrementelle Varianzaufklärung</h3>
<p>Der Determinationskoeffizient <span class="math inline">\(R^2\)</span> ist wie in der einfacher Regression
ein Maß dafür, wie präzise die Vorhersagen des Modells sind.</p>
<p>Mit zumessender Anzahl UVs wird das Modell präziser:</p>
<p><span class="math display">\[R^2_{Y|X_1} \lt R^2_{Y|X_1,X_2} \lt
R^2_{Y|X_1, X_2, X_3}\]</span></p>
</div>
<div id="punktschätzung-der-varianzaufklärung" class="section level3">
<h3>Punktschätzung der Varianzaufklärung</h3>
<p><strong><span class="math inline">\(R^2\)</span> ist kein
erwartungstreuer Schätzer der Varianzaufklärung in der Population <span class="math inline">\(\rho^2\)</span>.</strong></p>
<p>Beispiel: 100 Stichproben zu je <span class="math inline">\(n
=10\)</span> Messpunkten von drei komplett unabhängigen Variablen <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span> und <span class="math inline">\(Y\)</span>. Alle Variablen sind zufällig generiert
und normalverteilt.</p>
<p>Korrelationsplot der ersten 20 Stichproben (200 Messwerte):</p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-75-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Es sollte also keine Korrelation zwischen den Variablen geben und
damit auch keine Varianzaufklärung. Entsprechend sollte in jeder
Stichprobe <span class="math inline">\(R^2 \approx 0\)</span>
gelten.</p>
<pre class="r"><code>samples %&gt;% group_by(stichprobe) %&gt;% mutate(
  Rsq = summary(lm(Y ~ X1 + X2))$r.squared
) -&gt; samples</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-77-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Durchschnittlicher Determinationskoeffizient, <span class="math inline">\(\overline{R}^2\)</span>:</p>
<pre><code>## [1] 0.2174016</code></pre>
<p>Es muss eine Adjustierung vorgenommen werden, damit <span class="math inline">\(\rho^2\)</span> nicht überschätzt wird.</p>
<div id="wherry-1-adjustierung" class="section level4">
<h4>Wherry-1-Adjustierung</h4>
<p><span class="math display">\[\hat{\rho}^2 = 1 - \frac{n-1}{n-k-1}
\cdot (1-R^2)\]</span> (<span class="math inline">\(n\)</span>:
Stichprobengröße, <span class="math inline">\(k\)</span>: Anzahl der
Regressionsgewichte)</p>
<p>Diese wird standardmäßig in R verwendet.</p>
<pre class="r"><code>samples %&gt;% group_by(stichprobe) %&gt;% mutate(
  Rsq_adj = summary(lm(Y ~ X1 + X2))$adj.r.squared
) -&gt; samples</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-80-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Durchschnittlicher adjustierter Determinationskoeffizient, <span class="math inline">\(\overline{R}_{Wherry-1}^2\)</span>:</p>
<pre><code>## [1] -0.006197947</code></pre>
</div>
<div id="adjustierung-nach-olkin-pratt-2017" class="section level4">
<h4>Adjustierung nach Olkin &amp; Pratt (2017)</h4>
<p><span class="math display">\[\hat{\rho}^2 = 1= \frac{n-3}{n-k-1}
\cdot ((1-R^2) + \frac{2}{n-k-1} \cdot (1-R^2))\]</span></p>
<p>In R kann die Olkin-Pratt-Adjustierung mit dem Paket
<code>semEff</code> berechnet werden:</p>
<pre class="r"><code>library(semEff)</code></pre>
<pre><code>## 
## Attaching package: 'semEff'</code></pre>
<pre><code>## The following object is masked from 'package:lme4':
## 
##     getData</code></pre>
<pre class="r"><code># Berechnung ist sehr langsam, daher hier nur für erste Stichprobe
samples %&gt;% filter(stichprobe == 1) %&gt;% mutate(
  Rsq_OP = R2(lm(Y ~ X1 + X2, data = .), adj.type = "olkin-pratt")[2]
) -&gt; samples</code></pre>
<p>Durchschnittlicher adjustierter Determinationskoeffizient, <span class="math inline">\(\overline{R}_{Olkin-Pratt}^2\)</span>:</p>
<pre class="r"><code>mean(samples$Rsq_OP)</code></pre>
<pre><code>## [1] 0</code></pre>
</div>
</div>
<div id="hypothesenprüfung-mit-multipler-linearer-regression" class="section level3">
<h3>Hypothesenprüfung mit multipler linearer Regression</h3>
<div id="hypothesen-zum-gesamtmodell-globale-hypothesen" class="section level4">
<h4>Hypothesen zum Gesamtmodell, globale Hypothesen</h4>
<p><span class="math display">\[H_0: \beta_1 = \beta_2 = \dots = \beta_k
= 0 \rightarrow H_o: \rho^2 = 0\]</span></p>
<p>Alle Regressionsgewichte sind null, also wird keine Varianz durch die
unabhängigen Variablen aufgeklärt.</p>
<p><span class="math display">\[H_1: \beta_j \ne 0 \rightarrow \rho^2
\ne 0\]</span></p>
<p>Mindestens eines der Regressionsgewichte <span class="math inline">\(\beta_j\)</span> ist nicht null, also wird ein
Teil der Varianz aufgeklärt.</p>
<p>Verteilung der Prüfgröße unter der Nullhypothese:</p>
<p><span class="math display">\[F = \frac{n-k-1}{k} \cdot
\frac{R^2}{1-R^2} \sim F(df_1 = k, df_2 = n-k-1)\]</span></p>
</div>
<div id="hypothesen-über-einzelne-regressionsgewichte" class="section level4">
<h4>Hypothesen über einzelne Regressionsgewichte</h4>
<p><span class="math display">\[H_0 : \beta_j = 0\]</span></p>
<p>Verteilung der Prüfgröße unter <span class="math inline">\(H_0\)</span>:</p>
<p><span class="math display">\[T =
\frac{\hat{\beta}_j}{\hat{\sigma}_{\beta_j}} \sim Student(df =
n-k-1)\]</span></p>
<p>Das geschätzte Regressionsgewicht <span class="math inline">\(\hat\beta_j\)</span> wird am <a href="#standardfehler-der-modellparameter">geschätzten
Standardfehler</a> <span class="math inline">\(\hat\sigma_{\beta_j}\)</span> standardisiert und
folgt dann eine Student-T-Verteilung.</p>
</div>
<div id="hypothesen-über-modellvergleiche" class="section level4">
<h4>Hypothesen über Modellvergleiche</h4>
<p>Die “Nützlichkeit” einer oder mehrerer unabhängiger Variablen kann
durch den Vergleich eines uneingeschränkten Modells, welches alle UVs
enthält, mit einem eingeschränkten Modell, in dem eine oder mehrere UV
fehlen, bestimmt werden.</p>
<p>Indem UVs entfernt werden, verschwindet ihre Varianzaufklärung im nun
größeren Residuum.</p>
<p>Verglichen werden letztendlich die Determinationskoeffizienten der
Modelle <span class="math inline">\(R_u^2\)</span> (uneingeschränkt) und
<span class="math inline">\(R_e^2\)</span> (eingeschränkt).</p>
<p>Verteilung unter der Nullhypothese <span class="math inline">\(H_0:
\rho_u^2 - \rho_y^2 = 0\)</span>:</p>
<p><span class="math display">\[F = \frac{n-k_u-1}{k_u - k_e} \cdot
\frac{R_u^2 - R_e^2}{1-R_u^2} \sim F(df_1 = k_u - k_e, df_2 =
n-k_u-1)\]</span></p>
<p>Sonderfall, wenn nur eine UV entfernt wird:</p>
<p><span class="math display">\[F = (n-k_u-1) \cdot
\frac{R_u^2-R_e^2}{1-R_u^2} \sim F(df_1 = 1, df_2 = n - k_u
-1)\]</span></p>
<p>Dieser F-Wert (für nur eine entfernte UV) entspricht dem quadrierten
T-Wert aus der <a href="#hypothesen-%C3%BCber-einzelne-regressionsgewichte">Hypothesenprüfung
über einzelne Regressionsgewichte</a>. Beide Ansätze sind
äquivalent.</p>
</div>
</div>
<div id="modellvergleiche-in-r" class="section level3">
<h3>Modellvergleiche in R</h3>
<p>Beispiel:</p>
<ul>
<li>Stichprobe mit <span class="math inline">\(n=20\)</span>
</li>
<li>2 unabhängige, normalverteilte Variablen</li>
<li>
<span class="math inline">\(Y\)</span> korreliert mit <span class="math inline">\(X_1\)</span> leicht positiv und mit <span class="math inline">\(X_2\)</span> leicht negativ</li>
<li>im Datensatz ist ein simulierter Interaktionseffekt vorhanden</li>
<li>normalverteiltes Residuum</li>
</ul>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-84-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Vergleich von uneingeschränktem Modell (mit Interaktion) und
eingeschränktem (ohne Interaktion):</p>
<pre class="r"><code>lm_u &lt;- lm(Y ~ X1 * X2, samples)
lm_e &lt;- lm(Y ~ X1 + X2, samples)

anova(lm_u, lm_e)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Y ~ X1 * X2
## Model 2: Y ~ X1 + X2
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    196 3165.1                                  
## 2    197 3395.8 -1   -230.69 14.286 0.0002084 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<p>Das uneingeschränkte Modell klärt signifikant mehr Varianz auf als
das eingeschränkte. Es gibt also einen Interaktionseffekt.</p>
<p>Vergleich der Determinationskoeffizienten:</p>
<pre class="r"><code>R_u &lt;- summary(lm_u)$adj.r.squared
R_e &lt;- summary(lm_e)$adj.r.squared

dR &lt;- R_u - R_e

dR</code></pre>
<pre><code>## [1] 0.0442245</code></pre>
<div id="likelihood-quotienten-test" class="section level4">
<h4>Likelihood-Quotienten-Test</h4>
<p>Wilks’ <span class="math inline">\(\Lambda\)</span>: Quotient der
Likelihoods der empirischen Daten unter dem eingeschränkten und dem
uneingeschränkten Modell.</p>
<p><span class="math display">\[\Lambda =
\frac{Lik(Y_e)}{Lik(Y_u)}\]</span></p>
<p>Prüfgröße des Likelihood-Quotienten-Tests:</p>
<p><span class="math display">\[-2 \cdot log(\Lambda) = -2 \cdot
log(Lik(Y_e) + 2 \cdot log(Lik(Y_u))\]</span></p>
<p>Unter der Nullhypothese <span class="math inline">\(H_0: \rho^2_u -
\rho^2_e = 0\)</span> gilt asymptotisch (also bei ausreichend großen
Stichproben):</p>
<p><span class="math display">\[-2 \cdot log(\Lambda) \sim \chi^2(df =
k_u - k_e)\]</span></p>
</div>
</div>
<div id="interaktionseffekte-bei-mutlipler-linearer-regression" class="section level3">
<h3>Interaktionseffekte bei mutlipler linearer Regression</h3>
<p><span class="math display">\[Y = \beta_0 + \beta_1 \cdot X_1 +
\beta_2 \cdot X_2 + \beta_3 \cdot X_1 \cdot X_2 + \epsilon\]</span></p>
<p><span class="math inline">\(\beta_3 \cdot X_1 \cdot X_2\)</span> ist
der Interaktionsterm. <span class="math inline">\(\beta_3\)</span> ist
das Regressionsgewicht des Interaktionseffektes.</p>
<p>Durch Modellvergleiche mit eingeschränkten Modellen, die den
Interaktionsterm nicht enthalten, kann bestimmt werden, welcher Anteil
der Varianz durch die Interaktion aufgeklärt wird.</p>
<p>Beispielhypothese:</p>
<p><span class="math display">\[Y_u = \beta_0 + \beta_1 \cdot X_1 +
\beta_2 \cdot X_2 + \beta_3 \cdot X_1 \cdot X_2 + \epsilon\]</span>
<span class="math display">\[Y_e = \beta_0 + \beta_1 \cdot X_1 + \beta_2
\cdot X_2 + \epsilon\]</span> <span class="math inline">\(H_0: \rho^2_u
- \rho^2_e = 0\)</span>, die Interaktion von <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span> klärt keine zusätzliche Varianz
auf.</p>
</div>
</div>
<div id="annahmen-des-allgemeinen-linearen-modells" class="section level2">
<h2>Annahmen des allgemeinen linearen Modells</h2>
<ul>
<li>Messfehlerfreiheit der UVs</li>
<li>korrekte Spezifikation des Modells (Linearität)</li>
<li>Homoskedastizität</li>
<li>Unabhängigkeit der Residuen</li>
<li>Normalverteilung der Residuen</li>
</ul>
<div id="korrekte-spezifikation-linearität" class="section level3">
<h3>Korrekte Spezifikation, Linearität</h3>
<p><strong>Underfitting</strong>: relevante UVs fehlen im Modell</p>
<p><strong>Overfitting</strong>: irrelevante UVs, die keine Varianz
aufklären, sind im Modell enthalten.</p>
<p>Form der Abbilddung der AV auf die UVs muss korrekt sein.</p>
<p>Bei Verletzung der Annahmen:</p>
<ul>
<li>verzerrte Schätzer der Regressionsgewichte</li>
<li>erhöhter Prognosefehler</li>
<li>verringerte Teststärke</li>
<li>falsche Schlussfolgerungen</li>
</ul>
<div id="prüfung-der-linearität" class="section level4">
<h4>Prüfung der Linearität</h4>
<p>Plot der Residuen gegenüber den vorhergesagten (fitted) Werten</p>
<p><strong>Eingeschränktes Modell:</strong></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-87-1.png" width="768" style="display: block; margin: auto;"></p>
<p><strong>Uneingeschränktes Modell:</strong></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-88-1.png" width="768" style="display: block; margin: auto;"></p>
<p><strong>Die durchschnittlichen Residuen aller Kombinationen der UVs
sollten einer Geraden mit Steigung 0 folgen, wenn Linearität gegeben
ist.</strong></p>
</div>
</div>
<div id="prüfung-der-homoskedastizität" class="section level3">
<h3>Prüfung der Homoskedastizität</h3>
<div id="breusch-pagan-test-in-r" class="section level4">
<h4>Breusch-Pagan-Test in R</h4>
<p>(mit Paket <code>lmtest</code>)</p>
<pre class="r"><code>library(lmtest)</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: 'zoo'</code></pre>
<pre><code>## The following objects are masked from 'package:base':
## 
##     as.Date, as.Date.numeric</code></pre>
<pre class="r"><code>bptest(lm_u)</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  lm_u
## BP = 3.351, df = 3, p-value = 0.3406</code></pre>
<p>Wenn <span class="math inline">\(p \ge 0.05\)</span>, dann kann die
Nullhypothese, dass Homoskedastizität vorliegt, akzeptiert werden.</p>
<p><strong>Der Breusch-Pagan-Test ist auch sensitiv für eine Verletzung
der Unabhängigkeit der Residuen.</strong></p>
</div>
<div id="visuelle-prüfung-der-heteroskedastizität" class="section level4">
<h4>Visuelle Prüfung der Heteroskedastizität</h4>
<p>Plot der Residuen gegenüber den vorhergesagten (fitted) Werten.</p>
<pre class="r"><code>samples %&gt;%
  ggplot(aes(x = fit_u, y = res_u)) +
  geom_point() +
  labs(x = "Vorhersage", y = "Residuum") +
  theme_custom</code></pre>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-90-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Es sind keine offensichtlichen Unterschieden in der Varianz der
Residuen erkennbar. Damit liegt vermutlich Homoskedastizität vor, sollte
aber dennoch genau getestet werden.</p>
</div>
</div>
<div id="normalverteilung-der-residuen" class="section level3">
<h3>Normalverteilung der Residuen</h3>
<div id="shapiro-wilk-test" class="section level4">
<h4>Shapiro-Wilk-Test</h4>
<ul>
<li>testet beliebige Werte auf Normalverteilung</li>
</ul>
<pre class="r"><code>shapiro.test(samples$res_u)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  samples$res_u
## W = 0.99108, p-value = 0.2553</code></pre>
<p>Wenn <span class="math inline">\(p \ge 0.05\)</span>, dann kann
Normalverteilung der Residuen angenommen werden.</p>
</div>
<div id="visuelle-prüfung-der-normalverteilung" class="section level4">
<h4>Visuelle Prüfung der Normalverteilung</h4>
<p><strong>Histogram der Residuen</strong></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-92-1.png" width="768" style="display: block; margin: auto;"></p>
<p><strong>Q-Q-Plot, Quantil-Quantil-Diagramm</strong></p>
<p><img src="statistik-2_files/figure-html/unnamed-chunk-93-1.png" width="768" style="display: block; margin: auto;"></p>
<p>Wenn die Residuumswerte nah an der theoretischen Normalverteilung
(entlang der diagonalen Geraden) liegen, liegt vermutlich
Normalverteilung vor, sollte aber noch genau getestet werden.</p>
</div>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->



  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->


<div class="post-nav">
  <span>
    
  </span>
  <span>
    
  </span>
</div>
  </section>


    </main>
    


<footer class="background" style="--image: url('/images/lines-21.png')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    
  </div>

  <div>
    © 2024
    PHB
      |   Erstellt mit
    <a href="https://github.com/greenelab/lab-website-template">
      Lab Website Template
    </a>
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
