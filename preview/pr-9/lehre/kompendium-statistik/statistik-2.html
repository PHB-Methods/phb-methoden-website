<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  



























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>B.Sc. Psychologie Statisik II | Psychologische Methodenlehre | PHB</title>

<link rel="icon" href="">

<meta name="title" content="B.Sc. Psychologie Statisik II | Psychologische Methodenlehre | PHB">
<meta name="description" content="Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin">

<meta property="og:title" content="B.Sc. Psychologie Statisik II | Psychologische Methodenlehre | PHB">
<meta property="og:site_title" content="PHB">
<meta property="og:description" content="Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin">
<meta property="og:url" content="/preview/pr-9">
<meta property="og:image" content="/preview/pr-9/images/share.jpg">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="B.Sc. Psychologie Statisik II">
<meta property="twitter:description" content="Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin">
<meta property="twitter:url" content="/preview/pr-9">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/preview/pr-9/images/share.jpg">


  <meta name="author" content="Esther Weidauer">
  <meta property="og:type" content="article">
  <meta property="og:updated_time" content="2024-09-04T12:59:19+00:00">
  <meta property="article:published_time" content="">
  <meta property="article:modified_time" content="2024-09-04T12:59:19+00:00">
  <meta name="revised" content="2024-09-04T12:59:19+00:00">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "BlogPosting",
      "author": { "@type": "Person", "name": "B.Sc. Psychologie Statisik II" },
      "datePublished": "",
      "dateModified": "2024-09-04T12:59:19+00:00",
    
    "name": "B.Sc. Psychologie Statisik II",
    "description": "Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin",
    "headline": "B.Sc. Psychologie Statisik II",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "" }
    },
    "url": "/preview/pr-9"
  }
</script>

<link rel="alternate" type="application/rss+xml" href="/preview/pr-9/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet" media="none" onload="this.removeAttribute('media'); this.onload = null;">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/preview/pr-9/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/all.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/background.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/body.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/button.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/card.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/code.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/float.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/font.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/form.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/header.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/image.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/link.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/list.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/main.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/section.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/table.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/preview/pr-9/_scripts/anchors.js"></script>

  <script src="/preview/pr-9/_scripts/dark-mode.js"></script>

  <script src="/preview/pr-9/_scripts/fetch-tags.js"></script>

  <script src="/preview/pr-9/_scripts/search.js"></script>

  <script src="/preview/pr-9/_scripts/site-search.js"></script>

  <script src="/preview/pr-9/_scripts/table-wrap.js"></script>

  <script src="/preview/pr-9/_scripts/tooltip.js"></script>


<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

  <body>
    







<header class="background" style="--image: url('/preview/pr-9/images/lines-7.png')" data-dark="true">
  <a href="/preview/pr-9/" class="home">
    
      <span class="logo">
        
          <img src="/preview/pr-9/images/logo.png" alt="logo">
        
      </span>
    
    
      <span class="title-text" data-tooltip="Home">
        
          <span class="title">PHB</span>
        
        
          <span class="subtitle">Psychologische Methodenlehre</span>
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/preview/pr-9/team/" data-tooltip="Unser Team">
          Team
        </a>
      
    
      
        <a href="/preview/pr-9/lehre/" data-tooltip="Methodenausbildung">
          Lehre
        </a>
      
    
      
        <a href="/preview/pr-9/forschung/" data-tooltip="Forschungsprojekte">
          Forschung
        </a>
      
    
      
        <a href="/preview/pr-9/beratung/" data-tooltip="Beratung zu Methodenfragen">
          Beratung
        </a>
      
    
      
        <a href="/preview/pr-9/aktuelles/" data-tooltip="Neuigkeiten und AnkÃ¼ndigungen">
          Aktuelles
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - filter out blank sections
-->






  
  
  

  <section class="background" data-size="1">
    <!--
  background: ;
  dark: ;
  size: 1;
-->


<h1 class="center">B.Sc. Psychologie Statisik II</h1>

<div class="post-info">
  
    
    
      <span data-tooltip="Author">
        <i class="icon fa-solid fa-feather-pointed"></i>
        <span>Esther Weidauer</span>
      </span>
    
  

  
  

  

  
    <span data-tooltip="Last updated on">
      <i class="icon fa-solid fa-clock-rotate-left"></i>
      <span>September 04, 2024</span>
    </span>
  
</div>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->


<ul id="toc" class="section-nav">
<li class="toc-entry toc-h1">
<a href="#stichprobenkennwerte-verteilung">Stichprobenkennwerte-Verteilung</a>
<ul>
<li class="toc-entry toc-h2"><a href="#beispiel-mittelwert">Beispiel: Mittelwert</a></li>
<li class="toc-entry toc-h2"><a href="#standardfehler-des-mittelwertes">Standardfehler des Mittelwertes</a></li>
<li class="toc-entry toc-h2"><a href="#berechnung-des-standardfehlers-des-mittelwertes">Berechnung des Standardfehlers des Mittelwertes</a></li>
<li class="toc-entry toc-h2"><a href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes">SchÃ¤tzung des Standardfehlers des Mittelwertes</a></li>
<li class="toc-entry toc-h2"><a href="#zentraler-grenzwertsatz">Zentraler Grenzwertsatz</a></li>
</ul>
</li>
<li class="toc-entry toc-h1">
<a href="#punktsch%C3%A4tzung-von-populationsparametern">PunktschÃ¤tzung von Populationsparametern</a>
<ul>
<li class="toc-entry toc-h2"><a href="#g%C3%BCtekriterien-f%C3%BCr-parametersch%C3%A4tzung">GÃ¼tekriterien fÃ¼r ParameterschÃ¤tzung</a></li>
<li class="toc-entry toc-h2"><a href="#punktsch%C3%A4tzung-des-mittelwertes">PunktschÃ¤tzung des Mittelwertes</a></li>
<li class="toc-entry toc-h2"><a href="#punktsch%C3%A4tzung-der-varianz">PunktschÃ¤tzung der Varianz</a></li>
</ul>
</li>
<li class="toc-entry toc-h1">
<a href="#intervallsch%C3%A4tzung-von-populationsparametern">IntervallschÃ¤tzung von Populationsparametern</a>
<ul>
<li class="toc-entry toc-h2">
<a href="#konfidenzintervall-des-mittelwertes">Konfidenzintervall des Mittelwertes</a>
<ul>
<li class="toc-entry toc-h3"><a href="#konfidenzintervall-pro-stichprobe">Konfidenzintervall pro Stichprobe</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#sch%C3%A4tzung-des-konfidenzintervalls-des-mittelwertes">SchÃ¤tzung des Konfidenzintervalls des Mittelwertes</a></li>
<li class="toc-entry toc-h2"><a href="#konfidenzintervall-abg%C3%A4ngig-von-stichprobengr%C3%B6%C3%9Fe">Konfidenzintervall abgÃ¤ngig von StichprobengrÃ¶Ãe</a></li>
</ul>
</li>
<li class="toc-entry toc-h1">
<a href="#statistische-hypothesenpr%C3%BCfung">Statistische HypothesenprÃ¼fung</a>
<ul>
<li class="toc-entry toc-h2">
<a href="#signifikanztests">Signifikanztests</a>
<ul>
<li class="toc-entry toc-h3"><a href="#einseitiger-signifikanztest">Einseitiger Signifikanztest</a></li>
<li class="toc-entry toc-h3"><a href="#zweiseitiger-signifikanztest">Zweiseitiger Signifikanztest</a></li>
<li class="toc-entry toc-h3"><a href="#standardisierte-pr%C3%BCfgr%C3%B6%C3%9Fen">Standardisierte PrÃ¼fgrÃ¶Ãen</a></li>
<li class="toc-entry toc-h3"><a href="#signifikanztest-mit-empirischen-daten">Signifikanztest mit empirischen Daten</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#hypothesentests">Hypothesentests</a>
<ul>
<li class="toc-entry toc-h3"><a href="#standardisierter-effekt-cohens-delta">Standardisierter Effekt: Cohenâs $\delta$</a></li>
<li class="toc-entry toc-h3"><a href="#konfidenzintervalle-f%C3%BCr-cohens-delta">Konfidenzintervalle fÃ¼r Cohenâs $\delta$</a></li>
<li class="toc-entry toc-h3">
<a href="#einstichproben-gauss-test">Einstichproben-Gauss-Test</a>
<ul>
<li class="toc-entry toc-h4"><a href="#einstichproben-gauss-test-in-r">Einstichproben-Gauss-Test in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#einstichproben-t-test">Einstichproben T-Test</a>
<ul>
<li class="toc-entry toc-h4"><a href="#einstichproben-t-test-in-r">Einstichproben T-Test in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#einstichproben-t-test-f%C3%BCr-abh%C3%A4ngige-beobachtungen">Einstichproben T-Test fÃ¼r abhÃ¤ngige Beobachtungen</a>
<ul>
<li class="toc-entry toc-h4"><a href="#einstichproben-t-test-f%C3%BCr-abh%C3%A4ngige-beobachtungen-t-test-in-r">Einstichproben T-Test fÃ¼r abhÃ¤ngige Beobachtungen T-Test in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#einstichproben-binomialtest">Einstichproben Binomialtest</a>
<ul>
<li class="toc-entry toc-h4"><a href="#binomialtest-in-r">Binomialtest in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#zweistichproben-t-test">Zweistichproben T-Test</a>
<ul>
<li class="toc-entry toc-h4"><a href="#zweistichproben-t-test-in-r">Zweistichproben T-Test in R</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#power-und-stichprobenplanung">Power und Stichprobenplanung</a>
<ul>
<li class="toc-entry toc-h3"><a href="#stichprobenplanung-in-r">Stichprobenplanung in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#tests-f%C3%BCr-kategoriale-merkmale">Tests fÃ¼r Kategoriale Merkmale</a>
<ul>
<li class="toc-entry toc-h3"><a href="#chi2-statistik">$\chi^2$-Statistik</a></li>
<li class="toc-entry toc-h3"><a href="#cramers-v">Cramerâs $V$</a></li>
<li class="toc-entry toc-h3">
<a href="#chi2-test">$\chi^2$-Test</a>
<ul>
<li class="toc-entry toc-h4"><a href="#chi2-test-in-r">$\chi^2$-Test in R</a></li>
<li class="toc-entry toc-h4"><a href="#kontinuit%C3%A4tskorrektur">KontinuitÃ¤tskorrektur</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1">
<a href="#multiplizit%C3%A4t">MultiplizitÃ¤t</a>
<ul>
<li class="toc-entry toc-h2"><a href="#bonferroni-korrektur">Bonferroni-Korrektur</a></li>
<li class="toc-entry toc-h2"><a href="#holm-bonferroni-korrektur">Holm-Bonferroni-Korrektur</a></li>
<li class="toc-entry toc-h2"><a href="#fallback-prozedur">Fallback-Prozedur</a></li>
</ul>
</li>
<li class="toc-entry toc-h1">
<a href="#varianzanalyse-anova">Varianzanalyse (ANOVA)</a>
<ul>
<li class="toc-entry toc-h2"><a href="#voraussetzungen">Voraussetzungen</a></li>
<li class="toc-entry toc-h2">
<a href="#einfaktorielle-varianzanalyse">Einfaktorielle Varianzanalyse</a>
<ul>
<li class="toc-entry toc-h3">
<a href="#messwertezerlegung">Messwertezerlegung</a>
<ul>
<li class="toc-entry toc-h4"><a href="#effekt-von-faktorstufen">Effekt von Faktorstufen</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#quadratsummenzerlegung">Quadratsummenzerlegung</a></li>
<li class="toc-entry toc-h3"><a href="#effektgr%C3%B6%C3%9Fensch%C3%A4tzer-hateta2">EffektgrÃ¶ÃenschÃ¤tzer $\hat{\eta}^2$</a></li>
<li class="toc-entry toc-h3"><a href="#effektgr%C3%B6%C3%9Fensch%C3%A4tzer-hatomega2">EffektgrÃ¶ÃenschÃ¤tzer $\hat{\omega}^2$</a></li>
<li class="toc-entry toc-h3">
<a href="#effektgr%C3%B6%C3%9Fe-phi2-signal-rausch-verh%C3%A4ltnis">EffektgrÃ¶Ãe $\phi^2$, Signal-Rausch-VerhÃ¤ltnis</a>
<ul>
<li class="toc-entry toc-h4"><a href="#konventionen-f%C3%BCr-phi2">Konventionen fÃ¼r $\phi^2$:</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#effektgr%C3%B6%C3%9Fe-phi">EffektgrÃ¶Ãe $\phi$</a></li>
<li class="toc-entry toc-h3"><a href="#effektgr%C3%B6%C3%9Fe-lambda">EffektgrÃ¶Ãe $\lambda$</a></li>
<li class="toc-entry toc-h3"><a href="#beziehungen-zwischen-effektgr%C3%B6%C3%9Fensch%C3%A4tzern">Beziehungen zwischen EffektgrÃ¶ÃenschÃ¤tzern</a></li>
<li class="toc-entry toc-h3"><a href="#konfidenzintervalle-der-effektgr%C3%B6%C3%9Fen">Konfidenzintervalle der EffektgrÃ¶Ãen</a></li>
<li class="toc-entry toc-h3">
<a href="#sch%C3%A4tzung-der-populationsparameter">SchÃ¤tzung der Populationsparameter</a>
<ul>
<li class="toc-entry toc-h4"><a href="#sch%C3%A4tzung-des-populationsmittelwertes">SchÃ¤tzung des Populationsmittelwertes</a></li>
<li class="toc-entry toc-h4"><a href="#sch%C3%A4tzung-des-effektes-tau_j">SchÃ¤tzung des Effektes $\tau_j$</a></li>
<li class="toc-entry toc-h4"><a href="#sch%C3%A4tzung-der-varianz-der-residuen-in-der-population">SchÃ¤tzung der Varianz der Residuen in der Population</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#hypothesenpr%C3%BCfung-in-der-varianzanalyse">HypothesenprÃ¼fung in der Varianzanalyse</a>
<ul>
<li class="toc-entry toc-h3">
<a href="#f-test">F-Test</a>
<ul>
<li class="toc-entry toc-h4"><a href="#beispiel-f%C3%BCr-f-test">Beispiel fÃ¼r F-Test</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#automatische-durchf%C3%BChrung-in-r">Automatische DurchfÃ¼hrung in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#zweifaktorielle-varianzanalyze">Zweifaktorielle Varianzanalyze</a>
<ul>
<li class="toc-entry toc-h3"><a href="#nicht-partiielles-effektst%C3%A4rkenma%C3%9F-hateta2">Nicht-partiielles EffektstÃ¤rkenmaÃ: $\hat{\eta}^2$</a></li>
<li class="toc-entry toc-h3"><a href="#partielles-effektgr%C3%B6%C3%9Fenma%C3%9F-hateta_p2">Partielles EffektgrÃ¶ÃenmaÃ $\hat{\eta}_p^2$</a></li>
<li class="toc-entry toc-h3"><a href="#sch%C3%A4tzung-der-haupteffekte">SchÃ¤tzung der Haupteffekte</a></li>
<li class="toc-entry toc-h3"><a href="#sch%C3%A4tzung-des-residuums">SchÃ¤tzung des Residuums</a></li>
<li class="toc-entry toc-h3"><a href="#sch%C3%A4tzung-der-populationsresidualvarianz">SchÃ¤tzung der Populationsresidualvarianz</a></li>
<li class="toc-entry toc-h3">
<a href="#hypothesenpr%C3%BCfung-bei-zweifaktorieller-varianzanalyse">HypothesenprÃ¼fung bei zweifaktorieller Varianzanalyse</a>
<ul>
<li class="toc-entry toc-h4"><a href="#zerlegung-der-freiheitsgrade">Zerlegung der Freiheitsgrade</a></li>
<li class="toc-entry toc-h4"><a href="#hypothesenpaare">Hypothesenpaare</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#varianzanalyse-mit-messwiederholung">Varianzanalyse mit Messwiederholung</a></li>
<li class="toc-entry toc-h2"><a href="#populationsmodell-der-varianzanalyse">Populationsmodell der Varianzanalyse</a></li>
</ul>
</li>
<li class="toc-entry toc-h1">
<a href="#allgemeines-lineares-modell">Allgemeines Lineares Modell</a>
<ul>
<li class="toc-entry toc-h2">
<a href="#einfache-lineare-regression">Einfache lineare Regression</a>
<ul>
<li class="toc-entry toc-h3"><a href="#bestimmung-der-regressionskoeffizienten">Bestimmung der Regressionskoeffizienten</a></li>
<li class="toc-entry toc-h3"><a href="#standardfehler-der-modellparameter">Standardfehler der Modellparameter</a></li>
<li class="toc-entry toc-h3">
<a href="#alternative-wege-zur-bestimmung-der-regressionskoeffizienten">Alternative Wege zur Bestimmung der Regressionskoeffizienten</a>
<ul>
<li class="toc-entry toc-h4"><a href="#kriterium-der-kleinsten-quadrate">Kriterium der kleinsten Quadrate</a></li>
<li class="toc-entry toc-h4"><a href="#likelihood-maximierung">Likelihood-Maximierung</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#hypothesenpr%C3%BCfung-bei-einfacher-linearer-regression">HypothesenprÃ¼fung bei einfacher linearer Regression</a></li>
<li class="toc-entry toc-h3"><a href="#konfidenzintervalle-f%C3%BCr-regressionskoeffizienten">Konfidenzintervalle fÃ¼r Regressionskoeffizienten</a></li>
<li class="toc-entry toc-h3"><a href="#einfache-lineare-regression-in-r">Einfache lineare Regression in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#multiple-lineare-regression">Multiple lineare Regression</a>
<ul>
<li class="toc-entry toc-h3"><a href="#modellgleichung">Modellgleichung</a></li>
<li class="toc-entry toc-h3"><a href="#bestimmung-der-regressionskoeffizienten-1">Bestimmung der Regressionskoeffizienten</a></li>
<li class="toc-entry toc-h3"><a href="#kompensatorisches-modell">Kompensatorisches Modell</a></li>
<li class="toc-entry toc-h3">
<a href="#dummy-kodierung">Dummy Kodierung</a>
<ul>
<li class="toc-entry toc-h4"><a href="#schritte-der-dummy-kodieruung">Schritte der Dummy-Kodieruung</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#interpretation-von-multiplen-regressionsgewichten">Interpretation von multiplen Regressionsgewichten</a>
<ul>
<li class="toc-entry toc-h4"><a href="#als-regressionsgewicht-einer-bedingten-einfacher-regression">Als Regressionsgewicht einer bedingten einfacher Regression.</a></li>
<li class="toc-entry toc-h4"><a href="#als-regressionsgewicht-zweier-regressionsredsiduen">Als Regressionsgewicht zweier Regressionsredsiduen</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#inkrementelle-varianzaufkl%C3%A4rung">Inkrementelle VarianzaufklÃ¤rung</a></li>
<li class="toc-entry toc-h3">
<a href="#punktsch%C3%A4tzung-der-varianzaufkl%C3%A4rung">PunktschÃ¤tzung der VarianzaufklÃ¤rung</a>
<ul>
<li class="toc-entry toc-h4"><a href="#wherry-1-adjustierung">Wherry-1-Adjustierung</a></li>
<li class="toc-entry toc-h4"><a href="#adjustierung-nach-olkin--pratt-2017">Adjustierung nach Olkin &amp; Pratt (2017)</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#hypothesenpr%C3%BCfung-mit-multipler-linearer-regression">HypothesenprÃ¼fung mit multipler linearer Regression</a>
<ul>
<li class="toc-entry toc-h4"><a href="#hypothesen-zum-gesamtmodell-globale-hypothesen">Hypothesen zum Gesamtmodell, globale Hypothesen</a></li>
<li class="toc-entry toc-h4"><a href="#hypothesen-%C3%BCber-einzelne-regressionsgewichte">Hypothesen Ã¼ber einzelne Regressionsgewichte</a></li>
<li class="toc-entry toc-h4"><a href="#hypothesen-%C3%BCber-modellvergleiche">Hypothesen Ã¼ber Modellvergleiche</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#modellvergleiche-in-r">Modellvergleiche in R</a>
<ul>
<li class="toc-entry toc-h4"><a href="#likelihood-quotienten-test">Likelihood-Quotienten-Test</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#interaktionseffekte-bei-mutlipler-linearer-regression">Interaktionseffekte bei mutlipler linearer Regression</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#annahmen-des-allgemeinen-linearen-modells">Annahmen des allgemeinen linearen Modells</a>
<ul>
<li class="toc-entry toc-h3">
<a href="#korrekte-spezifikation-linearit%C3%A4t">Korrekte Spezifikation, LinearitÃ¤t</a>
<ul>
<li class="toc-entry toc-h4"><a href="#pr%C3%BCfung-der-linearit%C3%A4t">PrÃ¼fung der LinearitÃ¤t</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#pr%C3%BCfung-der-homoskedastizit%C3%A4t">PrÃ¼fung der HomoskedastizitÃ¤t</a>
<ul>
<li class="toc-entry toc-h4"><a href="#breusch-pagan-test-in-r">Breusch-Pagan-Test in R</a></li>
<li class="toc-entry toc-h4"><a href="#visuelle-pr%C3%BCfung-der-heteroskedastizit%C3%A4t">Visuelle PrÃ¼fung der HeteroskedastizitÃ¤t</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#normalverteilung-der-residuen">Normalverteilung der Residuen</a>
<ul>
<li class="toc-entry toc-h4"><a href="#shapiro-wilk-test">Shapiro-Wilk-Test</a></li>
<li class="toc-entry toc-h4"><a href="#visuelle-pr%C3%BCfung-der-normalverteilung">Visuelle PrÃ¼fung der Normalverteilung</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- math equations in RMarkdown: https://rpruim.github.io/s341/S19/from-class/MathinRmd.html -->

<h1 id="stichprobenkennwerte-verteilung">
<a class="anchor" href="#stichprobenkennwerte-verteilung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stichprobenkennwerte-Verteilung</h1>

<h2 id="beispiel-mittelwert">
<a class="anchor" href="#beispiel-mittelwert" aria-hidden="true"><span class="octicon octicon-link"></span></a>Beispiel: Mittelwert</h2>

<p>$$\overline{x} = \frac{1}{k} \sum_{i=1}^{k}\overline{x}_i$$</p>

<ul>
  <li>$k$: Anzahl gezogener Stichproben</li>
  <li>$\overline{x}_{i}$: Mittelwerte innerhalb der Stichproben</li>
  <li>$\overline{x}$: durchschnittlicher Mittelwerte der Stichproben</li>
</ul>

<p>Erwartungswert des durchschnittlichen Mittelwertes der Stichproben ist der Mittelwert der Population:</p>

<p>$$E(\overline{x}) = \mu$$</p>

<h2 id="standardfehler-des-mittelwertes">
<a class="anchor" href="#standardfehler-des-mittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Standardfehler des Mittelwertes</h2>

<p>Die Standardabweichung der Stichprobenkennwert-Verteilung wird <em>Standardfehler</em> genannt, z.B. Standardfehler des Mittelwertes: $\sigma_{\overline{x}}$</p>

<h2 id="berechnung-des-standardfehlers-des-mittelwertes">
<a class="anchor" href="#berechnung-des-standardfehlers-des-mittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Berechnung des Standardfehlers des Mittelwertes</h2>

<ul>
  <li>wird anhand der Standardabweichung der Population $\sigma$ berechnet</li>
</ul>

<p>Bei $n &lt; 5\%$ der PopulationsgrÃ¶Ãe N:</p>

<p>$$\sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}$$</p>

<p>Bei $n \ge 5\%$ der PopulationsgrÃ¶Ãe N wird die âFinite Populationâ-Korrektur eingefÃ¼hrt:</p>

<p>$$\sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}} \cdot \color{red}{\sqrt{\frac{N-n}{N-1}}}$$</p>

<p>Je grÃ¶Ãer die einzelnen StichprobengrÃ¶Ãen, umso geringer wird der Standardfehler:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-1-1.png" alt="plot of chunk unnamed-chunk-1" width="576" style="display: block; margin: auto;"></p>

<h2 id="schÃ¤tzung-des-standardfehlers-des-mittelwertes">
<a class="anchor" href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>SchÃ¤tzung des Standardfehlers des Mittelwertes</h2>

<p>Wenn die Varianz der Population $\sigma^2$ nicht bekannt ist, wird er geschÃ¤tzte Standardfehler $\hat{\sigma}_{\overline{x}}$ aus der empirischen Varianz $s^{2*}$ bestimmt:</p>

<p>$$\hat{\sigma}_{\overline{x}} = \sqrt{\frac{\hat\sigma^2_x}{n}} = \sqrt{\frac{s^{2<em>}_x}{n - 1}}$$
Wichtig: die empirische Varianz $s^{2</em>}$ ist <strong>nicht</strong> gleich der Stichprobenvarianz $s^2$, siehe <a href="#punktsch%C3%A4tzung-der-varianz">PunktschÃ¤tzung der Varianz</a>. Die Stichprobenvarianz $s^2$ enthÃ¤lt bereits die Bessel-Korrektur $n-1$ und muss entsprechend nicht nochmals in der Berechnung des geschÃ¤tzten Standardfehlers korrigiert werden:</p>

<p>$$\hat{\sigma}_{\overline{x}} = \sqrt{\frac{s^2_x}{n}}$$</p>

<p>Die Stichprobenkennwerte-Verteilung folgt dann <strong>nicht mehr</strong> der Normalverteilung sondern nach Standardisierung einer Student-t-Verteilung mit $n - 1$ Freiheitsgraden:</p>

<p>$$\frac{\overline{x} - \mu}{\hat{\sigma}_{\overline{x}}} \sim Student(df = n -1)$$</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-2-1.png" alt="plot of chunk unnamed-chunk-2" width="576" style="display: block; margin: auto;"></p>

<ul>
  <li>$Normal(\mu = 0, \sigma = 1)$ (blaue Kurve): Verteilung in der Population</li>
  <li>$Student(df = n-1)$ (grÃ¼ne Kurve): geschÃ¤tzte Populationsverteilung</li>
</ul>

<p>Mit steigendem $n$ nÃ¤hern sich die beiden Verteilungen immer weiter an.</p>

<h2 id="zentraler-grenzwertsatz">
<a class="anchor" href="#zentraler-grenzwertsatz" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zentraler Grenzwertsatz</h2>

<p>Die Stichprobenkennwerteverteilung der Mittelwerte nÃ¤hert sich mit zunehmender StichprobengrÃ¶Ãe der Normalverteilung an, unabhÃ¤ngig davon, wie das Merkmal in der Population verteilt ist.</p>

<p>1 Sample ($n = 1000$) mit uniformer Verteilung:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-3-1.png" alt="plot of chunk unnamed-chunk-3" width="576" style="display: block; margin: auto;"></p>

<p>Mittelwerteverteilung von $k = 500$ Samples mit je $n = 1000$:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-4-1.png" alt="plot of chunk unnamed-chunk-4" width="576" style="display: block; margin: auto;"></p>

<p>Verteilung nÃ¤hert sich sichtbar der Normalverteilung an.</p>

<h1 id="punktschÃ¤tzung-von-populationsparametern">
<a class="anchor" href="#punktsch%C3%A4tzung-von-populationsparametern" aria-hidden="true"><span class="octicon octicon-link"></span></a>PunktschÃ¤tzung von Populationsparametern</h1>

<p>Populationsparameter sind meist unbekannt, daher werden sie auf Basis der Statistiken (Verteilungskennwerte) einer einzelnen Stichprobe geschÃ¤tzt. (âPunktschÃ¤tzungâ, weil ein Punktwert und kein Intervall geschÃ¤tzt wird)</p>

<p><strong>Populationsparameter</strong>: Kennwert einer theoretisch unendlich groÃen Population</p>

<p><strong>Stichprobenstatistik</strong>: Kennwert einer Verteilung tatsÃ¤chlicher, empirischer Stichproben</p>

<p><strong>SchÃ¤tzer</strong>: Inferenz von der Stichprobe auf die Population</p>

<table>
  <thead>
    <tr>
      <th>Â </th>
      <th style="text-align: right">Population</th>
      <th style="text-align: right">Stichprobenstatistik</th>
      <th style="text-align: right">SchÃ¤tzer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Arithmetisches Mittel</td>
      <td style="text-align: right">$\mu$</td>
      <td style="text-align: right">$\overline{x}$</td>
      <td style="text-align: right">$\hat{\mu}$</td>
    </tr>
    <tr>
      <td>Standardabweichung (SD)</td>
      <td style="text-align: right">$\sigma$</td>
      <td style="text-align: right">$s$</td>
      <td style="text-align: right">$\hat{\sigma}$</td>
    </tr>
    <tr>
      <td>Varianz</td>
      <td style="text-align: right">$\sigma^{2}$</td>
      <td style="text-align: right">$s^{2}$</td>
      <td style="text-align: right">$\hat{\sigma}^{2}$</td>
    </tr>
    <tr>
      <td>Korrelation</td>
      <td style="text-align: right">$\rho$</td>
      <td style="text-align: right">$r$</td>
      <td style="text-align: right">$\hat{\rho}$</td>
    </tr>
    <tr>
      <td>Regressionsgewicht</td>
      <td style="text-align: right">$\beta$</td>
      <td style="text-align: right">$b$</td>
      <td style="text-align: right">$\hat{\beta}$</td>
    </tr>
  </tbody>
</table>

<h2 id="gÃ¼tekriterien-fÃ¼r-parameterschÃ¤tzung">
<a class="anchor" href="#g%C3%BCtekriterien-f%C3%BCr-parametersch%C3%A4tzung" aria-hidden="true"><span class="octicon octicon-link"></span></a>GÃ¼tekriterien fÃ¼r ParameterschÃ¤tzung</h2>

<ol>
  <li>
    <p><strong>Erwartungstreue</strong></p>

    <p>Erwartungswert des Stichprobenkennwertes entspricht dem Populationsparameter</p>
  </li>
  <li>
    <p><strong>Konsistenz</strong></p>

    <p>Stichprobenkennwert nÃ¤hert sich mit wachsender Stichprobe dem Populationsparameter</p>
  </li>
  <li>
    <p><strong>Effizienz</strong></p>

    <p>Stichprobenkennwert hat den geringsten Standardfehler unter allen erwartungstreuen SchÃ¤tzern fÃ¼r einen Populationsparameter</p>
  </li>
  <li>
    <p><strong>Suffizienz</strong></p>

    <p>Stichprobenkennwert basiert auf alles in den Daten enthaltenen Informationen</p>
  </li>
</ol>

<h2 id="punktschÃ¤tzung-des-mittelwertes">
<a class="anchor" href="#punktsch%C3%A4tzung-des-mittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>PunktschÃ¤tzung des Mittelwertes</h2>

<p>$k = 100$ Stichproben einer uniform verteilten Merkmals $x$ mit jeweils $n = 100$ Messungen.</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-5-1.png" alt="plot of chunk unnamed-chunk-5" width="576" style="display: block; margin: auto;"></p>

<p>Der Mittelwert der Stichprobenverteilung $\hat{\mu}$ (rote Linie) nÃ¤hert sich mit steigender Stichprobenzahl ($i$) dem Populationsmittelwert $\mu$ (blaue Linie) immer weiter an.</p>

<p>Der Mittelwert der Stichprobenverteilung $\hat{\mu}$ ist also ein erwartungstreuer und konsistenter SchÃ¤tzer des Populationsmittelwertes $\mu$.</p>

<h2 id="punktschÃ¤tzung-der-varianz">
<a class="anchor" href="#punktsch%C3%A4tzung-der-varianz" aria-hidden="true"><span class="octicon octicon-link"></span></a>PunktschÃ¤tzung der Varianz</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: center">empirische Varianz</th>
      <th style="text-align: center">Stichprobenvarianz</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">$s^{2*} = \frac{1}{n} \sum_{i = 1}^{n}(x_i - \overline{x})^2$</td>
      <td style="text-align: center">$s^2 = \frac{1}{n - 1} \sum_{i = 1}^{n}(x_i - \overline{x})^2$</td>
    </tr>
  </tbody>
</table>

<p>$k = 100$ Stichproben mit je $n = 100$ Messungen eines normalverteilten Merkmals:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-6-1.png" alt="plot of chunk unnamed-chunk-6" width="576" style="display: block; margin: auto;"></p>

<p>Die empirische Varianz $s^{2*}$ (rote Linie) weicht stÃ¤rker vom wahren Kennwert der Population $\sigma^{2}$ (blaue Linie) ab als die Stichproben-Varianz $s^2$ (grÃ¼ne Linie).</p>

<p>Die empirische Varianz ist kein erwartungstreuer SchÃ¤tzer der Populationsvarianz, die Stichproben-Varianz dagegen schon.</p>

<p><strong>Aber:</strong> $\sqrt{s^2}$ (Stichproben-Standardabweichung $s$) ist <strong>KEIN</strong> erwartungstreuer SchÃ¤tzer der Populations-Standardabweichung $\sigma$!</p>

<h1 id="intervallschÃ¤tzung-von-populationsparametern">
<a class="anchor" href="#intervallsch%C3%A4tzung-von-populationsparametern" aria-hidden="true"><span class="octicon octicon-link"></span></a>IntervallschÃ¤tzung von Populationsparametern</h1>

<p><strong>Konfidenzintervall</strong>: Intervall um den geschÃ¤tzten Parameter, in dem mit Wahrscheinlichkeit $1-\alpha$ der wahre Populationsparameter liegt.</p>

<h2 id="konfidenzintervall-des-mittelwertes">
<a class="anchor" href="#konfidenzintervall-des-mittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konfidenzintervall des Mittelwertes</h2>

<p>Nach dem <a href="#zentraler-grenzwertsatz">zentralem Grenzwertsatz</a> folgen die Mittelwerte der Stichproben $\overline{x}$ einer Normalverteilung mit den Parametern Populationsmittelwert $\mu$ und Standardfehler der Stichprobenmittelwerte $\sigma_{\overline{x}}$:</p>

<p>$$\overline{x} \sim Normal(\mu, \sigma_{\overline{x}})$$</p>

<p>Entsprechend folgen die z-standardisierten Mittelwerte der Stichproben der Standard-Normalverteilung:</p>

<p>$$\frac{\overline{x} - \mu}{\sigma_{\overline{x}}} \sim Normal(0,1)$$</p>

<p>Die FlÃ¤che $1 - \alpha = 0.95$ liegt im Intervall $z = [-1.96, 1.96]$ der Standard-Normalverteilung.</p>

<p>$1-\alpha$ wird auch Konfidenzkoeffizient genannt.</p>

<p>Beispiel: Stichprobe mit $n = 100$ Messungen eines normalverteilten Merkmals:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-7-1.png" alt="plot of chunk unnamed-chunk-7" width="576" style="display: block; margin: auto;"></p>

<p>Der Populationsparameter $\mu$ liegt im Intervall um den Stichprobenmittelwert $\overline{x}$ (grÃ¼ne Linie), das 95% der FlÃ¤che der Kennwertverteilung (pink) abdeckt.</p>

<p>Da es ein zweiseitiges Konfidenzintervall ist, wird an beidem Seiten der Verteilung 2.5% abgeschnitten damit insgesamt $\alpha = 5\%$ gilt.</p>

<h3 id="konfidenzintervall-pro-stichprobe">
<a class="anchor" href="#konfidenzintervall-pro-stichprobe" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konfidenzintervall pro Stichprobe</h3>

<p>$k = 100$ Stichproben zu je $n = 1000$ normalverteilten Messungen, mit zweiseitigem Konfidenzintervall $\alpha = 0.05$:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-8-1.png" alt="plot of chunk unnamed-chunk-8" width="576" style="display: block; margin: auto;"></p>

<p>Prozentsatz der Mittelwerte die mit ihrem Konfidenzintervall <strong>nicht</strong> den Populationsmittelwert abdecken, entspricht in etwa dem Fehlerniveau $\alpha = 5\%$. 4 Stichproben von $k = 100$ decken nicht den Populationsmittelwert in ihrem Konfidenzintervall ab.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">filter</span><span class="p">(</span><span class="w">
    </span><span class="n">x.mean.lower</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">x.mean.upper</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">mu</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">summarize</span><span class="p">(</span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">k</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<h2 id="schÃ¤tzung-des-konfidenzintervalls-des-mittelwertes">
<a class="anchor" href="#sch%C3%A4tzung-des-konfidenzintervalls-des-mittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>SchÃ¤tzung des Konfidenzintervalls des Mittelwertes</h2>

<p>Wenn die Standardabweichung $\sigma$ der Population nicht bekannt ist, der Standardfehler also nicht daraus abgeleitet werden kann, wird das Konfidenzintervall anhand des <a href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes">geschÃ¤tzten Standardfehlers</a> berechnet.</p>

<p>$$\overline{x} \pm t(1- \frac{\alpha}{2}, n - 1) \cdot \hat\sigma_{\overline{x}}$$</p>

<p>Stichprobe von $n = 10$ Messungen eines normalverteilten Merkmals:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-10-1.png" alt="plot of chunk unnamed-chunk-10" width="576" style="display: block; margin: auto;"></p>

<p><em>Es ist gleichgÃ¼ltig ob das Konfidenzintervall um den Populationsmittelwert oder den Stichprobenmittelwert gelegt wird. Wichtig ist, dass beide Werte im Intervall liegen. Bei t-Verteilungen ist es einfacher, das Intervall um den 0-Punkt zu legen und alle Werte entsprechend zu standardisieren.</em></p>

<h2 id="konfidenzintervall-abgÃ¤ngig-von-stichprobengrÃ¶Ãe">
<a class="anchor" href="#konfidenzintervall-abg%C3%A4ngig-von-stichprobengr%C3%B6%C3%9Fe" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konfidenzintervall abgÃ¤ngig von StichprobengrÃ¶Ãe</h2>

<p>Sowohl der Standardfehler $\sigma_{\overline{x}}$ als auch der geschÃ¤tzte Standardfehler $\hat{\sigma}_{\overline{x}}$ hÃ¤ngen von der StichprobengrÃ¶Ãe ab und werden kleiner, je grÃ¶Ãer die Stichprobe ist. Entsprechend verÃ¤ndert sich auch das Konfidenzintervall.</p>

<p>Zwei Stichproben mit $n_1 = 20$ (grau) und $n_2 = 40$ (pink) Messungen des gleichen normalverteilten Merkmals, sowie Populationsmittelwert (blau):</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-11-1.png" alt="plot of chunk unnamed-chunk-11" width="576" style="display: block; margin: auto;"></p>

<p>Die grÃ¶Ãere Stichprobe $n_2 = 40$ hat ein deutlich schmaleres Konfidenzintervall.</p>

<h1 id="statistische-hypothesenprÃ¼fung">
<a class="anchor" href="#statistische-hypothesenpr%C3%BCfung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Statistische HypothesenprÃ¼fung</h1>

<h2 id="signifikanztests">
<a class="anchor" href="#signifikanztests" aria-hidden="true"><span class="octicon octicon-link"></span></a>Signifikanztests</h2>

<p><strong>Nullhypothese $H_0$:</strong> Annahme, dass kein Unterschied zwischen zwei Parametern besteht.</p>

<p><strong>p-Wert:</strong> Wahrscheinlichkeit, dass ein beobachteter Effekt trotz Annahme der $H_0$ zufÃ¤llig auftritt.</p>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Bedingte Wahrscheinlichkeit $Pr(\overline{x}</td>
          <td>H_0)$, also eine Aussage Ã¼ber die Wahrscheinlichkeit des beobachteten Stichprobenmittelwertes $Pr(\overline{x})$ unter der Voraussetzung dass die Nullhypothese $H_0$ wahr ist, <strong>NICHT</strong> Ã¼ber die Wahrscheinlichkeit, dass die Nullhypothese $H_0$ an sich zutrifft.</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>âSignifikantâ</strong> ist ein Effekt, wenn der <strong>p-Wert</strong> unter einem zuvor festgelegten Signifikanz-Niveau $\alpha$ liegt, oft 5%.</p>

<h3 id="einseitiger-signifikanztest">
<a class="anchor" href="#einseitiger-signifikanztest" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einseitiger Signifikanztest</h3>

<p>Population mit $\mu = 100$ und $\sigma = 55$, Stichprobe mit $n = 200$.</p>

<p>Liegt eine Stichprobe mit $\overline{x} = 107$ (blaue Linie) in den oberen 5% der Wahrscheinlichkeitsmasse? D.h. ist die Wahrscheinlichkeit fÃ¼r solch eine Stichprobe unter dem Signifikanz-Niveau?</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-12-1.png" alt="plot of chunk unnamed-chunk-12" width="576" style="display: block; margin: auto;"></p>

<p><strong>Die Parameter der Dichtefunktion sind hier Populationsmittelwert und Standardfehler $\sigma_{\overline{x}}$, errechnet aus der Standardabweichung $\sigma$ der Population und der StichprobengrÃ¶Ãe $n$. (siehe <a href="#berechnung-des-standardfehlers-des-mittelwertes">Berechnung des Standardfehlers</a>)</strong></p>

<h3 id="zweiseitiger-signifikanztest">
<a class="anchor" href="#zweiseitiger-signifikanztest" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zweiseitiger Signifikanztest</h3>

<p>Population mit $\mu = 100$ und $\sigma = 55$, Stichprobe mit $n = 200$.</p>

<p>Beim zweiseitigen Signifikanztest wird das Signifikanz-Niveau auf beide Seiten aufgeteilt, da es die Wahrscheinlichkeit betrifft mit der eine Stichprobe in einem der beiden Extrembereiche liegt, egal in welchem.</p>

<p>Liegt eine Stichprobe mit $\overline{x} = 107$ (blaue Linie) auÃerhalb der zentralen 95% der Wahrscheinlichkeitsmasse?</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-13-1.png" alt="plot of chunk unnamed-chunk-13" width="576" style="display: block; margin: auto;"></p>

<h3 id="standardisierte-prÃ¼fgrÃ¶Ãen">
<a class="anchor" href="#standardisierte-pr%C3%BCfgr%C3%B6%C3%9Fen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Standardisierte PrÃ¼fgrÃ¶Ãen</h3>

<p>Oft werden Daten zur HypothesenprÃ¼fung standardisiert:</p>

<p>$$z_{\overline{x}} = \frac{\overline{x} - \mu}{\sigma_{\overline{x}}}$$
Die Verteilung der Stichprobenkennwerte in der Population ist dann auf $\mu = 0$ zentriert und hat einen Standardfehler $\sigma_{\overline{x}} = 1.0$.</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-14-1.png" alt="plot of chunk unnamed-chunk-14" width="576" style="display: block; margin: auto;"></p>

<h3 id="signifikanztest-mit-empirischen-daten">
<a class="anchor" href="#signifikanztest-mit-empirischen-daten" aria-hidden="true"><span class="octicon octicon-link"></span></a>Signifikanztest mit empirischen Daten</h3>

<p><strong>One-Sample-T-Test:</strong> gibt fÃ¼r gegebene Samples und Populationsmittelwert den p-Wert aus. Verglichen wird eine Stichprobe (daher âone sampleâ) mit der Gesamtpopulation.</p>

<p>Da die Standardabweichung der Population nicht bekannt ist, wird der Standardfehler mittels der T-Verteilung geschÃ¤tzt. (siehe <a href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes">SchÃ¤tzung des Standardfehlers</a>)</p>

<p>Samples:</p>

<p>Einseitiger One-Sample-T-Test:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mu</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">100</span><span class="w">
</span><span class="n">alpha</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.05</span><span class="w">

</span><span class="c1"># alternative = "greater" -  &gt; Einseitiger Test in positiver Richtung</span><span class="w">
</span><span class="c1"># alternative = "less"      -&gt; Einseitiger Test in negativer Richtung</span><span class="w">
</span><span class="c1"># alternative = "two.sided" -&gt; Zweiseitiger Test</span><span class="w">
</span><span class="n">t.test</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	One Sample t-test
## 
## data:  samples
## t = 1.204, df = 9, p-value = 0.1296
## alternative hypothesis: true mean is greater than 100
## 95 percent confidence interval:
##  88.01066      Inf
## sample estimates:
## mean of x 
##  122.9462
</code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-17-1.png" alt="plot of chunk unnamed-chunk-17" width="576" style="display: block; margin: auto;"></p>

<h2 id="hypothesentests">
<a class="anchor" href="#hypothesentests" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesentests</h2>

<p><strong>Nullhypothese $H_0$:</strong> Annahme, dass ein bestimmter bedeutsamer Effekt nicht existiert.</p>

<p><strong>Alternativhypothese $H_1$:</strong> Annahme, dass ein bestimmter bedeutsamer Effekt existiert</p>

<p><strong>Die Nullhypothese ist niemals wirklich wahr. Mit ausreichender StichprobengrÃ¶Ãe lÃ¤sst sich ein beliebig kleiner Effekt zeigen.</strong></p>

<p><strong>Irrtumswahrscheinlichkeit $\alpha$:</strong> Wahrscheinlichkeit, dass ein Test in einer Stichprobe einen bedeutsamen Effekt zufÃ¤llig anzeigt, der eigentlich in der Population nicht existiert, also dass die Nullhypothese $H_0$ fÃ¤lschlicherweise abgelehnt wird. ($\alpha$-Fehler, False-Positive)</p>

<p><strong>Irrtumswahrscheinlichkeit $\beta$:</strong> Wahrscheinlichkeit, dass ein Effekt, der in der Population vorhanden ist, zufÃ¤llig in der getesteten Stichprobe nicht auftaucht, also dass die Nullhypothese $H_0$ fÃ¤lschlicherweise angenommen wird. ($\beta$-Fehler, False-Negative)</p>

<p><strong>TeststÃ¤rke/Power:</strong> $1 - \beta$, je hÃ¶her die Power, umso unwahrscheinlicher werden $\beta$-Fehler</p>

<p><strong>parametrische vs. nicht-parametrische Tests:</strong> parametrische Tests setzen voraus, dass Merkmale in der Population normalverteilt sind (z.B. Gauss-Test, T-Test). Nicht-parametrische Tests machen diese Annahme nicht (Gegenstand im M.Sc.-Studium).</p>

<p>Ein Test kann zwar einen p-Wert unter $\alpha$-Niveau (0.05) liefern, aber trotzdem einen sehr groÃer $\beta$-Fehler haben:</p>

<ul>
  <li>grÃ¼ne Linie: $\mu$</li>
  <li>blaue Linie: $\overline{x}$</li>
  <li>rosa FlÃ¤che: $\alpha$</li>
  <li>blaue FlÃ¤che: $\beta$</li>
  <li>gestrichelte Linie: kritischer Wert</li>
</ul>

<p><img src="statistik-2-abbildungen/unnamed-chunk-18-1.png" alt="plot of chunk unnamed-chunk-18" width="576" style="display: block; margin: auto;"></p>

<p>Mit niedrigerem $\alpha$-Niveau (0.01) wird der $\beta$-Fehler sogar noch grÃ¶Ãer.</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-19-1.png" alt="plot of chunk unnamed-chunk-19" width="576" style="display: block; margin: auto;"></p>

<p>Um den $\beta$-Fehler zu reduzieren, mÃ¼sste ein stÃ¤rkerer Effekt ($\overline{x} - \mu$) vorhanden sein:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-20-1.png" alt="plot of chunk unnamed-chunk-20" width="576" style="display: block; margin: auto;"></p>

<h3 id="standardisierter-effekt-cohens-delta">
<a class="anchor" href="#standardisierter-effekt-cohens-delta" aria-hidden="true"><span class="octicon octicon-link"></span></a>Standardisierter Effekt: Cohenâs $\delta$</h3>

<p><em>(Manchmal auch: âCohenâs dâ)</em></p>

<p>$$\delta = \frac{\overline{x} - \mu}{\sigma}$$</p>

<ul>
  <li>$\overline{x}$: Stichproben-Mittelwert</li>
  <li>$\mu$: Populationsmittelwert</li>
  <li>$\sigma$: Standardabweichung der Population</li>
</ul>

<p><img src="statistik-2-abbildungen/unnamed-chunk-21-1.png" alt="plot of chunk unnamed-chunk-21" width="576" style="display: block; margin: auto;"></p>

<h3 id="konfidenzintervalle-fÃ¼r-cohens-delta">
<a class="anchor" href="#konfidenzintervalle-f%C3%BCr-cohens-delta" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konfidenzintervalle fÃ¼r Cohenâs $\delta$</h3>

<p>Die Stichprobenkennwerte-Verteilung von $\overline{x}$ ist normalverteilt (siehe <a href="#zentraler-grenzwertsatz">Zentraler Grenzwertsatz</a>)</p>

<p>Der Erwartungswert von $\delta$ entspricht der standardisierten Differenz zwischen Stichprobenmittelwert und Populationsmittelwert.</p>

<p>$$E_{\delta} = \frac{\overline{x} - \mu}{\sigma}$$</p>

<p>Die Streuung $\sigma_{\delta}$ ist der Standardfehler wobei dieser hier vereinfacht $\frac{1}{\sqrt{n}}$ ist weil Standardisierung bereits erfolgt ist (die Standardabweichung von standardisierten GrÃ¶Ãen ist 1):</p>

<p>$$\sigma_{\delta} = \sigma_{\overline{x}} = \frac{1}{\sqrt{n}}$$</p>

<p>$$\delta \sim  Normal(E_{\delta} = \frac{\overline{x} - \mu}{\sigma}, \sigma_{\delta} = \frac{1}{\sqrt{n}})$$</p>

<p>Damit lassen sich die Konfidenzintervalle fÃ¼r ein gegebenes $\alpha$-Niveau berechnen:</p>

<p>$$\delta \pm z(1-\frac{\alpha}{2}) \cdot \sigma_{\delta} = \frac{\overline{x} - \mu}{\sigma} \pm  z(1-\frac{\alpha}{2}) \cdot \frac{1}{\sqrt{n}}$$</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-22-1.png" alt="plot of chunk unnamed-chunk-22" width="576" style="display: block; margin: auto;">
Konventionen fÃ¼r Effektinterpretationen fÃ¼r $\delta$ nach Cohen:</p>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>$</td>
          <td>d</td>
          <td>\approx 0.14$: âkleinerâ Effekt</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>$</td>
          <td>d</td>
          <td>\approx 0.35$: âmittlererâ Effekt</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>$</td>
          <td>d</td>
          <td>\approx 0.57$: âgroÃerâ Effekt</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>TODO: ci.smd in R (MBESS)</strong></p>

<h3 id="einstichproben-gauss-test">
<a class="anchor" href="#einstichproben-gauss-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben-Gauss-Test</h3>

<p>Voraussetzungen:</p>

<ul>
  <li>Merkmal ist in der Population normalverteilt
    <ul>
      <li>
        <p>alternativ: bei nicht-normalverteiltem Merkmal $x$ ist der Stichproben Mittelwert ab ca. $n = 30$ nahezu normalverteilt. (Siehe <a href="#zentraler-grenzwertsatz">zentraler Grenzwertsatz</a>)</p>

        <p>Der z-Test ist dann allerdings nicht mehr exakt.</p>
      </li>
    </ul>
  </li>
  <li>Standardabweichung $\sigma$ in der Population ist bekannt</li>
</ul>

<p>Gauss-Test, auch âz-Testâ genannt, ist geeignet, wenn die Standardabweichung $\sigma$ der Population bekannt ist, und damit der Standardfehler $\sigma_{\overline{x}}$ berechnet werden kann. (Siehe <a href="#berechnung-des-standardfehlers-des-mittelwertes">Berechnung des Standardfehlers des Mittelwertes</a>)</p>

<p>PrÃ¼fgrÃ¶Ãe: $z_{\overline{x} - \mu}$, z-standardisierte Differenz von Stichprobenmittelwert und Populationsmittelwert</p>

<p>$$z_{\overline{x} - \mu} = \frac{\overline{x} - \mu}{\sigma_{\overline{x}}}$$</p>

<p>Kritischer Wert: Wert fÃ¼r $\overline{x}$ der Ã¼ber- bzw. unterschritten werden muss damit $p \le 0.05$ eingehalten wird.</p>

<p>$Q(p)$ ist hier die Quantilsfunktion der Normalverteilung, die bestimmt welcher Wert eine Wahrscheinlichkeit von $p$ oder weniger hat.</p>

<p>Die Nullhypothese $H_0$ wird abgelehnt wenn:</p>

<ul>
  <li>
    <p>bei einseitigem Test in positiver Richtung</p>

    <p>$z_{\overline{x} - \mu} \ge Q(1 - \alpha)$</p>
  </li>
  <li>
    <p>bei einseitigem Test in negativer Richtung</p>

    <p>$z_{\overline{x} - \mu} \le Q(\alpha)$</p>
  </li>
  <li>
    <p>bei zweiseitigem Test</p>

    <p>$z_{\overline{x} - \mu} \le Q(\frac{\alpha}{2}) \cup z_{\overline{x} - \mu} \ge Q(1 - \frac{\alpha}{2})$</p>

    <p>($\cup$: âoderâ)</p>
  </li>
</ul>

<p>Siehe auch: <a href="#signifikanztests">Signifikanztests</a></p>

<h4 id="einstichproben-gauss-test-in-r">
<a class="anchor" href="#einstichproben-gauss-test-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben-Gauss-Test in R</h4>

<p>Samples mit $\mu = 0.5$, $\sigma = 1.0$, und $n = 20$</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##  [1]  1.76295428  0.17376664  1.82979926  1.77242932  0.91464143 -1.03995004 -0.42856703  0.20527955  0.49423283  2.90465339  1.26359346 -0.29900925 -0.64765701  0.21053843
## [15]  0.20078488  0.08848917  0.75222345 -0.39192113  0.93568330 -0.73753842
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">BSDA</span><span class="p">)</span><span class="w">

</span><span class="n">z.test</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sigma.x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	One-sample z-Test
## 
## data:  samples
## z = 2.2281, p-value = 0.01294
## alternative hypothesis: true mean is greater than 0
## 95 percent confidence interval:
##  0.1304209        NA
## sample estimates:
## mean of x 
## 0.4982213
</code></pre></div></div>

<h3 id="einstichproben-t-test">
<a class="anchor" href="#einstichproben-t-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben T-Test</h3>

<p>Voraussetzungen:</p>

<ul>
  <li>Merkmal ist in der Population normalverteilt
    <ul>
      <li>alternativ: bei nicht-normalverteiltem Merkmal $x$ ist der Stichproben Mittelwert ab ca. $n = 30$ nahezu normalverteilt. (Siehe <a href="#zentraler-grenzwertsatz">zentraler Grenzwertsatz</a>)</li>
    </ul>
  </li>
  <li>StichprobengrÃ¶Ãe ist bekannt (zur SchÃ¤tzung des Standardfehlers)</li>
</ul>

<p><em>Der T-Test ist wenn mÃ¶glich dem Gauss-Test vorzuziehen, da er auch ohne bekannte Standardabweichung der Population exakter ist.</em></p>

<p>SchÃ¤tzung des Standardfehlers $\hat{\sigma}_{\overline{x}}$</p>

<ul>
  <li>$\hat{\sigma}^2_{x}$: geschÃ¤tzte Populations-Varianz</li>
  <li>$s^2_{x}$: Stichproben-Varianz</li>
  <li>$s^{2*}$: empirische Varianz</li>
</ul>

<p>$$\hat{\sigma}<em>{\overline{x}} = \sqrt{\frac{\hat{\sigma}^2</em>{x}}{n}} = \sqrt{\frac{s^2<em>{x}}{n}} = \sqrt{\frac{s^{2*}</em>{x}}{n-1}}$$</p>

<p>PrÃ¼fgrÃ¶Ãe: $t_{\overline{x} - \mu}$</p>

<p>$$t_{\overline{x} - \mu} = \frac{\overline{x} - \mu}{\hat{\sigma}_{\overline{x}}}$$</p>

<p>Kritischer Wert: Analog zum <a href="#einstichproben-gauss-test">Einstichproben Gauss-Test</a></p>

<p>$Q(p)$ ist beim t-Test die Quantilsfunktion der Student-T-Verteilung mit $n-1$ Freiheitsgraden, denn die Verteilung von $t_{\overline{x} - \mu}$ folgt dieser Student-T-Verteilung:</p>

<p>$$t_{\overline{x} - \mu} \sim Student(df = n -1 )$$</p>

<p>Beispiel: Zwei T-Tests mit entsprechenden Student-T-Verteilungen fÃ¼r $n=10$ und $n=100$.</p>

<p>Die PrÃ¼fgrÃ¶Ãe fÃ¤llt bei $n=10$ nicht Ã¼ber den kritischen Wert fÃ¼r $p \le \alpha$, bei $n=100$ aber schon, da der geschÃ¤tzte Standardfehler geringer wird, d.h. der Test wird genauer.</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-26-1.png" alt="plot of chunk unnamed-chunk-26" width="576" style="display: block; margin: auto;"></p>

<h4 id="einstichproben-t-test-in-r">
<a class="anchor" href="#einstichproben-t-test-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben T-Test in R</h4>

<p>Samples mit $\mu = 0.5$, $\sigma = 1.0$, und $n = 20$</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##  [1] 0.8525909 0.5347533 0.8659599 0.8544859 0.6829283 0.2920100 0.4142866 0.5410559 0.5988466 1.0809307 0.7527187 0.4401982 0.3704686 0.5421077 0.5401570 0.5176978 0.6504447
## [18] 0.4216158 0.6871367 0.3524923
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t.test</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	One Sample t-test
## 
## data:  samples
## t = 2.1812, df = 19, p-value = 0.02097
## alternative hypothesis: true mean is greater than 0.5
## 95 percent confidence interval:
##  0.5206532       Inf
## sample estimates:
## mean of x 
## 0.5996443
</code></pre></div></div>

<h3 id="einstichproben-t-test-fÃ¼r-abhÃ¤ngige-beobachtungen">
<a class="anchor" href="#einstichproben-t-test-f%C3%BCr-abh%C3%A4ngige-beobachtungen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben T-Test fÃ¼r abhÃ¤ngige Beobachtungen</h3>

<p>T-Test fÃ¼r abhÃ¤ngige Messungen in einer Stichprobe. z.B. wenn die gleiche Stichprobe von Versuchspersonen vor und nach einem Treatment die gleiche Messung durchlÃ¤uft.</p>

<p>StichprobengrÃ¶Ãe ist hier die Anzahl der Messwertpaare, nicht die Anzahl aller Messungen.</p>

<p>Es wird eine neue Variable $\overline{x}_D$ eingefÃ¼hrt, der Mittelwert der Differenz der beiden Messungen von jeweils der gleichen Versuchsperson.</p>

<ul>
  <li>$H_0$: $\overline{x}_D = 0$</li>
  <li>$H_1$: $\overline{x}_D \neq 0$ (zweiseitiger Test)</li>
</ul>

<p><em>Es ist egal ob zuerst die Differenzen der Messungen fÃ¼r jede Versuchsperson gebildet und dann gemittelt werden, oder ob die Differenz der Mittelwerte beider Messungen gebildet wird. Das Ergebnis ist das gleiche</em></p>

<p>Der Rest der Tests verlÃ¤uft wie beim Einstichproben T-Test.</p>

<h4 id="einstichproben-t-test-fÃ¼r-abhÃ¤ngige-beobachtungen-t-test-in-r">
<a class="anchor" href="#einstichproben-t-test-f%C3%BCr-abh%C3%A4ngige-beobachtungen-t-test-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben T-Test fÃ¼r abhÃ¤ngige Beobachtungen T-Test in R</h4>

<p>$n=20$ Samples,</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">samples</span><span class="o">$</span><span class="n">m2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">samples</span><span class="o">$</span><span class="n">m1</span><span class="w">
</span><span class="n">t.test</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"two.sided"</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	One Sample t-test
## 
## data:  xd
## t = -2.853, df = 9, p-value = 0.019
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -2.1962337 -0.2536916
## sample estimates:
## mean of x 
## -1.224963
</code></pre></div></div>

<p>Alternativ kann die Funktion <code class="language-plaintext highlighter-rouge">t.test</code> auch die paarweisen Differenzen automatisch bestimmen:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t.test</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">samples</span><span class="o">$</span><span class="n">m2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">samples</span><span class="o">$</span><span class="n">m1</span><span class="p">,</span><span class="w">
       </span><span class="n">paired</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w">
       </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w">
       </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"two.sided"</span><span class="p">,</span><span class="w">
       </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Paired t-test
## 
## data:  samples$m2 and samples$m1
## t = -2.853, df = 9, p-value = 0.019
## alternative hypothesis: true mean difference is not equal to 0
## 95 percent confidence interval:
##  -2.1962337 -0.2536916
## sample estimates:
## mean difference 
##       -1.224963
</code></pre></div></div>

<h3 id="einstichproben-binomialtest">
<a class="anchor" href="#einstichproben-binomialtest" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben Binomialtest</h3>

<p>Test fÃ¼r ein dichotomes Merkmal $x$ (Merkmal mit zwei mÃ¶glichen AusprÃ¤gungen): $x \in {0,1}$</p>

<p>$\pi_0$: Wahrscheinlichkeit in der Population fÃ¼r $x = 1$</p>

<p>$\pi$: Wahrscheinlichkeit in der Stichprobe fÃ¼r $x = 1$</p>

<p>Hypothesenpaare:</p>

<ul>
  <li>ungerichtet
    <ul>
      <li>$H_0$: $\pi_0 = \pi$</li>
      <li>$H_1$: $\pi_0 \ne \pi$</li>
    </ul>
  </li>
  <li>gerichtet, positiv
    <ul>
      <li>$H_0$: $\pi_0 \ge \pi$</li>
      <li>$H_1$: $\pi_0 \lt \pi$</li>
    </ul>
  </li>
  <li>gerichtet, negativ
    <ul>
      <li>$H_0$: $\pi_0 \le \pi$</li>
      <li>$H_1$: $\pi_0 \gt \pi$</li>
    </ul>
  </li>
</ul>

<p>Aus $\pi_0$ und $\pi$ ergeben sich zwei Binomialverteilungen Ã¼ber $n$ Ziehungen, mit $\alpha$-Fehler analog zu anderen Tests.</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-34-1.png" alt="plot of chunk unnamed-chunk-34" width="576" style="display: block; margin: auto;"></p>

<h4 id="binomialtest-in-r">
<a class="anchor" href="#binomialtest-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Binomialtest in R</h4>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">binom.test</span><span class="p">(</span><span class="m">39</span><span class="p">,</span><span class="w"> </span><span class="m">60</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Exact binomial test
## 
## data:  39 and 60
## number of successes = 39, number of trials = 60, p-value = 0.01367
## alternative hypothesis: true probability of success is greater than 0.5
## 95 percent confidence interval:
##  0.5363726 1.0000000
## sample estimates:
## probability of success 
##                   0.65
</code></pre></div></div>

<h3 id="zweistichproben-t-test">
<a class="anchor" href="#zweistichproben-t-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zweistichproben T-Test</h3>

<p>Wird angewendet beim Vergleich von 2 unabhÃ¤ngigen Stichproben (z.B. Studienarme).</p>

<p>Voraussetzungen:</p>

<ul>
  <li>normalverteiltes Merkmal</li>
  <li>Messwerte in beiden Stichproben unabhÃ¤ngig</li>
  <li>VarianzhomogenitÃ¤t zwischen den Stichproben</li>
</ul>

<p>PrÃ¼fgrÃ¶Ãe:</p>

<p>$$T = t_{\overline{x}<em>1} - t</em>{\overline{x}<em>2} = \frac{\overline{x}_1 - \overline{x}_2} {\hat{\sigma}</em>{\overline{x}_1 - \overline{x}_2}}$$</p>

<p>$T$ folgt der Student-T-Verteilung mit $df = n_1 + n_2 - 2$$ Freiheitsgraden</p>

<p>$$T \sim Student(0, 1, n_1 + n_2 - 2)$$</p>

<p>Standardfehler hÃ¤ngt hier von den GrÃ¶Ãen beider Stichproben ab, da diese nicht unbedingt gleich groÃ sind.</p>

<p>$$\hat{\sigma}<em>{\overline{x}_1 - \overline{x}_2} = \sqrt{\frac{\hat{\sigma}^2</em>{inn}} {n_1} + \frac{\hat{\sigma}^2_{inn}}{n_2}}$$</p>

<p>Geteilte/Gepoolte Innerhalb-Varianz $\hat{\sigma}^2_{inn}$ wird aus den geschÃ¤tzten Varianzen der Stichproben ($\hat{\sigma}^2_1$, $\hat{\sigma}^2_2$) berechnet (siehe auch <a href="#punktsch%C3%A4tzung-der-varianz">PunktschÃ¤tzung der Varianz</a>):</p>

<p>$$\hat{\sigma}^2_{inn} = \frac{\hat{\sigma}^2_1 \cdot (n_1 -1) + \hat{\sigma}^2_2 \cdot (n_2 -1)} {(n_1 - 1) + (n_2 - 1)}$$</p>

<p>Beispiel: Stichproben aus zwei Studienarmen mit jeweils $n = 100$</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-36-1.png" alt="plot of chunk unnamed-chunk-36" width="576" style="display: block; margin: auto;"></p>

<p>Verteilung der PrÃ¼fgrÃ¶Ãe $T$:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-37-1.png" alt="plot of chunk unnamed-chunk-37" width="576" style="display: block; margin: auto;"></p>

<h4 id="zweistichproben-t-test-in-r">
<a class="anchor" href="#zweistichproben-t-test-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zweistichproben T-Test in R</h4>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t.test</span><span class="p">(</span><span class="n">samples2</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">samples1</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Welch Two Sample t-test
## 
## data:  samples2$x and samples1$x
## t = 2.5715, df = 193.31, p-value = 0.005438
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  6.070815      Inf
## sample estimates:
## mean of x mean of y 
##  118.1253  101.1334
</code></pre></div></div>

<h2 id="power-und-stichprobenplanung">
<a class="anchor" href="#power-und-stichprobenplanung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Power und Stichprobenplanung</h2>

<p><strong>Power: $1-\beta$</strong></p>

<p>$\beta$ und Power hÃ¤ngen vom Standardfehler und damit von der StichprobengrÃ¶Ãe ab.</p>

<p>Beispiel $n = 20$, $\beta$-Fehler ist gering:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-39-1.png" alt="plot of chunk unnamed-chunk-39" width="576" style="display: block; margin: auto;"></p>

<p>Bei $n = 7$ ist der $\beta$-Fehler deutlich hÃ¶her und die Power daher geringer, wÃ¤hrend $\alpha$-Niveau weiterhin unterschritten wird:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-40-1.png" alt="plot of chunk unnamed-chunk-40" width="576" style="display: block; margin: auto;"></p>

<p>$\beta$ ist ebenfalls vom Effekt abhÃ¤ngig. Zur Planung der StichprobengrÃ¶Ãe mÃ¼ssen $\alpha$-Niveau und der minimale als signifikant akzeptierte Effekt bekannt sein.</p>

<h3 id="stichprobenplanung-in-r">
<a class="anchor" href="#stichprobenplanung-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stichprobenplanung in R</h3>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">pwr</span><span class="p">)</span><span class="w">

</span><span class="c1"># post-hoc Power-Analyse fÃ¼r einseitigen Gauss-Test/Z-Test</span><span class="w">
</span><span class="c1"># - Stichproben-Signifikanztest</span><span class="w">
</span><span class="c1"># - Normalverteilte Merkmale</span><span class="w">
</span><span class="c1"># - bekannter Standardabweichung</span><span class="w">
</span><span class="n">pwr.norm.test</span><span class="p">(</span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">sig.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
##      Mean power calculation for normal distribution with known variance 
## 
##               d = 0.5
##               n = 10
##       sig.level = 0.05
##           power = 0.4745987
##     alternative = greater
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># bei Test in negativer Richtung: alternative = "lesser"</span><span class="w">
</span><span class="c1"># bei zweiseitigem Test: alternative = "two.sided"</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># a priori Power Analyse fÃ¼r Zweistichproben-T-Test</span><span class="w">
</span><span class="c1"># n ist noch nicht bekannt, aber alpha-Niveau, Effekt und Power sind gegeben</span><span class="w">
</span><span class="n">pwr.t.test</span><span class="p">(</span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">sig.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">power</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.9</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"two.sample"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
##      Two-sample t test power calculation 
## 
##               n = 85.03128
##               d = 0.5
##       sig.level = 0.05
##           power = 0.9
##     alternative = two.sided
## 
## NOTE: n is number in *each* group
</code></pre></div></div>

<p>Plot von Power in AbhÃ¤ngigkeit von StichprobengrÃ¶Ãe:</p>

<p>Effekt $d = 0.7$, $\alpha_1 = 5\%$ (blau), $\alpha_2 = 1\%$ (pink)</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Funktion die einen einseitigen Z-Test ausfÃ¼hrt</span><span class="w">
</span><span class="c1"># und den Power-Wert aus dem Ergebnis extrahiert</span><span class="w">
</span><span class="n">power</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">pwr.norm.test</span><span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">sig.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">alpha</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">)</span><span class="w">
  
  </span><span class="nf">return</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="m">4</span><span class="p">]])</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># Plot der Funktion Ã¼ber StichprobengrÃ¶Ãen 1-75</span><span class="w">
</span><span class="c1"># Effekt d = 0.7</span><span class="w">
</span><span class="c1"># alpha = 0.05 und alpha = 0.01</span><span class="w">
</span><span class="n">tibble</span><span class="p">(</span><span class="w">
  </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">50</span><span class="p">,</span><span class="w">
  </span><span class="n">power5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">power</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.7</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">),</span><span class="w">
  </span><span class="n">power1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">power</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.7</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.01</span><span class="p">),</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">power</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_col</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">power5</span><span class="p">),</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"skyblue3"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_col</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">power1</span><span class="p">),</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"hotpink3"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">annotate</span><span class="p">(</span><span class="s2">"text"</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"alpha[1] == 0.05"</span><span class="p">,</span><span class="w"> </span><span class="n">parse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"skyblue3"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">annotate</span><span class="p">(</span><span class="s2">"text"</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"alpha[2] == 0.01"</span><span class="p">,</span><span class="w"> </span><span class="n">parse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.90</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"hotpink3"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">xlab</span><span class="p">(</span><span class="s2">"StichprobengrÃ¶Ãe"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">ylab</span><span class="p">(</span><span class="s2">"Power"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme_custom</span><span class="w">
</span></code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-43-1.png" alt="plot of chunk unnamed-chunk-43" width="576" style="display: block; margin: auto;"></p>

<p>FÃ¼r ein strengeres $\alpha_2 = 1\%$ ist gegenÃ¼ber $\alpha_1 = 5\%$ eine grÃ¶Ãere Stichrobe nÃ¶tig, um die gleiche Power zu erreichen.</p>

<h2 id="tests-fÃ¼r-kategoriale-merkmale">
<a class="anchor" href="#tests-f%C3%BCr-kategoriale-merkmale" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tests fÃ¼r Kategoriale Merkmale</h2>

<p>Kategoriale Merkmale:</p>

<ul>
  <li>nominalskalierte Merkmale</li>
  <li>ordinalskalierte Merkmale
    <ul>
      <li>auch geschichtete metrische Merkmale</li>
    </ul>
  </li>
</ul>

<h3 id="chi2-statistik">
<a class="anchor" href="#chi2-statistik" aria-hidden="true"><span class="octicon octicon-link"></span></a>$\chi^2$-Statistik</h3>

<p>$$\chi^2 = \sum_{i=1}^r{\sum_{j=1}^c{\frac{(f_{ij} - e_{ij})^2}{e_{ij}}}}$$</p>

<ul>
  <li>$r$: Anzahl Zeilen</li>
  <li>$c$: Anzahl Spalten</li>
  <li>$f_{ij}$: beobachtete HÃ¤ufigkeiten</li>
  <li>
    <p>$e_{ij}$: erwartete HÃ¤ufigkeiten</p>

    <p>$e_{ij} = \frac{Zeilensumme \cdot Spaltensumme}{Stichprobenumfang}$</p>
  </li>
</ul>

<h3 id="cramers-v">
<a class="anchor" href="#cramers-v" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cramerâs $V$</h3>

<p>$$V = \sqrt{\frac{\chi^2}{n \cdot (m - 1)}}$$</p>

<ul>
  <li>$n$: Stichprobenumfang</li>
  <li>
    <p>$m$: MerkmalsausprÃ¤gungen</p>

    <p>$m = min(r, c)$</p>
  </li>
</ul>

<h3 id="chi2-test">
<a class="anchor" href="#chi2-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>$\chi^2$-Test</h3>

<ul>
  <li>$V$: EffektstÃ¤rke</li>
  <li>$\chi^2$: PrÃ¼fgrÃ¶Ãe</li>
</ul>

<p>Nullhypothese $H_0$: $V = 0$, es existiert kein Effekt</p>

<p>Die PrÃ¼fgrÃ¶Ãe folgt einer $\chi^2$-Verteilung mit Freiheitsgraden $df = (r-1) \cdot (c-1)$.</p>

<h4 id="chi2-test-in-r">
<a class="anchor" href="#chi2-test-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>$\chi^2$-Test in R</h4>

<p>Beispieldaten:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##      A   B   C
## I  125 108 125
## II 127  93 230
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chisq.test</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Pearson's Chi-squared test
## 
## data:  samples
## X-squared = 22.002, df = 2, p-value = 1.669e-05
</code></pre></div></div>

<h4 id="kontinuitÃ¤tskorrektur">
<a class="anchor" href="#kontinuit%C3%A4tskorrektur" aria-hidden="true"><span class="octicon octicon-link"></span></a>KontinuitÃ¤tskorrektur</h4>

<p>Zellen mit $f_{ij} \lt 5$ gelten als âunterbesetztâ. Der $\chi^2$-Test reagiert dann progressiv, das $\alpha$-Fehlerniveau wird unterschritten und die Wahrscheinlichkeit, die $H_1$ anzunehmen steigt.</p>

<p>Die PrÃ¼fgrÃ¶Ãe muss in diesem Fall adjustiert werden:</p>

<table>
  <tbody>
    <tr>
      <td>$$\chi^2<em>{adj} = \sum</em>{i=1}^r{\sum_{j=1}^c{\frac{(</td>
      <td>f_{ij} - e_{ij}</td>
      <td>
<ul>
  <li>0.5)^2}{e_{ij}}}}$$</li>
</ul>
</td>
    </tr>
  </tbody>
</table>

<p>In R erfolgt die Korrektur automatisch, kann aber auch mit der <code class="language-plaintext highlighter-rouge">correct</code>-Option explizit aktiviert oder deaktiviert werden:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##     A  B
## I  10  8
## II  4 16
</code></pre></div></div>

<p>Ohne Korrektur wird $\alpha = 0.05$ unterschritten:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chisq.test</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span><span class="w"> </span><span class="n">correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Pearson's Chi-squared test
## 
## data:  samples
## X-squared = 5.1471, df = 1, p-value = 0.02329
</code></pre></div></div>

<p>Mit Korrektur wird $\alpha = 0.05$ nicht unterschritten:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chisq.test</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span><span class="w"> </span><span class="n">correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Pearson's Chi-squared test with Yates' continuity correction
## 
## data:  samples
## X-squared = 3.7325, df = 1, p-value = 0.05336
</code></pre></div></div>

<h1 id="multiplizitÃ¤t">
<a class="anchor" href="#multiplizit%C3%A4t" aria-hidden="true"><span class="octicon octicon-link"></span></a>MultiplizitÃ¤t</h1>

<p>Wenn mit erhobenen Daten mehrere Tests durchgefÃ¼hrt werden, gilt fÃ¼r jeden Test (âEndpunktâ) ein eigenes $\alpha$-Fehlerniveau (âPer-Comparison Error Rateâ, PCER).</p>

<p>$$\alpha_1 = \alpha_2 = \ldots = \alpha_k = 0.05$$</p>

<p>Insgesamt bilden diese dann die âFamily-Wise Error Rateâ (FWER), die deutlich hÃ¶her ausfallen kann, da die Wahrscheinlichkeiten $1-\alpha_i$, also dafÃ¼r, sich korrekterweise fÃ¼r $H_0$ zu entscheiden, entsprechend der Kettenregel multipliziert werden.</p>

<p>$$(1-\alpha_1) \cdot (1-\alpha_2) \cdot \ldots \cdot (1-\alpha_k) = (1-\alpha_i)^k$$</p>

<p>Bei $\alpha = 0.05$ und 5 Endpunkten:</p>

<p>$$(1 - 0.05)^5 = 0.95^5 \approx 0.774$$
$$1-0.774 = 0.226 = \alpha_{FWER}$$</p>

<p>Bei 14 Endpunkten und $\alpha = 0.05$ wird eine FWER von 50% Ã¼berschritten:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-49-1.png" alt="plot of chunk unnamed-chunk-49" width="576" style="display: block; margin: auto;"></p>

<h2 id="bonferroni-korrektur">
<a class="anchor" href="#bonferroni-korrektur" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bonferroni-Korrektur</h2>

<ul>
  <li>bestimmt $\alpha_i$, so dass $\alpha_{FWER} \le 0.05$ wird.</li>
</ul>

<p>FÃ¼r $k$ unabhÃ¤ngige Endpunkte:</p>

<p>$$\alpha_i = \frac{\alpha_{FWER}}{k}$$
<strong>Beispiel: $\alpha_{FWER} = 0.05$ und $k = 3$</strong></p>

<p>$$\alpha_i = \frac{0.05}{3} \approx 0.0167 $$</p>

<p>$$1 - (1- 0.0167)^3 \approx 0.049 \le 0.05$$</p>

<p><strong>Beispiel: Zwei Endpunkte in Form von zwei gerichteten Alternativhypothesen $H_{1,1}$ und $H_{1,2}$ gegenÃ¼ber Nullhypothese $H_{0,1}$</strong></p>

<p><em>(analog zu einer ungerichteten $H_1$, wo $\alpha$ ebenfalls auf beide Seiten aufgeteilt wird. Siehe <a href="#zweiseitiger-signifikanztest">Zweiseitiger Signifikanztest</a>)</em></p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-50-1.png" alt="plot of chunk unnamed-chunk-50" width="576" style="display: block; margin: auto;"></p>

<p>$\overline{x}_1$ liegt Ã¼ber dem kritischen Wert fÃ¼r $\alpha_i = 0.025$ in positiver Richtung wÃ¤hrend $\overline{x}_2$ nicht unterhalb des kritischen Wertes in negativer Richtung liegt.</p>

<p>$H_{1,1}$ kann also akzeptiert werden, $H_{1,2}$ jedoch nicht.</p>

<h2 id="holm-bonferroni-korrektur">
<a class="anchor" href="#holm-bonferroni-korrektur" aria-hidden="true"><span class="octicon octicon-link"></span></a>Holm-Bonferroni-Korrektur</h2>

<p>$k$ UnabhÃ¤ngige Endpunkte werden aufsteigend nach p-Wert sortiert.</p>

<p>$$\alpha_i = \frac{\alpha_{FWER}}{k - (i - 1)}$$</p>

<p>$$\alpha_1 = \frac{\alpha_{FWER}}{k}, \alpha_2 = \frac{\alpha_{FWER}}{k - 1}, \alpha_3 = \frac{\alpha_{FWER}}{k - 2}, \dots, \alpha_k = \frac{\alpha_{FWER}}{1}$$</p>

<h2 id="fallback-prozedur">
<a class="anchor" href="#fallback-prozedur" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fallback-Prozedur</h2>

<ol>
  <li>$k$ unabhÃ¤ngige Endpunkte werde <em>a priori</em> nach Wichtigkeit sortiert.</li>
  <li>$\alpha$ Fehler (z.B.) 5% wird frei auf Endpunkte verteilt.</li>
  <li>Endpunkte werden der Reihe nach getestet
    <ul>
      <li>$p_i &gt; \alpha_i \rightarrow \alpha_i = 0$, nicht signifikant</li>
      <li>$p_i \le \alpha_i \rightarrow \alpha^*<em>{i + 1} = \alpha</em>{i + 1} + \alpha_{i}$</li>
    </ul>

    <p>âunverbrauchterâ $\alpha$-Fehler wird an folgenden Test vererbt</p>
  </li>
</ol>

<p>Beispiel:</p>

<p>Durch die âVererbungâ des $\alpha$-Fehlers werden einige Tests signifikant, die bei einfacher Aufteilung der Fehlerwahrscheinlichkeit nicht als signifikant gelten kÃ¶nnten. Insgesamt beleibt aber $\alpha_{FWER} \le 5\%$.</p>

<h1 id="varianzanalyse-anova">
<a class="anchor" href="#varianzanalyse-anova" aria-hidden="true"><span class="octicon octicon-link"></span></a>Varianzanalyse (ANOVA)</h1>

<p>Zweck der ANOVA ist es, aufzuklÃ¤ren, ob die Variation zwischen Stichproben, z.B. Versuchsarmen (Kontrollgruppe vs. Treatment-Gruppe), auf die experimentelle Manipulation zurÃ¼ckzufÃ¼hren ist, oder zufÃ¤llige Variation ist, die auch auftreten wÃ¼rde, wenn mehrere Zufallsstichproben aus der gleichen Population gezogen wÃ¼rden.</p>

<h2 id="voraussetzungen">
<a class="anchor" href="#voraussetzungen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Voraussetzungen</h2>

<ul>
  <li>
    <p><strong>unabhÃ¤ngige Variable in Faktorstufen</strong></p>

    <p>UV muss in diskreten Faktorstufen vorliegen, damit sich eindeutige Gruppen bilden lassen.</p>
  </li>
  <li>
    <p><strong>HomooskedastizitÃ¤t</strong></p>

    <p>Die Varianzen der einzelnen Gruppen dÃ¼rfen sich nicht unterscheiden</p>

    <p>In R mittels <code class="language-plaintext highlighter-rouge">leveneTest</code> im Paket <code class="language-plaintext highlighter-rouge">car</code></p>
  </li>
  <li>
    <p><strong>Normalverteilung der Residuen</strong></p>
  </li>
</ul>

<h2 id="einfaktorielle-varianzanalyse">
<a class="anchor" href="#einfaktorielle-varianzanalyse" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einfaktorielle Varianzanalyse</h2>

<h3 id="messwertezerlegung">
<a class="anchor" href="#messwertezerlegung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Messwertezerlegung</h3>

<ul>
  <li>Messwert eines Merkmals einer Versuchsperson $m$, unter Versuchsbedingung $j$: $x_{mj}$</li>
  <li>Durchschnittlicher Messwert aller VP unter Bedingung $j$: $\overline{x}_j$</li>
  <li>
    <p>Abweichung vom Durchschnitt der Bedingungsgruppe $j$: $\overline{x}<em>j - x</em>{jm} = e_{mj}$</p>

    <p>$e$: Fehlerwert, auch Residuum genannt: die Variation von Messwerten, die Ã¼brig bleibt, nachdem alle systematischen Anteile der Variation entfernt wurden</p>
  </li>
</ul>

<p>$$x_{mj}=\overline{x}<em>j + e</em>{mj}$$</p>

<p>Der Messwert $x_{mj}$ wird zerlegt in den Gruppenmittelwert $\overline{x}<em>j$ und das Residuum $e</em>{mj}$.</p>

<h4 id="effekt-von-faktorstufen">
<a class="anchor" href="#effekt-von-faktorstufen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Effekt von Faktorstufen</h4>

<p>Der Effekt $t_j$ jeder Faktorstufe (Bedingung) ist die Abweichung des jeweiligen Gruppenmittelwertes $\overline{x}_j$ vom Gesamtmittelwert $\overline{x}$:</p>

<p>$$t_j = \overline{x}_j - \overline{x}$$
Der Effekt $t_j$ ist <em>nur bedingt interpretierbar</em>, da er sowohl eine systematische AbhÃ¤ngigkeit von der Faktorstufe $j$ haben kann, aber auch durch Stichprobenfehler entstehen kann.</p>

<p>Der Messwert $x_{mj}$ einer einzelnen Versuchsperson $m$ unter Bedingung $j$ wird also zerlegt in den Gesamtmittelwert $\overline{x}$ (Grundniveau), den Effekt der Bedingung $t_j$ und das Residuum der Person selbst $e_{mj}$:</p>

<p>$$x_{mj} = \overline{x} + t_j + e_{mj}$$</p>

<h3 id="quadratsummenzerlegung">
<a class="anchor" href="#quadratsummenzerlegung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Quadratsummenzerlegung</h3>

<p><strong>Quadratsumme</strong>: MaÃ der Variation (analog zur Varianz, nur ohne Einfluss der StichprobengrÃ¶Ãe)</p>

<p>$$QS_{total} = \sum_{j=1}^{J}{\sum_{m=1}^{n_j}{(x_{mj} - \overline{x})^2}}$$</p>

<p>$J$: Anzahl der Faktorstufen</p>

<p>$n_j$: Anzahl Individuen in der jeweiligen Faktorgruppe</p>

<p><strong>Quadratsumme zwischen der Gruppen:</strong></p>

<p>$$QS_{zw} = \sum_{j=1}^{J}{\sum_{m=1}^{n_j}{(\overline{x}_{j} - \overline{x})^2}}$$</p>

<p>In $(\overline{x}<em>{j} - \overline{x})$ kommt $m$ nicht mehr vor. $QS</em>{zw}$ ist also unabhÃ¤ngig von der Variation die nur durch die einzelnen Versuchspersonen verursacht wird. Also lÃ¤sst sich $QS_{zw}$ vereinfachen als, weil $(\overline{x}_{j} - \overline{x})$ jeweils fÃ¼r jedes $m$ gleich ist:</p>

<p>$$QS_{zw} = \sum_{j=1}^{J}{n_j \cdot (\overline{x}_{j} - \overline{x})^2}$$</p>

<p><strong>Quadratsumme innerhalb der Gruppen:</strong></p>

<p>$$QS_{inn} = \sum_{j=1}^{J}{\sum_{m=1}^{n_j}{(x_{mj} - \overline{x}_{j})^2}}$$</p>

<p>Hier taucht $\overline{x}$ nicht mehr auf und die Abweichungen der Faktorgruppen vom Gesamtmittelwert haben keinen Einfluss mehr.</p>

<p><strong>Die Gesamtquadratsumme entspricht der Summe der Teilquadratsummen:</strong></p>

<p>$$QS_{total} = QS_{zw} + QS_{inn}$$</p>

<p>Die Teilquadratsummen stellen ein MaÃ dafÃ¼r dar, wie viel Varianz durch den Effekt des jeweiligen Faktors bzw. die Residuen individuellen Versuchspersonen erklÃ¤rt werden.</p>

<p>$QS_{zw}$: Quadratsumme des Effektes</p>

<p>$QS_{inn}$: Quadratsumme der Residuen</p>

<h3 id="effektgrÃ¶ÃenschÃ¤tzer-hateta2">
<a class="anchor" href="#effektgr%C3%B6%C3%9Fensch%C3%A4tzer-hateta2" aria-hidden="true"><span class="octicon octicon-link"></span></a>EffektgrÃ¶ÃenschÃ¤tzer $\hat{\eta}^2$</h3>

<p>$\eta$: Eta</p>

<p>Das VerhÃ¤ltnis der Effekt-Quadratsumme zur Gesamtquadratsumme stellt dar, welcher Anteil der Gesamtvarianz durch den Effekt aufgeklÃ¤rt wird.</p>

<p>$$\hat{\eta}^2 = \frac{QS_{zw}}{QS_{total}}$$</p>

<p>$\hat{\eta}^2$ kann auch direkt aus dem empirischen F-Wert berechnet werden (siehe <a href="#f-test">F-Test</a>):</p>

<p>$$\hat{\eta}^2 = \frac{F \cdot df_{zw}}{F \cdot df_{zw} + df_{inn}}$$</p>

<p>$\hat{\eta}^2 = 0$: Variation entsteht komplett aus den Residuen und es gibt keinen gemessenen Effekt.</p>

<p>$\hat{\eta}^2 = 1$: Variation stammt vollstÃ¤ndig vom Effekt, keine Residuen.</p>

<h3 id="effektgrÃ¶ÃenschÃ¤tzer-hatomega2">
<a class="anchor" href="#effektgr%C3%B6%C3%9Fensch%C3%A4tzer-hatomega2" aria-hidden="true"><span class="octicon octicon-link"></span></a>EffektgrÃ¶ÃenschÃ¤tzer $\hat{\omega}^2$</h3>

<p>$\omega$: Omega</p>

<p>$\hat{\eta}^2$ ist kein erwartungstreuer SchÃ¤tzer fÃ¼r $\eta^2$, da die zugrundeliegende ZÃ¤hlerquadratsumme $QS_{zw}$ Stichprobenfehler enthÃ¤lt.</p>

<p>$\hat{\omega}^2$ enthÃ¤lt diese ÃberschÃ¤tzung von $\eta^2$ nicht.</p>

<p>$$\hat{\omega}^2 = \frac{QS_{zw} - (J - 1) \cdot MQS_{inn}}{QS_{total} + MQS_{inn}}$$</p>

<h3 id="effektgrÃ¶Ãe-phi2-signal-rausch-verhÃ¤ltnis">
<a class="anchor" href="#effektgr%C3%B6%C3%9Fe-phi2-signal-rausch-verh%C3%A4ltnis" aria-hidden="true"><span class="octicon octicon-link"></span></a>EffektgrÃ¶Ãe $\phi^2$, Signal-Rausch-VerhÃ¤ltnis</h3>

<p>$\phi$: Phi</p>

<p>In der Population ist $\phi^2$ der Quotient aus Effektvarianz und Residualvarianz:</p>

<p>$$\phi^2 = \frac{\sigma_{\tau}^2}{\sigma_{\epsilon}^2}$$</p>

<p>$\phi^2$ lÃ¤sst sich auch aus $\eta^2$ berechnen:</p>

<p>$$\phi^2 = \frac{\eta^2}{1 - \eta^2}$$</p>

<p>Analog gilt fÃ¼r den SchÃ¤tzer $\hat{\phi}^2$:</p>

<p>$$\hat{\phi}^2 = \frac{\hat{\eta}^2}{1 - \hat{\eta}^2}$$</p>

<h4 id="konventionen-fÃ¼r-phi2">
<a class="anchor" href="#konventionen-f%C3%BCr-phi2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konventionen fÃ¼r $\phi^2$:</h4>

<ul>
  <li>$\phi^2 \approx 0.01$: kleiner Effekt</li>
  <li>$\phi^2 \approx 0.0625$: mittlerer Effekt</li>
  <li>$\phi^2 \approx 0.16$: groÃer Effekt</li>
</ul>

<h3 id="effektgrÃ¶Ãe-phi">
<a class="anchor" href="#effektgr%C3%B6%C3%9Fe-phi" aria-hidden="true"><span class="octicon octicon-link"></span></a>EffektgrÃ¶Ãe $\phi$</h3>

<p>Auch $f$ genannt</p>

<p>$$\phi = f = \sqrt{\phi^2}$$</p>

<p>$\phi$ ist leichter interpretierbar als $\phi^2$, da es Vielfache der Standardabweichung $\sigma$ des Merkmals angibt.</p>

<h3 id="effektgrÃ¶Ãe-lambda">
<a class="anchor" href="#effektgr%C3%B6%C3%9Fe-lambda" aria-hidden="true"><span class="octicon octicon-link"></span></a>EffektgrÃ¶Ãe $\lambda$</h3>

<p>$\lambda$: Lambda</p>

<p>$\lambda$ ist der Nicht-ZentralitÃ¤ts-Parameter der F-Verteilung. Je grÃ¶Ãer $\lambda$, umso weiter nach rechts verschoben und flacher ist die Dichtefunktion der F-Verteilung:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-52-1.png" alt="plot of chunk unnamed-chunk-52" width="576" style="display: block; margin: auto;"></p>

<p>Die Kurve fÃ¼r $\lambda = 0$ (âzentrale F-Verteilungâ) ist die Verteilung unter der Nullhypothese dar wÃ¤hrend die Kurve mit $\lambda \gt 0$ die Alternativhypothese unter Annahme eines Effektes darstellt.</p>

<p>$$\lambda = n \cdot \frac{\sigma_{\tau}^2}{\sigma_{\epsilon}^2} = n \cdot \phi^2$$</p>

<h3 id="beziehungen-zwischen-effektgrÃ¶ÃenschÃ¤tzern">
<a class="anchor" href="#beziehungen-zwischen-effektgr%C3%B6%C3%9Fensch%C3%A4tzern" aria-hidden="true"><span class="octicon octicon-link"></span></a>Beziehungen zwischen EffektgrÃ¶ÃenschÃ¤tzern</h3>

<p>$$\hat{\lambda} = n \cdot \hat{\phi}^2 = n \cdot \frac{\hat{\eta}^2}{1 - \hat{\eta}^2}$$</p>

<p>$$\hat{\eta}^2 = \frac{\hat{\lambda}}{\hat{\lambda} + n}$$</p>

<p>$$\hat{\phi}^2 = \frac{\hat{\lambda}}{n}$$
FÃ¼r die EffektgrÃ¶Ãen in der Population gelten die Formeln analog ohne SchÃ¤tzer.</p>

<h3 id="konfidenzintervalle-der-effektgrÃ¶Ãen">
<a class="anchor" href="#konfidenzintervalle-der-effektgr%C3%B6%C3%9Fen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konfidenzintervalle der EffektgrÃ¶Ãen</h3>

<p>Es wird meistens das Konfidenzintervall fÃ¼r eine EffektgrÃ¶Ãe berechnet und dann je nach Bedarf in eine der anderen  EffektgrÃ¶Ãen umgerechnet.</p>

<p>Das Konfidenzintervall fÃ¼r $\hat{\eta}^2$ kann in R mit der Funktion <code class="language-plaintext highlighter-rouge">ci.pvaf</code> (Paket MBESS) ermittelt werden.</p>

<p><em>(CI: confidence interval, PVAF: proportion of variance accounted for)</em></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w">
</span><span class="n">df2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">20</span><span class="w">
</span><span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">100</span><span class="w">
</span><span class="n">f_v</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">6</span><span class="w">

</span><span class="n">ci.pvaf</span><span class="p">(</span><span class="n">F.value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f_v</span><span class="p">,</span><span class="w"> </span><span class="n">df.1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df1</span><span class="p">,</span><span class="w"> </span><span class="n">df.2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df2</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">ci_result</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in ci.pvaf(F.value = f_v, df.1 = df1, df.2 = df2, N = n, conf.level = 0.95): could not find function "ci.pvaf"
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ci_result</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in eval(expr, envir, enclos): object 'ci_result' not found
</code></pre></div></div>

<p>Dargestellt als F-Verteilungen mit $\lambda$-Konfidenzintervall:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in h(simpleError(msg, call)): error in evaluating the argument 'obj' in selecting a method for function 'unname': object 'ci_result' not found
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in h(simpleError(msg, call)): error in evaluating the argument 'obj' in selecting a method for function 'unname': object 'ci_result' not found
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in eval(expr, envir, enclos): object 'eta_sq_lower' not found
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in eval(expr, envir, enclos): object 'eta_sq_upper' not found
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in list2(na.rm = na.rm, ...): object 'ncp_lower' not found
</code></pre></div></div>

<h3 id="schÃ¤tzung-der-populationsparameter">
<a class="anchor" href="#sch%C3%A4tzung-der-populationsparameter" aria-hidden="true"><span class="octicon octicon-link"></span></a>SchÃ¤tzung der Populationsparameter</h3>

<h4 id="schÃ¤tzung-des-populationsmittelwertes">
<a class="anchor" href="#sch%C3%A4tzung-des-populationsmittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>SchÃ¤tzung des Populationsmittelwertes</h4>

<p>$$\hat{\mu} = \overline{x} = \frac{\sum_{j=1}^J{\sum_{m=1}^{n_j}{x_{mj}}}}{n}$$</p>

<p>Der Gesamtmittelwert aller Messungen $x_{mj}$ ist der SchÃ¤tzer fÃ¼r den Mittelwert der Population $\hat{\mu}$.</p>

<h4 id="schÃ¤tzung-des-effektes-tau_j">
<a class="anchor" href="#sch%C3%A4tzung-des-effektes-tau_j" aria-hidden="true"><span class="octicon octicon-link"></span></a>SchÃ¤tzung des Effektes $\tau_j$</h4>

<p>$$\hat{\tau_j} = t_j = x_{mj} - \overline{x}$$</p>

<h4 id="schÃ¤tzung-der-varianz-der-residuen-in-der-population">
<a class="anchor" href="#sch%C3%A4tzung-der-varianz-der-residuen-in-der-population" aria-hidden="true"><span class="octicon octicon-link"></span></a>SchÃ¤tzung der Varianz der Residuen in der Population</h4>

<p>Die geschÃ¤tzte Varianz der Residuen in der Population $\hat{\sigma}<em>\epsilon^2$ entspricht der mittleren Quadratsumme $MQS</em>{inn}$ innerhalb der einzelnen Bedingungen $MQS_{j}$:</p>

<p>$$MQS_{j} = \frac{\sum_{m-1}^{n_j}{(x_{mj}-\overline{x})^2}}{n_j - 1}$$</p>

<p>$$\hat{\sigma}<em>\epsilon^2 = MQS</em>{inn} = \frac{\sum_{j=1}^{J}{MQS_j}}{J}$$</p>

<p>Beim unterschiedlich groÃen Gruppen wird ein gewichtetes arithmetisches Mittel der $MQS_j$ berechnet:</p>

<p>$$\hat{\sigma}<em>\epsilon^2 = MQS</em>{inn} = \frac{\sum_{j=1}^{J}{MQS_j \cdot (n_j - 1)}}{\sum_{j=1}^J{n_j-1}}$$</p>

<p>Das lÃ¤sst sich vereinfachen als:</p>

<p>$$\hat{\sigma}<em>\epsilon^2 = MQS</em>{inn} = \frac{QS_{inn}}{n-J}$$</p>

<h2 id="hypothesenprÃ¼fung-in-der-varianzanalyse">
<a class="anchor" href="#hypothesenpr%C3%BCfung-in-der-varianzanalyse" aria-hidden="true"><span class="octicon octicon-link"></span></a>HypothesenprÃ¼fung in der Varianzanalyse</h2>

<p>Wenn $H_0$ gilt, und kein Effekt zwischen den Faktorgruppen besteht, so sind $MQS_{zw}$ und $MQS_{inn}$ beides erwartungstreue SchÃ¤tzer der Varianz der Residuen in der Population $\hat{\sigma}^2_\epsilon$, da auÃer den Residuen keine andere Quelle fÃ¼r Varianz vorhanden ist.</p>

<p>Je mehr $MQS{zw}$ von $MQS_{inn}$ abweicht, umso mehr spricht das dafÃ¼r, dass die Nullhypothese nicht haltbar ist.</p>

<p>$$MQS_{zw} = \frac{QS_{zw}}{J-1}$$</p>

<h3 id="f-test">
<a class="anchor" href="#f-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>F-Test</h3>

<p>Die F-Statistik ist ein MaÃ dafÃ¼r, wie stark $MQS_{zw}$ von $MQS_{inn}$ abweicht:</p>

<p>$$F = \frac{MQS_{zw}}{MQS_{inn}}$$</p>

<p>$F$ folgt der F-Verteilung. Diese hat zwei Parameter:</p>

<ul>
  <li>
    <p>Freiheitsgrade des Kennwertes im ZÃ¤hler, hier $MQS_{zw}$</p>

    <p>$df_{zw} = J-1$</p>
  </li>
  <li>
    <p>Freiheitsgrade des Kennwertes in Nenner, hier $MQS_{inn}$</p>

    <p>$df_{inn} = n-J$</p>
  </li>
</ul>

<p>GeprÃ¼ft wird der empirische F-Wert also gegen die Verteilung $F(df_{zw}; df_{inn})$. Wenn der kritische F-Wert fÃ¼r das festgelegte $\alpha$-Niveau erreicht wird, ist die Nullhypothese zu verwerfen.</p>

<p>Der F-Test <strong>prÃ¼ft nur die globale Nullhypothese</strong>, also dass ALLE Effekte $\tau_j$ in der Population 0 sind. Er gibt keine Auskunft darÃ¼ber, welche Mittelwertunterschiede zwischen welchen Faktorstufen signifikant sind.</p>

<h4 id="beispiel-fÃ¼r-f-test">
<a class="anchor" href="#beispiel-f%C3%BCr-f-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Beispiel fÃ¼r F-Test</h4>

<p>Zwei Faktorgruppen (Studienarme), je 10 Versuchspersonen, $J = 2, n_j = 10$</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-55-1.png" alt="plot of chunk unnamed-chunk-55" width="576" style="display: block; margin: auto;"></p>

<p><strong>Gesamtquadratsumme $QS_{total}$:</strong></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">summarize</span><span class="p">(</span><span class="w">
    </span><span class="n">QS_total</span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="p">)</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">pull</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">QS_total</span><span class="w">

</span><span class="n">QS_total</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 41.86613
</code></pre></div></div>

<p><strong>Quadratsumme zwischen den Faktorgruppen $QS_{zw}$:</strong></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="w">
    </span><span class="n">x_j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">ungroup</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">summarize</span><span class="p">(</span><span class="w">
    </span><span class="n">QS_zw</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="w"> </span><span class="p">(</span><span class="n">x_j</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="p">)</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">pull</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">QS_zw</span><span class="w">

</span><span class="n">QS_zw</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 16.27101
</code></pre></div></div>

<p><strong>Quadratsumme innerhalb der Gruppen $QS_{inn}$:</strong></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="w">
    </span><span class="n">x_j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">ungroup</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">summarize</span><span class="p">(</span><span class="w">
    </span><span class="n">QS_inn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">x_j</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="p">)</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">pull</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">QS_inn</span><span class="w">

</span><span class="n">QS_inn</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 25.59512
</code></pre></div></div>

<p><strong>AdditivitÃ¤t der Quadratsummen:</strong></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">QS_total</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">QS_zw</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">QS_inn</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] TRUE
</code></pre></div></div>

<p><strong>VarianzaufklÃ¤rung $\eta^2$:</strong></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">eta_sq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QS_zw</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">QS_total</span><span class="w">
</span><span class="n">eta_sq</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 0.3886438
</code></pre></div></div>

<p>Der Effekt zwischen den Faktorstufen klÃ¤rt 38.9% der Varianz auf.</p>

<p><strong>HypothesenprÃ¼fung:</strong></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MQS_zw</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">QS_zw</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">J</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">MQS_zw</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 16.27101
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MQS_inn</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">QS_inn</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">n_total</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">J</span><span class="p">)</span><span class="w">
</span><span class="n">MQS_inn</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1.421951
</code></pre></div></div>

<p>Empirischer F-Wert:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f_emp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MQS_zw</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">MQS_inn</span><span class="w">
</span><span class="n">f_emp</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 11.44274
</code></pre></div></div>

<p>Freiheitsgrade:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_zw</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">J</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">df_inn</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">n_total</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">J</span><span class="w">
</span><span class="nf">list</span><span class="p">(</span><span class="n">df_zw</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_zw</span><span class="p">,</span><span class="w"> </span><span class="n">df_inn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_inn</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## $df_zw
## [1] 1
## 
## $df_inn
## [1] 18
</code></pre></div></div>

<p>F-Verteilung und Vergleich mit kritischem F-Wert bei $\alpha = 0.05$:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f_crit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">qf</span><span class="p">(</span><span class="m">0.95</span><span class="p">,</span><span class="w"> </span><span class="n">df1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_zw</span><span class="p">,</span><span class="w"> </span><span class="n">df2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_inn</span><span class="p">)</span><span class="w">

</span><span class="n">ggplot</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">xlim</span><span class="p">(</span><span class="m">2.5</span><span class="p">,</span><span class="w"> </span><span class="m">13</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_function</span><span class="p">(</span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">df1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_zw</span><span class="p">,</span><span class="w"> </span><span class="n">df2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_inn</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">stat_function</span><span class="p">(</span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">df1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_zw</span><span class="p">,</span><span class="w"> </span><span class="n">df2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_inn</span><span class="p">),</span><span class="w">
                </span><span class="n">geom</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"area"</span><span class="p">,</span><span class="w">
                </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"hotpink3"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.3</span><span class="p">,</span><span class="w">
                </span><span class="n">xlim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">f_crit</span><span class="p">,</span><span class="w"> </span><span class="m">13</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f_emp</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"skyblue3"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">annotate</span><span class="p">(</span><span class="s2">"text"</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">paste</span><span class="p">(</span><span class="s2">"F ="</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">f_emp</span><span class="p">,</span><span class="m">2</span><span class="p">)),</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.025</span><span class="p">,</span><span class="w"> </span><span class="n">hjust</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"skyblue3"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"F-Wert"</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Wahrscheinlichkeitsdichte"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme_custom</span><span class="w">
</span></code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-65-1.png" alt="plot of chunk unnamed-chunk-65" width="576" style="display: block; margin: auto;"></p>

<p>Der empirische F-Wert Ã¼berschreitet den kritischen F-Wert fÃ¼r $\alpha = 0.05$. Die Nullhypothese wird also verworfen. Es besteht ein signifikanter Unterschied zwischen den Faktorgruppen, der sich nicht durch zufÃ¤llige Variation erklÃ¤ren lÃ¤sst.</p>

<h3 id="automatische-durchfÃ¼hrung-in-r">
<a class="anchor" href="#automatische-durchf%C3%BChrung-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Automatische DurchfÃ¼hrung in R</h3>

<p>Die <code class="language-plaintext highlighter-rouge">aov()</code> Funktion ist standardmÃ¤Ãig verfÃ¼gbar.</p>

<p>Es muss eine Formel angegeben werden, die den Zusammenhang zwischen unabhÃ¤ngigen und abhÃ¤ngigen Variablen beschreibt, hier z.B. <code class="language-plaintext highlighter-rouge">x ~ j</code> (Messwert $x$ in AbhÃ¤ngigkeit von Faktor $j$).</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">aov</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">j</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">samples</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">summary</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##             Df Sum Sq Mean Sq F value  Pr(&gt;F)   
## j            1  16.27  16.271   11.44 0.00332 **
## Residuals   18  25.59   1.422                   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
</code></pre></div></div>

<h2 id="zweifaktorielle-varianzanalyze">
<a class="anchor" href="#zweifaktorielle-varianzanalyze" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zweifaktorielle Varianzanalyze</h2>

<p>ZusÃ¤tzlich zum ersten Faktor $A$ und einem zweiten Faktor $B$, die die Haupteffekte verursachen kÃ¶nnen, kommt noch die Interaktion $A \times B$ hinzu. Die Gesamtquadratsumme $QS_{total} wird bei zwei Faktoren zerlegt in:</p>

<ul>
  <li>$QS_A$</li>
  <li>$QS_B$</li>
  <li>$QS_{A \times B}$</li>
  <li>$QS_{inn}$</li>
</ul>

<p>FÃ¼r die Quadratsummen der Haupteffekte werden die Abweichungen der Mittelwerte in ALLEN Gruppen der gleichen Faktorstufe auf dem jeweiligen Faktor vom Gesamtmittelwert bestimmt.</p>

<p>FÃ¼r Faktor $A$ mit $j$ Stufen:</p>

<p>$$QS_A = \sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{(\overline{x}_j - \overline{x})^2}}}$$</p>

<p>Vereinfacht, da Variation der $n_{Zelle}$ Messwerte in jeder Zelle gemittelt werden:</p>

<p><em>(Vorausgesetzt alle Zellen enthalten gleich viele Messwerte)</em></p>

<p>$$QS_A = n_{Zelle} \cdot K \cdot\sum_{j=1}^J{}{(\overline{x}_j - \overline{x})^2}$$</p>

<p>FÃ¼r Faktor $B$ analog:</p>

<p>$$QS_B = \sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{(\overline{x}<em>k - \overline{x})^2}}} = n</em>{Zelle} \cdot J \cdot\sum_{k=1}^K{}{(\overline{x}_k - \overline{x})^2} $$</p>

<p>Die Quadratsumme des Interaktionseffektes $QS_{A \times B}$ ergibt sich, indem die Mittelwertabweichungen der Haupteffekte $A$ und $B$ von der Mittelwertabweichung in jeder Zelle abgezogen werden:</p>

<p>$$QS_{A \times B} = \sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{((\overline{x}_{jk} - \overline x) - (\overline x_j - \overline x) - (\overline x_k - \overline{x}))^2}}}$$</p>

<p>Auch hier lÃ¤sst sich vereinfachen:</p>

<p>$$QS_{A \times B} = n_{Zelle} \cdot \sum_{k=1}^K{\sum_{j=1}^J{((\overline{x}_{jk} - \overline x) - (\overline x_j - \overline{x}) - (\overline x_k - \overline{x}))^2}}$$</p>

<h3 id="nicht-partiielles-effektstÃ¤rkenmaÃ-hateta2">
<a class="anchor" href="#nicht-partiielles-effektst%C3%A4rkenma%C3%9F-hateta2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Nicht-partiielles EffektstÃ¤rkenmaÃ: $\hat{\eta}^2$</h3>

<p>Genau wie in der einfaktoriellen Varianzanalyse ist $\hat{\eta}^2$ das VerhÃ¤ltnis von Effektquadratsumme zu Gesamtquadratsumme.</p>

<p>$$\hat{\eta}<em>A^2 = \frac{QS_A}{QS</em>{total}}$$
$$\hat{\eta}<em>B^2 = \frac{QS_B}{QS</em>{total}}$$
$$\hat{\eta}<em>{A \times B}^2 = \frac{QS</em>{A \times B}}{QS_{total}}$$</p>

<p>Das nicht-partielle $\hat{\eta}^2$ hat das Problem, dass es nur Auskunft darÃ¼ber gibt, wie viel der Gesamtvarianz in einer konkreten Untersuchung ein Faktor oder eine Interaktion aufklÃ¤rt. Es ermÃ¶glicht keinen Vergleich mit anderen Untersuchungen, die den gleichen Faktor enthalten aber zusÃ¤tzlich noch weitere, die nicht in beiden Untersuchungen vorhanden sind.</p>

<h3 id="partielles-effektgrÃ¶ÃenmaÃ-hateta_p2">
<a class="anchor" href="#partielles-effektgr%C3%B6%C3%9Fenma%C3%9F-hateta_p2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Partielles EffektgrÃ¶ÃenmaÃ $\hat{\eta}_p^2$</h3>

<p>Das partielle $\hat{\eta}_p^2$ ist das VerhÃ¤ltnis einer Effektquadratsumme und einer Teilquadratsumme, die Effekt und Residuum enthÃ¤lt:</p>

<p>$$\hat{\eta}<em>{pA}^2 = \frac{QS</em>{A}}{QS_{A} + QS_{inn}}$$</p>

<p><em>(analog fÃ¼r Effekte $B$ und $A \times B$)</em></p>

<h3 id="schÃ¤tzung-der-haupteffekte">
<a class="anchor" href="#sch%C3%A4tzung-der-haupteffekte" aria-hidden="true"><span class="octicon octicon-link"></span></a>SchÃ¤tzung der Haupteffekte</h3>

<p>$$\tau_{b_j} = \hat{\tau}_{b_j} = \overline{x}_j - \overline {x}$$</p>

<p>$$\tau_{b_k} = \hat{\tau}_{b_k} = \overline{x}_k - \overline {x}$$</p>

<p>$$\tau_{b_{(A \times B)<em>{jk}}} = \hat{\tau}</em>{b_k} = (\overline{x}<em>{jk} - \overline {x}) - (\overline{x}</em>{j} - \overline {x}) - (\overline{x}_{k} - \overline {x})$$</p>

<h3 id="schÃ¤tzung-des-residuums">
<a class="anchor" href="#sch%C3%A4tzung-des-residuums" aria-hidden="true"><span class="octicon octicon-link"></span></a>SchÃ¤tzung des Residuums</h3>

<p>$$\hat{\epsilon}<em>{mjk} = x</em>{mjk} - \overline x_{jk}$$</p>

<h3 id="schÃ¤tzung-der-populationsresidualvarianz">
<a class="anchor" href="#sch%C3%A4tzung-der-populationsresidualvarianz" aria-hidden="true"><span class="octicon octicon-link"></span></a>SchÃ¤tzung der Populationsresidualvarianz</h3>

<p>$$\hat{\sigma}^2<em>{\epsilon} = \frac{\sum</em>{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{(x_{mjk} - \overline x_{jk})^2}}}}{J \cdot K \cdot (n_{Zelle} - 1)}$$</p>

<h3 id="hypothesenprÃ¼fung-bei-zweifaktorieller-varianzanalyse">
<a class="anchor" href="#hypothesenpr%C3%BCfung-bei-zweifaktorieller-varianzanalyse" aria-hidden="true"><span class="octicon octicon-link"></span></a>HypothesenprÃ¼fung bei zweifaktorieller Varianzanalyse</h3>

<h4 id="zerlegung-der-freiheitsgrade">
<a class="anchor" href="#zerlegung-der-freiheitsgrade" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zerlegung der Freiheitsgrade</h4>

<p>$$df_{zw} = df_A + df_B + df_{A \times B} = J \cdot K - 1$$</p>

<p>$$df_A = J - 1$$
$$df_B = K - 1$$
$$df_{inn} = J \cdot K \cdot (n_{Zelle} - 1)$$</p>

<p>daraus folgt:</p>

<p>$$df_{A \times B} = (J \cdot K - 1) - (J - 1) - (K - 1)$$
$$df_{A \times B} = (J - 1) \cdot (K - 1)$$</p>

<p>$$df_{total} = df_A + df_B + df_{A \times B} +df_{inn}$$</p>

<p>Entsprechende mittlere Quadratsummen und F-Werte wie bei einfaktorieller ANOVA:</p>

<p>$$MQS_{inn} = \frac{QS_{inn}}{df_{inn}}$$</p>

<p>\begin{align<em>}
MQS_A &amp;= \frac{QS_A}{df_A} <br>
F_A &amp;= \frac{MQS_A}{MQS_{inn}}
\end{align</em>}</p>

<p>\begin{align<em>}
MQS_B &amp;= \frac{QS_B}{df_B} <br>
F_B &amp;= \frac{MQS_B}{MQS_{inn}}
\end{align</em>}</p>

<p>\begin{align<em>}
MQS_{A \times B} &amp;= \frac{QS_{A \times B}}{df_{A \times B}} <br>
F_{A \times B} &amp;= \frac{MQS_{A \times B}}{MQS_{inn}}
\end{align</em>}</p>

<p>F-Tests und Konfidenzintervalle funktionieren genau wie bei der einfaktoriellen Varianzanalyse.</p>

<h4 id="hypothesenpaare">
<a class="anchor" href="#hypothesenpaare" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesenpaare</h4>

<ul>
  <li>
    <p>Haupteffekt $A$</p>

    <p>$H_0: \mu_j - \mu = 0$ bzw. $\tau_{A_j} = 0$</p>

    <p>$H_1: \mu_j = \mu \neq 0$ bzw. $\tau_{A_j} \neq 0$</p>
  </li>
  <li>
    <p>Haupteffekt $B$</p>

    <p>$H_0: \mu_k - \mu = 0$ bzw. $\tau_{B_k} = 0$</p>

    <p>$H_1: \mu_k = \mu \neq 0$ bzw. $\tau_{B_k} \neq 0$</p>
  </li>
  <li>
    <p>Interaktion $A \times B$</p>

    <p>$H_0: \mu_{jk} - \mu_j - \mu_k = 0$ bzw. $\tau_{(A \times B)_{jk}} = 0$</p>

    <p>$H_1: \mu_{jk} - \mu_j - \mu_k \neq 0$ bzw. $\tau_{(A \times B)_{jk}} \neq 0$</p>
  </li>
</ul>

<h2 id="varianzanalyse-mit-messwiederholung">
<a class="anchor" href="#varianzanalyse-mit-messwiederholung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Varianzanalyse mit Messwiederholung</h2>

<p>Sowohl bei einfaktorieller als auch zweifaktorieller ANOVA kÃ¶nnen Messwiederholungen der gleichen Versuchspersonen mit berÃ¼cksichtigt werden.</p>

<p>Hierzu wird die Versuchsperson selbst als Faktor mit Haupteffekt eingefÃ¼hrt und es findet eine weitere Quadratsummenzerlegung statt:</p>

<p>$$QS_{zw} = QS_{zwA} + QS_{zwP}$$</p>

<p>$QS_{zwA}$: Quadratsumme der Variation zwischen den Stufen des Faktors $A$</p>

<p>$QS_{zwP}$: Quadratsumme der Variation zwischen Versuchspersonen</p>

<p>$QS_{res}$ bezeichnet die verbleibende residuale Quadratsumme, die auch die Variation zwischen Messzeitpunkten der jeweils gleichen Versuchsperson enthÃ¤lt.</p>

<p>Das partielle $\hat{\eta}^2_p$ gibt dann Auskunft darÃ¼ber, welcher Anteil der Gesamt Varianz NUR durch den Faktor $A$ aufgeklÃ¤rt wird:</p>

<p>$$\hat{\eta}^2<em>p = \frac{QS</em>{zwA}}{QS_{zwA} + QS_{res}}$$</p>

<p>Messwiederholung ist sowohl auf einfaktorielle als auch zweifaktorielle ANOVA anwendbar.</p>

<h2 id="populationsmodell-der-varianzanalyse">
<a class="anchor" href="#populationsmodell-der-varianzanalyse" aria-hidden="true"><span class="octicon octicon-link"></span></a>Populationsmodell der Varianzanalyse</h2>

<p>In der Population ergibt sich der Messwert aus dem Gesamtmittelwert addiert mit allen Haupt- und Interaktionseffekten, sowie dem Residuum:</p>

<p>$$x_{mjk} = \mu + \tau_{a_j} + \tau_{b_k} + \tau_{(A \times B)<em>{jk}} + \epsilon</em>{mjk}$$</p>

<p>$\rightarrow$ Grundlage fÃ¼r allgemeines lineares Modell!</p>

<h1 id="allgemeines-lineares-modell">
<a class="anchor" href="#allgemeines-lineares-modell" aria-hidden="true"><span class="octicon octicon-link"></span></a>Allgemeines Lineares Modell</h1>

<ul>
  <li>Oberbegriff fÃ¼r eine generisches statistisches Modell zur Prognose bzw. ErklÃ¤rung von metrischen abhÃ¤ngigen Variablen</li>
</ul>

<p>Student-T-Test und Varianzanalyse sind z.B. SonderfÃ¤lle dieses Modells.</p>

<h2 id="einfache-lineare-regression">
<a class="anchor" href="#einfache-lineare-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einfache lineare Regression</h2>

<p>Bei der linearen Regression wird versucht, eine Gerade so zu legen, dass deren mittlerer Abstand zu den empirischen Messwerten mÃ¶glichst gering ist.</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-67-1.png" alt="plot of chunk unnamed-chunk-67" width="576" style="display: block; margin: auto;"></p>

<p><strong>Modellgleichung mit einer unabhÃ¤ngigen Variablen:</strong></p>

<p>In einer Stichprobe:</p>

<p>$$Y = b_0 + b_1 \cdot X_1 + E$$</p>

<p>In der Population:</p>

<p>$$Y = \beta_0 + \beta_1 \cdot X_1 + \epsilon$$</p>

<ul>
  <li>$b_0$/$\beta_0$: Regressionskonstante, Schnittpunkt mit der Y-Achse, âInterceptâ</li>
  <li>$b_1$/$\beta_1$: Regressionsgewicht, Steigung der Regressionsgeraden, âSlopeâ</li>
</ul>

<p>Der Abstand der Messpunkte zur Regressionsgeraden sind die Residuen:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y_fit</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_segment</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">xend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">yend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"hotpink3"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Residuum"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme_custom</span><span class="w">
</span></code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-68-1.png" alt="plot of chunk unnamed-chunk-68" width="576" style="display: block; margin: auto;"></p>

<p>Der Mittelwert der Residuen ist immer 0.</p>

<p>Die Varianz der Residuen wird auch als <strong>Fehlervarianz</strong> bezeichnet, da die angibt, wie weit die empirischen Werte um die Regressionsgerade streuen und damit, wie ungenau die Vorhersagen des Modells sind.</p>

<p>Die Standardabweichung der Residuen ist der <strong>StandardschÃ¤tzfehler</strong>. Sie ist in der Stichprobe allerdings kein erwartungstreuer SchÃ¤tzer des StandardschÃ¤tzfehlers in der Population.</p>

<h3 id="bestimmung-der-regressionskoeffizienten">
<a class="anchor" href="#bestimmung-der-regressionskoeffizienten" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bestimmung der Regressionskoeffizienten</h3>

<p>Die Bedingung, dass der Abstand der Messpunkte zur Regressionsgeraden minimal sein soll, ist am besten erfÃ¼llt wenn $b1$ aus der Produkt-Moment-Korrelation der beiden Variablen sowie ihrer Stichprobenstandardabweichungen $s_X$ und $z_Y$ bestimmt wird:</p>

<p>$$b_1 = r_{XY} \cdot \frac{s_Y}{s_X}$$</p>

<p>$$r_{XY} = \frac{1}{n} \cdot \sum_{m = 1}^n{z_X \cdot z_Y}$$
<em>$z_X$ und $z_Y$ sind die Z-transformierten Werte der Variablen.</em></p>

<p>Bei zwei Z-standardisierten Variablen ist das Regressionsgewicht gleich der Produkt-Moment-Korrelation, weil die Stichprobenstandardabweichungen beide 1 sind.</p>

<p>Die Regressionskonstante $b_0$ ergibt sich dann wie folgt:</p>

<p>$$b_0 = \overline{y} - b_1 \cdot \overline{x}$$</p>

<h3 id="standardfehler-der-modellparameter">
<a class="anchor" href="#standardfehler-der-modellparameter" aria-hidden="true"><span class="octicon octicon-link"></span></a>Standardfehler der Modellparameter</h3>

<p><strong>Erwartungsstreuer SchÃ¤tzer des StandardschÃ¤tzfehlers:</strong></p>

<p>$$\hat{\sigma}_e = \sqrt{\frac{1}{n-2} \cdot \sum{(y_m - \hat{y}_m)^2}}$$
$y_m - \hat{y}_m$ ist die Abweichung des tatsÃ¤chlichen Messwertes vom modellierten Wert, also das Residuum.</p>

<p><strong>SchÃ¤tzer der Standardfehler der Regressionskoeffizienten:</strong></p>

<p>$$\hat{\sigma}_{\beta_0} = \hat{\sigma}_e \cdot \sqrt{\frac{1}{n} + \frac{\overline{x}^2}{n \cdot s^2_X}}$$</p>

<p>$$\hat{\sigma}_{\beta_1} = \sqrt{\frac{\hat{\sigma_e}^2}{n \cdot s_X^2}}$$</p>

<h3 id="alternative-wege-zur-bestimmung-der-regressionskoeffizienten">
<a class="anchor" href="#alternative-wege-zur-bestimmung-der-regressionskoeffizienten" aria-hidden="true"><span class="octicon octicon-link"></span></a>Alternative Wege zur Bestimmung der Regressionskoeffizienten</h3>

<h4 id="kriterium-der-kleinsten-quadrate">
<a class="anchor" href="#kriterium-der-kleinsten-quadrate" aria-hidden="true"><span class="octicon octicon-link"></span></a>Kriterium der kleinsten Quadrate</h4>

<p>Die Regressionskoeffizienten werden so geschÃ¤tzt, dass die Summe der quadrierten Abweichungen der tatsÃ¤chlichen Messwerte von den modellierten Werten minimal wird.</p>

<p>$$\sum_{m=1}^n{(y_m - \hat{y}_m)^2} \rightarrow min$$</p>

<h4 id="likelihood-maximierung">
<a class="anchor" href="#likelihood-maximierung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Likelihood-Maximierung</h4>

<p>Die Grundannahme, dass die abhÃ¤ngige Variable in der Population normalverteilt ist, fÃ¼hrt dazu, dass sie wie folgt modelliert werden kann:</p>

<p>$$y \sim Normal(\beta_0 + \beta_1 \cdot x_m, \sigma_e^2)$$</p>

<p>Die tatsÃ¤chliche AusprÃ¤gung folgt einer Normalverteilung, bei der der Mittelwert der Vorhersagewert des linearen Modells und die Standardabweichung der StandardschÃ¤tzfehler ist.</p>

<p>FÃ¼r diese Normalverteilung kann die Likelihood der empirisch beobachteten Daten bestimmt werden.</p>

<p>Es werden dann die Regressionskoeffizienten gesucht, fÃ¼r die die Likelihood bzw. Log(Likelihood) maximal werden.</p>

<p><strong>Sowohl die Likelihood-Maximierung, als auch das Kriterium der kleinsten Quadrate sind Optimierungsprobleme, die sich kaum von Hand lÃ¶sen lassen und durch Computer numerisch gelÃ¶st werden mÃ¼ssen.</strong></p>

<h3 id="hypothesenprÃ¼fung-bei-einfacher-linearer-regression">
<a class="anchor" href="#hypothesenpr%C3%BCfung-bei-einfacher-linearer-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>HypothesenprÃ¼fung bei einfacher linearer Regression</h3>

<p>$H_{00}$: $\beta_1 = 0$, $H_{01}$: $\beta_1 \neq 0$</p>

<p>$$t = \frac{b_1 - \beta_{10}}{\hat{\sigma}_{b_1}} \sim Student(df = n - 2)$$</p>

<p>($\beta_{10} = 0$ bei spezieller Nullhypothese $H_0: \beta_1 = 0$)</p>

<p>$H_{10}$: $\beta_0 = \beta_{00}$, $H_{11}$: $\beta_0 \neq \beta_{00}$</p>

<p>$$t = \frac{b_0 - \beta_{00}}{\hat{\sigma}_{b_0}} \sim Student(df = n - 2)$$</p>

<h3 id="konfidenzintervalle-fÃ¼r-regressionskoeffizienten">
<a class="anchor" href="#konfidenzintervalle-f%C3%BCr-regressionskoeffizienten" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konfidenzintervalle fÃ¼r Regressionskoeffizienten</h3>

<p>$$b_1 \pm t_{(1-\frac{\alpha}{2}; n-2)} \cdot \hat{\sigma}_{b_1}$$</p>

<p>$$b_0 \pm t_{(1-\frac{\alpha}{2}; n-2)} \cdot \hat{\sigma}_{b_0}$$</p>

<h3 id="einfache-lineare-regression-in-r">
<a class="anchor" href="#einfache-lineare-regression-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einfache lineare Regression in R</h3>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">samples</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">lm1</span><span class="w">

</span><span class="n">summary</span><span class="p">(</span><span class="n">lm1</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## Call:
## lm(formula = y ~ x, data = samples)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7060 -0.9742 -0.4539  0.9479  3.0728 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  7.25267    1.35524   5.352 4.37e-05 ***
## x            0.30451    0.05124   5.943 1.27e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.625 on 18 degrees of freedom
## Multiple R-squared:  0.6624,	Adjusted R-squared:  0.6437 
## F-statistic: 35.32 on 1 and 18 DF,  p-value: 1.267e-05
</code></pre></div></div>

<p>Extraktion der Koeffizienten:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">coef</span><span class="p">(</span><span class="n">lm1</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## (Intercept)           x 
##    7.252667    0.304506
</code></pre></div></div>

<p>Konfidenzintervalle der Koeffizienten:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">confint</span><span class="p">(</span><span class="n">lm1</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##                 2.5 %     97.5 %
## (Intercept) 4.4054111 10.0999220
## x           0.1968588  0.4121532
</code></pre></div></div>

<p>Residuen:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">resid</span><span class="p">(</span><span class="n">lm1</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##            1            2            3            4            5            6            7            8            9           10           11           12           13 
## -0.810005726 -1.669324066 -0.782480228  1.163274890  0.924972643  0.005258351 -1.220609279 -0.634036491  3.072819146  1.016600629 -0.523908529 -1.250597374  0.222625960 
##           14           15           16           17           18           19           20 
## -2.706005447 -0.383962449 -0.892032207  3.008439197  2.631282829  0.436793706 -1.609105554
</code></pre></div></div>

<p>Modellierte(âfittedâ) Werte:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fitted</span><span class="p">(</span><span class="n">lm1</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##        1        2        3        4        5        6        7        8        9       10       11       12       13       14       15       16       17       18       19 
## 11.83282 17.67453 13.81424 13.29164 15.79802 15.81898 11.43628 12.98896 15.57430 16.06184 14.97508 14.91121 15.17624 15.38830 18.22633 17.87727 11.31583 16.72605 18.49644 
##       20 
## 12.85313
</code></pre></div></div>

<h2 id="multiple-lineare-regression">
<a class="anchor" href="#multiple-lineare-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multiple lineare Regression</h2>

<ul>
  <li>Vorhersage von metrischen Endpunkten bei mehreren unabhÃ¤ngigen Variablen</li>
  <li>Kontrolle von StÃ¶rvariablen</li>
  <li>
    <p>BerÃ¼cksichtigung von Redundanzen zwischen Merkmalen</p>

    <p>z.B. Wenn UVs nicht unabhÃ¤ngig voneinander sind</p>
  </li>
</ul>

<h3 id="modellgleichung">
<a class="anchor" href="#modellgleichung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Modellgleichung</h3>

<p>In der Stichprobe:</p>

<p>$$Y = b_0 + b_1 \cdot X_1 + b_2 \cdot X_2 + \dots + b_j \cdot X_j + E$$</p>

<p>In der Population:</p>

<p>$$Y = \beta_0 + \beta_1 \cdot X_1 + \beta_2 \cdot X_2 + \dots + \beta_j \cdot X_J + \epsilon$$</p>

<h3 id="bestimmung-der-regressionskoeffizienten-1">
<a class="anchor" href="#bestimmung-der-regressionskoeffizienten-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bestimmung der Regressionskoeffizienten</h3>

<p>Ãhnlich wie bei einfacher linearer Regression werden die Koeffizienten so geschÃ¤tzt, dass die Summer der quadrierten Abweichungen von den modellierten Werten minimal wird:</p>

<p>$$\sum_{m=1}^n{(y_m - \hat{y}_m)^2} \rightarrow min$$
Geometrische Sicht:</p>

<p>Bei zwei unabhÃ¤ngigen Variablen erzeugt das Regressionsmodell eine Ebene (statt einer Geraden bei einfacher Regression). Die Ebene wird so platziert, dass der AbstÃ¤nde aller empirischen Messpunkte zur Ebene minimal werden.</p>

<p>Die Regressionskoeffizienten kÃ¶nnen auch analog zur einfacher Regression berechnet werden, was aber unÃ¼blich ist. (siehe EGS Kapitel 19.3.3)</p>

<p>Stattdessen erfolgt die Bestimmung bei multipler Regression eher numerisch.</p>

<h3 id="kompensatorisches-modell">
<a class="anchor" href="#kompensatorisches-modell" aria-hidden="true"><span class="octicon octicon-link"></span></a>Kompensatorisches Modell</h3>

<p>Mehrere Kombinationen vom UVs kÃ¶nnen in der multiplen Regression zur gleichen AusprÃ¤gung der AV fÃ¼hren.</p>

<p>Beispiel:</p>

<ul>
  <li>$\beta_0 = 10$</li>
  <li>$\beta_1 = 2$</li>
  <li>$\beta_2 = 1$</li>
</ul>

<p>$$10 + 2 \cdot 2 + 1 \cdot 0.5 = 10 + 2 \cdot 1 + 1 \cdot 2.5 = 14.5$$</p>

<p>FÃ¼r $X_1 = 2; X_2 = 0.5$ sowie fÃ¼r $X_1 = 1; X_2 = 2.5$ ergibt sich das gleiche $Y = 14.5$.</p>

<p>Die UVs kÃ¶nnen also ihre EinflÃ¼sse gegenseitig kompensieren.</p>

<h3 id="dummy-kodierung">
<a class="anchor" href="#dummy-kodierung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dummy Kodierung</h3>

<p>Bei UVs, die mehr als zwei Faktorstufen beinhalten, wird jede eine Referenzkategorie definiert und alle anderen Stufen als âDummyâ-Variablen kodiert die jeweils AusprÃ¤gungen 0 oder 1 haben.</p>

<h4 id="schritte-der-dummy-kodieruung">
<a class="anchor" href="#schritte-der-dummy-kodieruung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Schritte der Dummy-Kodieruung</h4>

<ol>
  <li>
    <p>Referenzkategorie zuweisen (vollkommen willkÃ¼rlich)</p>

    <p>Die Faktorstufe der Referenzkategorie hat auf allen Dummy-Variablen den Wert 0.</p>
  </li>
  <li>
    <p>Allen anderen Kategorien der unabhÃ¤ngigen Faktorvariablen werden Dummy-Werte zugewiesen, so dass:</p>
    <ul>
      <li>jede Kategorie in nur einer Dummy-Variablen den Wert 1 hat</li>
      <li>jede Dummy-Variable nur fÃ¼r eine Kategorie den Wert 1 hat und sonst Ã¼berall 0</li>
    </ul>
  </li>
</ol>

<h3 id="interpretation-von-multiplen-regressionsgewichten">
<a class="anchor" href="#interpretation-von-multiplen-regressionsgewichten" aria-hidden="true"><span class="octicon octicon-link"></span></a>Interpretation von multiplen Regressionsgewichten</h3>

<h4 id="als-regressionsgewicht-einer-bedingten-einfacher-regression">
<a class="anchor" href="#als-regressionsgewicht-einer-bedingten-einfacher-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Als Regressionsgewicht einer bedingten einfacher Regression.</h4>

<p>Alle UVs bis auf eine werden konstant gehalten.</p>

<p>Nur noch eine UV und ihr Regressionsgewicht haben Einfluss auf $Y$.</p>

<p>Entspricht dem Modell fÃ¼r eine Subgruppe an Personen, die hinsichtlich aller UVs bis auf eine identisch sind.</p>

<h4 id="als-regressionsgewicht-zweier-regressionsredsiduen">
<a class="anchor" href="#als-regressionsgewicht-zweier-regressionsredsiduen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Als Regressionsgewicht zweier Regressionsredsiduen</h4>

<p>Es werden zwei Residuen von einfachen Regressionen gebildet:</p>

<ul>
  <li>Residuum von $Y(X_2)$ ($Y$ in AbhÃ¤ngigkeit von $X_2$</li>
  <li>Residuum von $X_1(X_2)$ ($X_1$ in AbhÃ¤ngigkeit von $X_2$</li>
</ul>

<p>Diese Residuen werden dann als unabhÃ¤ngige und abhÃ¤ngige Variable in einer weiteren einfacher Regression verwendet.</p>

<p>Dadurch werden die betrachtete UV und die AV von AbhÃ¤ngigkeiten zu anderen UVs bereinigt. Das Regressionsgewicht quantifiziert den Einfluss der betrachteten UV, der nicht bereits durch andere UVs erklÃ¤rt wird.</p>

<h3 id="inkrementelle-varianzaufklÃ¤rung">
<a class="anchor" href="#inkrementelle-varianzaufkl%C3%A4rung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Inkrementelle VarianzaufklÃ¤rung</h3>

<p>Der Determinationskoeffizient $R^2$ ist wie in der einfacher Regression ein MaÃ dafÃ¼r, wie prÃ¤zise die Vorhersagen des Modells sind.</p>

<p>Mit zumessender Anzahl UVs wird das Modell prÃ¤ziser:</p>

<table>
  <tbody>
    <tr>
      <td>$$R^2_{Y</td>
      <td>X_1} \lt R^2_{Y</td>
      <td>X_1,X_2} \lt R^2_{Y</td>
      <td>X_1, X_2, X_3}$$</td>
    </tr>
  </tbody>
</table>

<h3 id="punktschÃ¤tzung-der-varianzaufklÃ¤rung">
<a class="anchor" href="#punktsch%C3%A4tzung-der-varianzaufkl%C3%A4rung" aria-hidden="true"><span class="octicon octicon-link"></span></a>PunktschÃ¤tzung der VarianzaufklÃ¤rung</h3>

<p><strong>$R^2$ ist kein erwartungstreuer SchÃ¤tzer der VarianzaufklÃ¤rung in der Population $\rho^2$.</strong></p>

<p>Beispiel: 100 Stichproben zu je $n =10$ Messpunkten von drei komplett unabhÃ¤ngigen Variablen $X_1$, $X_2$ und $Y$. Alle Variablen sind zufÃ¤llig generiert und normalverteilt.</p>

<p>Korrelationsplot der ersten 20 Stichproben (200 Messwerte):</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-74-1.png" alt="plot of chunk unnamed-chunk-74" width="576" style="display: block; margin: auto;"></p>

<p>Es sollte also keine Korrelation zwischen den Variablen geben und damit auch keine VarianzaufklÃ¤rung. Entsprechend sollte in jeder Stichprobe $R^2 \approx 0$ gelten.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">stichprobe</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">mutate</span><span class="p">(</span><span class="w">
  </span><span class="n">Rsq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span><span class="n">lm</span><span class="p">(</span><span class="n">Y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">X1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X2</span><span class="p">))</span><span class="o">$</span><span class="n">r.squared</span><span class="w">
</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">samples</span><span class="w">
</span></code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-76-1.png" alt="plot of chunk unnamed-chunk-76" width="576" style="display: block; margin: auto;"></p>

<p>Durchschnittlicher Determinationskoeffizient, $\overline{R}^2$:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 0.2174016
</code></pre></div></div>

<p>Es muss eine Adjustierung vorgenommen werden, damit $\rho^2$ nicht Ã¼berschÃ¤tzt wird.</p>

<h4 id="wherry-1-adjustierung">
<a class="anchor" href="#wherry-1-adjustierung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Wherry-1-Adjustierung</h4>

<p>$$\hat{\rho}^2 = 1 - \frac{n-1}{n-k-1} \cdot (1-R^2)$$
($n$: StichprobengrÃ¶Ãe, $k$: Anzahl der Regressionsgewichte)</p>

<p>Diese wird standardmÃ¤Ãig in R verwendet.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">stichprobe</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">mutate</span><span class="p">(</span><span class="w">
  </span><span class="n">Rsq_adj</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span><span class="n">lm</span><span class="p">(</span><span class="n">Y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">X1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X2</span><span class="p">))</span><span class="o">$</span><span class="n">adj.r.squared</span><span class="w">
</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">samples</span><span class="w">
</span></code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-79-1.png" alt="plot of chunk unnamed-chunk-79" width="576" style="display: block; margin: auto;"></p>

<p>Durchschnittlicher adjustierter Determinationskoeffizient, $\overline{R}_{Wherry-1}^2$:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] -0.006197947
</code></pre></div></div>

<h4 id="adjustierung-nach-olkin--pratt-2017">
<a class="anchor" href="#adjustierung-nach-olkin--pratt-2017" aria-hidden="true"><span class="octicon octicon-link"></span></a>Adjustierung nach Olkin &amp; Pratt (2017)</h4>

<p>$$\hat{\rho}^2 = 1= \frac{n-3}{n-k-1} \cdot ((1-R^2) + \frac{2}{n-k-1} \cdot (1-R^2))$$</p>

<p>In R kann die Olkin-Pratt-Adjustierung mit dem Paket <code class="language-plaintext highlighter-rouge">semEff</code> berechnet werden:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">semEff</span><span class="p">)</span><span class="w">

</span><span class="c1"># Berechnung ist sehr langsam, daher hier nur fÃ¼r erste Stichprobe</span><span class="w">
</span><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">filter</span><span class="p">(</span><span class="n">stichprobe</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">mutate</span><span class="p">(</span><span class="w">
  </span><span class="n">Rsq_OP</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">R2</span><span class="p">(</span><span class="n">lm</span><span class="p">(</span><span class="n">Y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">X1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X2</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">.</span><span class="p">),</span><span class="w"> </span><span class="n">adj.type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"olkin-pratt"</span><span class="p">)[</span><span class="m">2</span><span class="p">]</span><span class="w">
</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">samples</span><span class="w">
</span></code></pre></div></div>

<p>Durchschnittlicher adjustierter Determinationskoeffizient, $\overline{R}_{Olkin-Pratt}^2$:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="o">$</span><span class="n">Rsq_OP</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 0
</code></pre></div></div>

<h3 id="hypothesenprÃ¼fung-mit-multipler-linearer-regression">
<a class="anchor" href="#hypothesenpr%C3%BCfung-mit-multipler-linearer-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>HypothesenprÃ¼fung mit multipler linearer Regression</h3>

<h4 id="hypothesen-zum-gesamtmodell-globale-hypothesen">
<a class="anchor" href="#hypothesen-zum-gesamtmodell-globale-hypothesen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesen zum Gesamtmodell, globale Hypothesen</h4>

<p>$$H_0: \beta_1 = \beta_2 = \dots = \beta_k = 0 \rightarrow H_o: \rho^2 = 0$$</p>

<p>Alle Regressionsgewichte sind null, also wird keine Varianz durch die unabhÃ¤ngigen Variablen aufgeklÃ¤rt.</p>

<p>$$H_1: \beta_j \ne 0 \rightarrow \rho^2 \ne 0$$</p>

<p>Mindestens eines der Regressionsgewichte $\beta_j$ ist nicht null, also wird ein Teil der Varianz aufgeklÃ¤rt.</p>

<p>Verteilung der PrÃ¼fgrÃ¶Ãe unter der Nullhypothese:</p>

<p>$$F = \frac{n-k-1}{k} \cdot \frac{R^2}{1-R^2} \sim F(df_1 = k, df_2 = n-k-1)$$</p>

<h4 id="hypothesen-Ã¼ber-einzelne-regressionsgewichte">
<a class="anchor" href="#hypothesen-%C3%BCber-einzelne-regressionsgewichte" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesen Ã¼ber einzelne Regressionsgewichte</h4>

<p>$$H_0 : \beta_j = 0$$</p>

<p>Verteilung der PrÃ¼fgrÃ¶Ãe unter $H_0$:</p>

<p>$$T = \frac{\hat{\beta}<em>j}{\hat{\sigma}</em>{\beta_j}} \sim Student(df = n-k-1)$$</p>

<p>Das geschÃ¤tzte Regressionsgewicht $\hat\beta_j$ wird am <a href="#standardfehler-der-modellparameter">geschÃ¤tzten Standardfehler</a> $\hat\sigma_{\beta_j}$ standardisiert und folgt dann eine Student-T-Verteilung.</p>

<h4 id="hypothesen-Ã¼ber-modellvergleiche">
<a class="anchor" href="#hypothesen-%C3%BCber-modellvergleiche" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesen Ã¼ber Modellvergleiche</h4>

<p>Die âNÃ¼tzlichkeitâ einer oder mehrerer unabhÃ¤ngiger Variablen kann durch den Vergleich eines uneingeschrÃ¤nkten Modells, welches alle UVs enthÃ¤lt, mit einem eingeschrÃ¤nkten Modell, in dem eine oder mehrere UV fehlen, bestimmt werden.</p>

<p>Indem UVs entfernt werden, verschwindet ihre VarianzaufklÃ¤rung im nun grÃ¶Ãeren Residuum.</p>

<p>Verglichen werden letztendlich die Determinationskoeffizienten der Modelle $R_u^2$ (uneingeschrÃ¤nkt) und $R_e^2$ (eingeschrÃ¤nkt).</p>

<p>Verteilung unter der Nullhypothese $H_0: \rho_u^2 - \rho_y^2 = 0$:</p>

<p>$$F = \frac{n-k_u-1}{k_u - k_e} \cdot \frac{R_u^2 - R_e^2}{1-R_u^2} \sim F(df_1 = k_u - k_e, df_2 = n-k_u-1)$$</p>

<p>Sonderfall, wenn nur eine UV entfernt wird:</p>

<p>$$F = (n-k_u-1) \cdot \frac{R_u^2-R_e^2}{1-R_u^2} \sim F(df_1 = 1, df_2 = n - k_u -1)$$</p>

<p>Dieser F-Wert (fÃ¼r nur eine entfernte UV) entspricht dem quadrierten T-Wert aus der <a href="#hypothesen-%C3%BCber-einzelne-regressionsgewichte">HypothesenprÃ¼fung Ã¼ber einzelne Regressionsgewichte</a>. Beide AnsÃ¤tze sind Ã¤quivalent.</p>

<h3 id="modellvergleiche-in-r">
<a class="anchor" href="#modellvergleiche-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Modellvergleiche in R</h3>

<p>Beispiel:</p>

<ul>
  <li>Stichprobe mit $n=20$</li>
  <li>2 unabhÃ¤ngige, normalverteilte Variablen</li>
  <li>$Y$ korreliert mit $X_1$ leicht positiv und mit $X_2$ leicht negativ</li>
  <li>im Datensatz ist ein simulierter Interaktionseffekt vorhanden</li>
  <li>normalverteiltes Residuum</li>
</ul>

<p><img src="statistik-2-abbildungen/unnamed-chunk-83-1.png" alt="plot of chunk unnamed-chunk-83" width="576" style="display: block; margin: auto;"></p>

<p>Vergleich von uneingeschrÃ¤nktem Modell (mit Interaktion) und eingeschrÃ¤nktem (ohne Interaktion):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lm_u</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">Y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">X1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">X2</span><span class="p">,</span><span class="w"> </span><span class="n">samples</span><span class="p">)</span><span class="w">
</span><span class="n">lm_e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">Y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">X1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X2</span><span class="p">,</span><span class="w"> </span><span class="n">samples</span><span class="p">)</span><span class="w">

</span><span class="n">anova</span><span class="p">(</span><span class="n">lm_u</span><span class="p">,</span><span class="w"> </span><span class="n">lm_e</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Analysis of Variance Table
## 
## Model 1: Y ~ X1 * X2
## Model 2: Y ~ X1 + X2
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    196 3165.1                                  
## 2    197 3395.8 -1   -230.69 14.286 0.0002084 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
</code></pre></div></div>

<p>Das uneingeschrÃ¤nkte Modell klÃ¤rt signifikant mehr Varianz auf als das eingeschrÃ¤nkte. Es gibt also einen Interaktionseffekt.</p>

<p>Vergleich der Determinationskoeffizienten:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">R_u</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span><span class="n">lm_u</span><span class="p">)</span><span class="o">$</span><span class="n">adj.r.squared</span><span class="w">
</span><span class="n">R_e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span><span class="n">lm_e</span><span class="p">)</span><span class="o">$</span><span class="n">adj.r.squared</span><span class="w">

</span><span class="n">dR</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">R_u</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">R_e</span><span class="w">

</span><span class="n">dR</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 0.0442245
</code></pre></div></div>

<h4 id="likelihood-quotienten-test">
<a class="anchor" href="#likelihood-quotienten-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Likelihood-Quotienten-Test</h4>

<p>Wilksâ $\Lambda$: Quotient der Likelihoods der empirischen Daten unter dem eingeschrÃ¤nkten und dem uneingeschrÃ¤nkten Modell.</p>

<p>$$\Lambda = \frac{Lik(Y_e)}{Lik(Y_u)}$$</p>

<p>PrÃ¼fgrÃ¶Ãe des Likelihood-Quotienten-Tests:</p>

<p>$$-2 \cdot log(\Lambda) = -2 \cdot log(Lik(Y_e) + 2 \cdot log(Lik(Y_u))$$</p>

<p>Unter der Nullhypothese $H_0: \rho^2_u - \rho^2_e = 0$ gilt asymptotisch (also bei ausreichend groÃen Stichproben):</p>

<p>$$-2 \cdot log(\Lambda) \sim \chi^2(df = k_u - k_e)$$</p>

<h3 id="interaktionseffekte-bei-mutlipler-linearer-regression">
<a class="anchor" href="#interaktionseffekte-bei-mutlipler-linearer-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Interaktionseffekte bei mutlipler linearer Regression</h3>

<p>$$Y = \beta_0 + \beta_1 \cdot X_1 + \beta_2 \cdot X_2 + \beta_3 \cdot X_1 \cdot X_2 + \epsilon$$</p>

<p>$\beta_3 \cdot X_1 \cdot X_2$ ist der Interaktionsterm. $\beta_3$ ist das Regressionsgewicht des Interaktionseffektes.</p>

<p>Durch Modellvergleiche mit eingeschrÃ¤nkten Modellen, die den Interaktionsterm nicht enthalten, kann bestimmt werden, welcher Anteil der Varianz durch die Interaktion aufgeklÃ¤rt wird.</p>

<p>Beispielhypothese:</p>

<p>$$Y_u = \beta_0 + \beta_1 \cdot X_1 + \beta_2 \cdot X_2 + \beta_3 \cdot X_1 \cdot X_2 + \epsilon$$
$$Y_e = \beta_0 + \beta_1 \cdot X_1 + \beta_2 \cdot X_2 + \epsilon$$
$H_0: \rho^2_u - \rho^2_e = 0$, die Interaktion von $X_1$ und $X_2$ klÃ¤rt keine zusÃ¤tzliche Varianz auf.</p>

<h2 id="annahmen-des-allgemeinen-linearen-modells">
<a class="anchor" href="#annahmen-des-allgemeinen-linearen-modells" aria-hidden="true"><span class="octicon octicon-link"></span></a>Annahmen des allgemeinen linearen Modells</h2>

<ul>
  <li>Messfehlerfreiheit der UVs</li>
  <li>korrekte Spezifikation des Modells (LinearitÃ¤t)</li>
  <li>HomoskedastizitÃ¤t</li>
  <li>UnabhÃ¤ngigkeit der Residuen</li>
  <li>Normalverteilung der Residuen</li>
</ul>

<h3 id="korrekte-spezifikation-linearitÃ¤t">
<a class="anchor" href="#korrekte-spezifikation-linearit%C3%A4t" aria-hidden="true"><span class="octicon octicon-link"></span></a>Korrekte Spezifikation, LinearitÃ¤t</h3>

<p><strong>Underfitting</strong>: relevante UVs fehlen im Modell</p>

<p><strong>Overfitting</strong>: irrelevante UVs, die keine Varianz aufklÃ¤ren, sind im Modell enthalten.</p>

<p>Form der Abbilddung der AV auf die UVs muss korrekt sein.</p>

<p>Bei Verletzung der Annahmen:</p>

<ul>
  <li>verzerrte SchÃ¤tzer der Regressionsgewichte</li>
  <li>erhÃ¶hter Prognosefehler</li>
  <li>verringerte TeststÃ¤rke</li>
  <li>falsche Schlussfolgerungen</li>
</ul>

<h4 id="prÃ¼fung-der-linearitÃ¤t">
<a class="anchor" href="#pr%C3%BCfung-der-linearit%C3%A4t" aria-hidden="true"><span class="octicon octicon-link"></span></a>PrÃ¼fung der LinearitÃ¤t</h4>

<p>Plot der Residuen gegenÃ¼ber den vorhergesagten (fitted) Werten</p>

<p><strong>EingeschrÃ¤nktes Modell:</strong></p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-86-1.png" alt="plot of chunk unnamed-chunk-86" width="576" style="display: block; margin: auto;"></p>

<p><strong>UneingeschrÃ¤nktes Modell:</strong></p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-87-1.png" alt="plot of chunk unnamed-chunk-87" width="576" style="display: block; margin: auto;"></p>

<p><strong>Die durchschnittlichen Residuen aller Kombinationen der UVs sollten einer Geraden mit Steigung 0 folgen, wenn LinearitÃ¤t gegeben ist.</strong></p>

<h3 id="prÃ¼fung-der-homoskedastizitÃ¤t">
<a class="anchor" href="#pr%C3%BCfung-der-homoskedastizit%C3%A4t" aria-hidden="true"><span class="octicon octicon-link"></span></a>PrÃ¼fung der HomoskedastizitÃ¤t</h3>

<h4 id="breusch-pagan-test-in-r">
<a class="anchor" href="#breusch-pagan-test-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Breusch-Pagan-Test in R</h4>

<p>(mit Paket <code class="language-plaintext highlighter-rouge">lmtest</code>)</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">lmtest</span><span class="p">)</span><span class="w">

</span><span class="n">bptest</span><span class="p">(</span><span class="n">lm_u</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	studentized Breusch-Pagan test
## 
## data:  lm_u
## BP = 3.351, df = 3, p-value = 0.3406
</code></pre></div></div>

<p>Wenn $p \ge 0.05$, dann kann die Nullhypothese, dass HomoskedastizitÃ¤t vorliegt, akzeptiert werden.</p>

<p><strong>Der Breusch-Pagan-Test ist auch sensitiv fÃ¼r eine Verletzung der UnabhÃ¤ngigkeit der Residuen.</strong></p>

<h4 id="visuelle-prÃ¼fung-der-heteroskedastizitÃ¤t">
<a class="anchor" href="#visuelle-pr%C3%BCfung-der-heteroskedastizit%C3%A4t" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visuelle PrÃ¼fung der HeteroskedastizitÃ¤t</h4>

<p>Plot der Residuen gegenÃ¼ber den vorhergesagten (fitted) Werten.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit_u</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">res_u</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Vorhersage"</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Residuum"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme_custom</span><span class="w">
</span></code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-89-1.png" alt="plot of chunk unnamed-chunk-89" width="576" style="display: block; margin: auto;"></p>

<p>Es sind keine offensichtlichen Unterschieden in der Varianz der Residuen erkennbar. Damit liegt vermutlich HomoskedastizitÃ¤t vor, sollte aber dennoch genau getestet werden.</p>

<h3 id="normalverteilung-der-residuen">
<a class="anchor" href="#normalverteilung-der-residuen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Normalverteilung der Residuen</h3>

<h4 id="shapiro-wilk-test">
<a class="anchor" href="#shapiro-wilk-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Shapiro-Wilk-Test</h4>

<ul>
  <li>testet beliebige Werte auf Normalverteilung</li>
</ul>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">shapiro.test</span><span class="p">(</span><span class="n">samples</span><span class="o">$</span><span class="n">res_u</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Shapiro-Wilk normality test
## 
## data:  samples$res_u
## W = 0.99108, p-value = 0.2553
</code></pre></div></div>

<p>Wenn $p \ge 0.05$, dann kann Normalverteilung der Residuen angenommen werden.</p>

<h4 id="visuelle-prÃ¼fung-der-normalverteilung">
<a class="anchor" href="#visuelle-pr%C3%BCfung-der-normalverteilung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visuelle PrÃ¼fung der Normalverteilung</h4>

<p><strong>Histogram der Residuen</strong></p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-91-1.png" alt="plot of chunk unnamed-chunk-91" width="576" style="display: block; margin: auto;"></p>

<p><strong>Q-Q-Plot, Quantil-Quantil-Diagramm</strong></p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-92-1.png" alt="plot of chunk unnamed-chunk-92" width="576" style="display: block; margin: auto;"></p>

<p>Wenn die Residuumswerte nah an der theoretischen Normalverteilung (entlang der diagonalen Geraden) liegen, liegt vermutlich Normalverteilung vor, sollte aber noch genau getestet werden.</p>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->


<div class="post-nav">
  <span>
    
  </span>
  <span>
    
  </span>
</div>
  </section>


    </main>
    


<footer class="background" style="--image: url('/preview/pr-9/images/lines-21.png')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    
  </div>

  <div>
    Â© 2024
    PHB
    Â  | Â  Erstellt mit
    <a href="https://github.com/greenelab/lab-website-template">
      Lab Website Template
    </a>
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
