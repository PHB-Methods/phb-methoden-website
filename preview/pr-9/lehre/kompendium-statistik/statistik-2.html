<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  



























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>B.Sc. Psychologie Statisik II | Psychologische Methodenlehre | PHB</title>

<link rel="icon" href="">

<meta name="title" content="B.Sc. Psychologie Statisik II | Psychologische Methodenlehre | PHB">
<meta name="description" content="Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin">

<meta property="og:title" content="B.Sc. Psychologie Statisik II | Psychologische Methodenlehre | PHB">
<meta property="og:site_title" content="PHB">
<meta property="og:description" content="Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin">
<meta property="og:url" content="/preview/pr-9">
<meta property="og:image" content="/preview/pr-9/images/share.jpg">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="B.Sc. Psychologie Statisik II">
<meta property="twitter:description" content="Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin">
<meta property="twitter:url" content="/preview/pr-9">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/preview/pr-9/images/share.jpg">


  <meta name="author" content="Esther Weidauer">
  <meta property="og:type" content="article">
  <meta property="og:updated_time" content="2024-09-04T12:59:19+00:00">
  <meta property="article:published_time" content="">
  <meta property="article:modified_time" content="2024-09-04T12:59:19+00:00">
  <meta name="revised" content="2024-09-04T12:59:19+00:00">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "BlogPosting",
      "author": { "@type": "Person", "name": "B.Sc. Psychologie Statisik II" },
      "datePublished": "",
      "dateModified": "2024-09-04T12:59:19+00:00",
    
    "name": "B.Sc. Psychologie Statisik II",
    "description": "Psychologische Methodenlehre. Statistik und Forschungsmethoden an der Psychologischen Hochschule Berlin",
    "headline": "B.Sc. Psychologie Statisik II",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "" }
    },
    "url": "/preview/pr-9"
  }
</script>

<link rel="alternate" type="application/rss+xml" href="/preview/pr-9/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet" media="none" onload="this.removeAttribute('media'); this.onload = null;">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/preview/pr-9/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/all.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/background.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/body.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/button.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/card.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/code.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/float.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/font.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/form.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/header.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/image.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/link.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/list.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/main.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/section.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/table.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/preview/pr-9/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/preview/pr-9/_scripts/anchors.js"></script>

  <script src="/preview/pr-9/_scripts/dark-mode.js"></script>

  <script src="/preview/pr-9/_scripts/fetch-tags.js"></script>

  <script src="/preview/pr-9/_scripts/search.js"></script>

  <script src="/preview/pr-9/_scripts/site-search.js"></script>

  <script src="/preview/pr-9/_scripts/table-wrap.js"></script>

  <script src="/preview/pr-9/_scripts/tooltip.js"></script>


<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

  <body>
    







<header class="background" style="--image: url('/preview/pr-9/images/lines-7.png')" data-dark="true">
  <a href="/preview/pr-9/" class="home">
    
      <span class="logo">
        
          <img src="/preview/pr-9/images/logo.png" alt="logo">
        
      </span>
    
    
      <span class="title-text" data-tooltip="Home">
        
          <span class="title">PHB</span>
        
        
          <span class="subtitle">Psychologische Methodenlehre</span>
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/preview/pr-9/team/" data-tooltip="Unser Team">
          Team
        </a>
      
    
      
        <a href="/preview/pr-9/lehre/" data-tooltip="Methodenausbildung">
          Lehre
        </a>
      
    
      
        <a href="/preview/pr-9/forschung/" data-tooltip="Forschungsprojekte">
          Forschung
        </a>
      
    
      
        <a href="/preview/pr-9/beratung/" data-tooltip="Beratung zu Methodenfragen">
          Beratung
        </a>
      
    
      
        <a href="/preview/pr-9/aktuelles/" data-tooltip="Neuigkeiten und Ankündigungen">
          Aktuelles
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - filter out blank sections
-->






  
  
  

  <section class="background" data-size="1">
    <!--
  background: ;
  dark: ;
  size: 1;
-->


<h1 class="center">B.Sc. Psychologie Statisik II</h1>

<div class="post-info">
  
    
    
      <span data-tooltip="Author">
        <i class="icon fa-solid fa-feather-pointed"></i>
        <span>Esther Weidauer</span>
      </span>
    
  

  
  

  

  
    <span data-tooltip="Last updated on">
      <i class="icon fa-solid fa-clock-rotate-left"></i>
      <span>September 04, 2024</span>
    </span>
  
</div>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->


<ul id="toc" class="section-nav">
<li class="toc-entry toc-h1">
<a href="#stichprobenkennwerte-verteilung">Stichprobenkennwerte-Verteilung</a>
<ul>
<li class="toc-entry toc-h2"><a href="#beispiel-mittelwert">Beispiel: Mittelwert</a></li>
<li class="toc-entry toc-h2"><a href="#standardfehler-des-mittelwertes">Standardfehler des Mittelwertes</a></li>
<li class="toc-entry toc-h2"><a href="#berechnung-des-standardfehlers-des-mittelwertes">Berechnung des Standardfehlers des Mittelwertes</a></li>
<li class="toc-entry toc-h2"><a href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes">Schätzung des Standardfehlers des Mittelwertes</a></li>
<li class="toc-entry toc-h2"><a href="#zentraler-grenzwertsatz">Zentraler Grenzwertsatz</a></li>
</ul>
</li>
<li class="toc-entry toc-h1">
<a href="#punktsch%C3%A4tzung-von-populationsparametern">Punktschätzung von Populationsparametern</a>
<ul>
<li class="toc-entry toc-h2"><a href="#g%C3%BCtekriterien-f%C3%BCr-parametersch%C3%A4tzung">Gütekriterien für Parameterschätzung</a></li>
<li class="toc-entry toc-h2"><a href="#punktsch%C3%A4tzung-des-mittelwertes">Punktschätzung des Mittelwertes</a></li>
<li class="toc-entry toc-h2"><a href="#punktsch%C3%A4tzung-der-varianz">Punktschätzung der Varianz</a></li>
</ul>
</li>
<li class="toc-entry toc-h1">
<a href="#intervallsch%C3%A4tzung-von-populationsparametern">Intervallschätzung von Populationsparametern</a>
<ul>
<li class="toc-entry toc-h2">
<a href="#konfidenzintervall-des-mittelwertes">Konfidenzintervall des Mittelwertes</a>
<ul>
<li class="toc-entry toc-h3"><a href="#konfidenzintervall-pro-stichprobe">Konfidenzintervall pro Stichprobe</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#sch%C3%A4tzung-des-konfidenzintervalls-des-mittelwertes">Schätzung des Konfidenzintervalls des Mittelwertes</a></li>
<li class="toc-entry toc-h2"><a href="#konfidenzintervall-abg%C3%A4ngig-von-stichprobengr%C3%B6%C3%9Fe">Konfidenzintervall abgängig von Stichprobengröße</a></li>
</ul>
</li>
<li class="toc-entry toc-h1">
<a href="#statistische-hypothesenpr%C3%BCfung">Statistische Hypothesenprüfung</a>
<ul>
<li class="toc-entry toc-h2">
<a href="#signifikanztests">Signifikanztests</a>
<ul>
<li class="toc-entry toc-h3"><a href="#einseitiger-signifikanztest">Einseitiger Signifikanztest</a></li>
<li class="toc-entry toc-h3"><a href="#zweiseitiger-signifikanztest">Zweiseitiger Signifikanztest</a></li>
<li class="toc-entry toc-h3"><a href="#standardisierte-pr%C3%BCfgr%C3%B6%C3%9Fen">Standardisierte Prüfgrößen</a></li>
<li class="toc-entry toc-h3"><a href="#signifikanztest-mit-empirischen-daten">Signifikanztest mit empirischen Daten</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#hypothesentests">Hypothesentests</a>
<ul>
<li class="toc-entry toc-h3"><a href="#standardisierter-effekt-cohens-delta">Standardisierter Effekt: Cohen’s $\delta$</a></li>
<li class="toc-entry toc-h3"><a href="#konfidenzintervalle-f%C3%BCr-cohens-delta">Konfidenzintervalle für Cohen’s $\delta$</a></li>
<li class="toc-entry toc-h3">
<a href="#einstichproben-gauss-test">Einstichproben-Gauss-Test</a>
<ul>
<li class="toc-entry toc-h4"><a href="#einstichproben-gauss-test-in-r">Einstichproben-Gauss-Test in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#einstichproben-t-test">Einstichproben T-Test</a>
<ul>
<li class="toc-entry toc-h4"><a href="#einstichproben-t-test-in-r">Einstichproben T-Test in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#einstichproben-t-test-f%C3%BCr-abh%C3%A4ngige-beobachtungen">Einstichproben T-Test für abhängige Beobachtungen</a>
<ul>
<li class="toc-entry toc-h4"><a href="#einstichproben-t-test-f%C3%BCr-abh%C3%A4ngige-beobachtungen-t-test-in-r">Einstichproben T-Test für abhängige Beobachtungen T-Test in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#einstichproben-binomialtest">Einstichproben Binomialtest</a>
<ul>
<li class="toc-entry toc-h4"><a href="#binomialtest-in-r">Binomialtest in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#zweistichproben-t-test">Zweistichproben T-Test</a>
<ul>
<li class="toc-entry toc-h4"><a href="#zweistichproben-t-test-in-r">Zweistichproben T-Test in R</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#power-und-stichprobenplanung">Power und Stichprobenplanung</a>
<ul>
<li class="toc-entry toc-h3"><a href="#stichprobenplanung-in-r">Stichprobenplanung in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#tests-f%C3%BCr-kategoriale-merkmale">Tests für Kategoriale Merkmale</a>
<ul>
<li class="toc-entry toc-h3"><a href="#chi2-statistik">$\chi^2$-Statistik</a></li>
<li class="toc-entry toc-h3"><a href="#cramers-v">Cramer’s $V$</a></li>
<li class="toc-entry toc-h3">
<a href="#chi2-test">$\chi^2$-Test</a>
<ul>
<li class="toc-entry toc-h4"><a href="#chi2-test-in-r">$\chi^2$-Test in R</a></li>
<li class="toc-entry toc-h4"><a href="#kontinuit%C3%A4tskorrektur">Kontinuitätskorrektur</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1">
<a href="#multiplizit%C3%A4t">Multiplizität</a>
<ul>
<li class="toc-entry toc-h2"><a href="#bonferroni-korrektur">Bonferroni-Korrektur</a></li>
<li class="toc-entry toc-h2"><a href="#holm-bonferroni-korrektur">Holm-Bonferroni-Korrektur</a></li>
<li class="toc-entry toc-h2"><a href="#fallback-prozedur">Fallback-Prozedur</a></li>
</ul>
</li>
<li class="toc-entry toc-h1">
<a href="#varianzanalyse-anova">Varianzanalyse (ANOVA)</a>
<ul>
<li class="toc-entry toc-h2"><a href="#voraussetzungen">Voraussetzungen</a></li>
<li class="toc-entry toc-h2">
<a href="#einfaktorielle-varianzanalyse">Einfaktorielle Varianzanalyse</a>
<ul>
<li class="toc-entry toc-h3">
<a href="#messwertezerlegung">Messwertezerlegung</a>
<ul>
<li class="toc-entry toc-h4"><a href="#effekt-von-faktorstufen">Effekt von Faktorstufen</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#quadratsummenzerlegung">Quadratsummenzerlegung</a></li>
<li class="toc-entry toc-h3"><a href="#effektgr%C3%B6%C3%9Fensch%C3%A4tzer-hateta2">Effektgrößenschätzer $\hat{\eta}^2$</a></li>
<li class="toc-entry toc-h3"><a href="#effektgr%C3%B6%C3%9Fensch%C3%A4tzer-hatomega2">Effektgrößenschätzer $\hat{\omega}^2$</a></li>
<li class="toc-entry toc-h3">
<a href="#effektgr%C3%B6%C3%9Fe-phi2-signal-rausch-verh%C3%A4ltnis">Effektgröße $\phi^2$, Signal-Rausch-Verhältnis</a>
<ul>
<li class="toc-entry toc-h4"><a href="#konventionen-f%C3%BCr-phi2">Konventionen für $\phi^2$:</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#effektgr%C3%B6%C3%9Fe-phi">Effektgröße $\phi$</a></li>
<li class="toc-entry toc-h3"><a href="#effektgr%C3%B6%C3%9Fe-lambda">Effektgröße $\lambda$</a></li>
<li class="toc-entry toc-h3"><a href="#beziehungen-zwischen-effektgr%C3%B6%C3%9Fensch%C3%A4tzern">Beziehungen zwischen Effektgrößenschätzern</a></li>
<li class="toc-entry toc-h3"><a href="#konfidenzintervalle-der-effektgr%C3%B6%C3%9Fen">Konfidenzintervalle der Effektgrößen</a></li>
<li class="toc-entry toc-h3">
<a href="#sch%C3%A4tzung-der-populationsparameter">Schätzung der Populationsparameter</a>
<ul>
<li class="toc-entry toc-h4"><a href="#sch%C3%A4tzung-des-populationsmittelwertes">Schätzung des Populationsmittelwertes</a></li>
<li class="toc-entry toc-h4"><a href="#sch%C3%A4tzung-des-effektes-tau_j">Schätzung des Effektes $\tau_j$</a></li>
<li class="toc-entry toc-h4"><a href="#sch%C3%A4tzung-der-varianz-der-residuen-in-der-population">Schätzung der Varianz der Residuen in der Population</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#hypothesenpr%C3%BCfung-in-der-varianzanalyse">Hypothesenprüfung in der Varianzanalyse</a>
<ul>
<li class="toc-entry toc-h3">
<a href="#f-test">F-Test</a>
<ul>
<li class="toc-entry toc-h4"><a href="#beispiel-f%C3%BCr-f-test">Beispiel für F-Test</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#automatische-durchf%C3%BChrung-in-r">Automatische Durchführung in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#zweifaktorielle-varianzanalyze">Zweifaktorielle Varianzanalyze</a>
<ul>
<li class="toc-entry toc-h3"><a href="#nicht-partiielles-effektst%C3%A4rkenma%C3%9F-hateta2">Nicht-partiielles Effektstärkenmaß: $\hat{\eta}^2$</a></li>
<li class="toc-entry toc-h3"><a href="#partielles-effektgr%C3%B6%C3%9Fenma%C3%9F-hateta_p2">Partielles Effektgrößenmaß $\hat{\eta}_p^2$</a></li>
<li class="toc-entry toc-h3"><a href="#sch%C3%A4tzung-der-haupteffekte">Schätzung der Haupteffekte</a></li>
<li class="toc-entry toc-h3"><a href="#sch%C3%A4tzung-des-residuums">Schätzung des Residuums</a></li>
<li class="toc-entry toc-h3"><a href="#sch%C3%A4tzung-der-populationsresidualvarianz">Schätzung der Populationsresidualvarianz</a></li>
<li class="toc-entry toc-h3">
<a href="#hypothesenpr%C3%BCfung-bei-zweifaktorieller-varianzanalyse">Hypothesenprüfung bei zweifaktorieller Varianzanalyse</a>
<ul>
<li class="toc-entry toc-h4"><a href="#zerlegung-der-freiheitsgrade">Zerlegung der Freiheitsgrade</a></li>
<li class="toc-entry toc-h4"><a href="#hypothesenpaare">Hypothesenpaare</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#varianzanalyse-mit-messwiederholung">Varianzanalyse mit Messwiederholung</a></li>
<li class="toc-entry toc-h2"><a href="#populationsmodell-der-varianzanalyse">Populationsmodell der Varianzanalyse</a></li>
</ul>
</li>
<li class="toc-entry toc-h1">
<a href="#allgemeines-lineares-modell">Allgemeines Lineares Modell</a>
<ul>
<li class="toc-entry toc-h2">
<a href="#einfache-lineare-regression">Einfache lineare Regression</a>
<ul>
<li class="toc-entry toc-h3"><a href="#bestimmung-der-regressionskoeffizienten">Bestimmung der Regressionskoeffizienten</a></li>
<li class="toc-entry toc-h3"><a href="#standardfehler-der-modellparameter">Standardfehler der Modellparameter</a></li>
<li class="toc-entry toc-h3">
<a href="#alternative-wege-zur-bestimmung-der-regressionskoeffizienten">Alternative Wege zur Bestimmung der Regressionskoeffizienten</a>
<ul>
<li class="toc-entry toc-h4"><a href="#kriterium-der-kleinsten-quadrate">Kriterium der kleinsten Quadrate</a></li>
<li class="toc-entry toc-h4"><a href="#likelihood-maximierung">Likelihood-Maximierung</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#hypothesenpr%C3%BCfung-bei-einfacher-linearer-regression">Hypothesenprüfung bei einfacher linearer Regression</a></li>
<li class="toc-entry toc-h3"><a href="#konfidenzintervalle-f%C3%BCr-regressionskoeffizienten">Konfidenzintervalle für Regressionskoeffizienten</a></li>
<li class="toc-entry toc-h3"><a href="#einfache-lineare-regression-in-r">Einfache lineare Regression in R</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#multiple-lineare-regression">Multiple lineare Regression</a>
<ul>
<li class="toc-entry toc-h3"><a href="#modellgleichung">Modellgleichung</a></li>
<li class="toc-entry toc-h3"><a href="#bestimmung-der-regressionskoeffizienten-1">Bestimmung der Regressionskoeffizienten</a></li>
<li class="toc-entry toc-h3"><a href="#kompensatorisches-modell">Kompensatorisches Modell</a></li>
<li class="toc-entry toc-h3">
<a href="#dummy-kodierung">Dummy Kodierung</a>
<ul>
<li class="toc-entry toc-h4"><a href="#schritte-der-dummy-kodieruung">Schritte der Dummy-Kodieruung</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#interpretation-von-multiplen-regressionsgewichten">Interpretation von multiplen Regressionsgewichten</a>
<ul>
<li class="toc-entry toc-h4"><a href="#als-regressionsgewicht-einer-bedingten-einfacher-regression">Als Regressionsgewicht einer bedingten einfacher Regression.</a></li>
<li class="toc-entry toc-h4"><a href="#als-regressionsgewicht-zweier-regressionsredsiduen">Als Regressionsgewicht zweier Regressionsredsiduen</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#inkrementelle-varianzaufkl%C3%A4rung">Inkrementelle Varianzaufklärung</a></li>
<li class="toc-entry toc-h3">
<a href="#punktsch%C3%A4tzung-der-varianzaufkl%C3%A4rung">Punktschätzung der Varianzaufklärung</a>
<ul>
<li class="toc-entry toc-h4"><a href="#wherry-1-adjustierung">Wherry-1-Adjustierung</a></li>
<li class="toc-entry toc-h4"><a href="#adjustierung-nach-olkin--pratt-2017">Adjustierung nach Olkin &amp; Pratt (2017)</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#hypothesenpr%C3%BCfung-mit-multipler-linearer-regression">Hypothesenprüfung mit multipler linearer Regression</a>
<ul>
<li class="toc-entry toc-h4"><a href="#hypothesen-zum-gesamtmodell-globale-hypothesen">Hypothesen zum Gesamtmodell, globale Hypothesen</a></li>
<li class="toc-entry toc-h4"><a href="#hypothesen-%C3%BCber-einzelne-regressionsgewichte">Hypothesen über einzelne Regressionsgewichte</a></li>
<li class="toc-entry toc-h4"><a href="#hypothesen-%C3%BCber-modellvergleiche">Hypothesen über Modellvergleiche</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#modellvergleiche-in-r">Modellvergleiche in R</a>
<ul>
<li class="toc-entry toc-h4"><a href="#likelihood-quotienten-test">Likelihood-Quotienten-Test</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#interaktionseffekte-bei-mutlipler-linearer-regression">Interaktionseffekte bei mutlipler linearer Regression</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#annahmen-des-allgemeinen-linearen-modells">Annahmen des allgemeinen linearen Modells</a>
<ul>
<li class="toc-entry toc-h3">
<a href="#korrekte-spezifikation-linearit%C3%A4t">Korrekte Spezifikation, Linearität</a>
<ul>
<li class="toc-entry toc-h4"><a href="#pr%C3%BCfung-der-linearit%C3%A4t">Prüfung der Linearität</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#pr%C3%BCfung-der-homoskedastizit%C3%A4t">Prüfung der Homoskedastizität</a>
<ul>
<li class="toc-entry toc-h4"><a href="#breusch-pagan-test-in-r">Breusch-Pagan-Test in R</a></li>
<li class="toc-entry toc-h4"><a href="#visuelle-pr%C3%BCfung-der-heteroskedastizit%C3%A4t">Visuelle Prüfung der Heteroskedastizität</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#normalverteilung-der-residuen">Normalverteilung der Residuen</a>
<ul>
<li class="toc-entry toc-h4"><a href="#shapiro-wilk-test">Shapiro-Wilk-Test</a></li>
<li class="toc-entry toc-h4"><a href="#visuelle-pr%C3%BCfung-der-normalverteilung">Visuelle Prüfung der Normalverteilung</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- math equations in RMarkdown: https://rpruim.github.io/s341/S19/from-class/MathinRmd.html -->

<h1 id="stichprobenkennwerte-verteilung">
<a class="anchor" href="#stichprobenkennwerte-verteilung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stichprobenkennwerte-Verteilung</h1>

<h2 id="beispiel-mittelwert">
<a class="anchor" href="#beispiel-mittelwert" aria-hidden="true"><span class="octicon octicon-link"></span></a>Beispiel: Mittelwert</h2>

<p>$$\overline{x} = \frac{1}{k} \sum_{i=1}^{k}\overline{x}_i$$</p>

<ul>
  <li>$k$: Anzahl gezogener Stichproben</li>
  <li>$\overline{x}_{i}$: Mittelwerte innerhalb der Stichproben</li>
  <li>$\overline{x}$: durchschnittlicher Mittelwerte der Stichproben</li>
</ul>

<p>Erwartungswert des durchschnittlichen Mittelwertes der Stichproben ist der Mittelwert der Population:</p>

<p>$$E(\overline{x}) = \mu$$</p>

<h2 id="standardfehler-des-mittelwertes">
<a class="anchor" href="#standardfehler-des-mittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Standardfehler des Mittelwertes</h2>

<p>Die Standardabweichung der Stichprobenkennwert-Verteilung wird <em>Standardfehler</em> genannt, z.B. Standardfehler des Mittelwertes: $\sigma_{\overline{x}}$</p>

<h2 id="berechnung-des-standardfehlers-des-mittelwertes">
<a class="anchor" href="#berechnung-des-standardfehlers-des-mittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Berechnung des Standardfehlers des Mittelwertes</h2>

<ul>
  <li>wird anhand der Standardabweichung der Population $\sigma$ berechnet</li>
</ul>

<p>Bei $n &lt; 5\%$ der Populationsgröße N:</p>

<p>$$\sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}$$</p>

<p>Bei $n \ge 5\%$ der Populationsgröße N wird die “Finite Population”-Korrektur eingeführt:</p>

<p>$$\sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}} \cdot \color{red}{\sqrt{\frac{N-n}{N-1}}}$$</p>

<p>Je größer die einzelnen Stichprobengrößen, umso geringer wird der Standardfehler:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-1-1.png" alt="plot of chunk unnamed-chunk-1" width="576" style="display: block; margin: auto;"></p>

<h2 id="schätzung-des-standardfehlers-des-mittelwertes">
<a class="anchor" href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Schätzung des Standardfehlers des Mittelwertes</h2>

<p>Wenn die Varianz der Population $\sigma^2$ nicht bekannt ist, wird er geschätzte Standardfehler $\hat{\sigma}_{\overline{x}}$ aus der empirischen Varianz $s^{2*}$ bestimmt:</p>

<p>$$\hat{\sigma}_{\overline{x}} = \sqrt{\frac{\hat\sigma^2_x}{n}} = \sqrt{\frac{s^{2<em>}_x}{n - 1}}$$
Wichtig: die empirische Varianz $s^{2</em>}$ ist <strong>nicht</strong> gleich der Stichprobenvarianz $s^2$, siehe <a href="#punktsch%C3%A4tzung-der-varianz">Punktschätzung der Varianz</a>. Die Stichprobenvarianz $s^2$ enthält bereits die Bessel-Korrektur $n-1$ und muss entsprechend nicht nochmals in der Berechnung des geschätzten Standardfehlers korrigiert werden:</p>

<p>$$\hat{\sigma}_{\overline{x}} = \sqrt{\frac{s^2_x}{n}}$$</p>

<p>Die Stichprobenkennwerte-Verteilung folgt dann <strong>nicht mehr</strong> der Normalverteilung sondern nach Standardisierung einer Student-t-Verteilung mit $n - 1$ Freiheitsgraden:</p>

<p>$$\frac{\overline{x} - \mu}{\hat{\sigma}_{\overline{x}}} \sim Student(df = n -1)$$</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-2-1.png" alt="plot of chunk unnamed-chunk-2" width="576" style="display: block; margin: auto;"></p>

<ul>
  <li>$Normal(\mu = 0, \sigma = 1)$ (blaue Kurve): Verteilung in der Population</li>
  <li>$Student(df = n-1)$ (grüne Kurve): geschätzte Populationsverteilung</li>
</ul>

<p>Mit steigendem $n$ nähern sich die beiden Verteilungen immer weiter an.</p>

<h2 id="zentraler-grenzwertsatz">
<a class="anchor" href="#zentraler-grenzwertsatz" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zentraler Grenzwertsatz</h2>

<p>Die Stichprobenkennwerteverteilung der Mittelwerte nähert sich mit zunehmender Stichprobengröße der Normalverteilung an, unabhängig davon, wie das Merkmal in der Population verteilt ist.</p>

<p>1 Sample ($n = 1000$) mit uniformer Verteilung:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-3-1.png" alt="plot of chunk unnamed-chunk-3" width="576" style="display: block; margin: auto;"></p>

<p>Mittelwerteverteilung von $k = 500$ Samples mit je $n = 1000$:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-4-1.png" alt="plot of chunk unnamed-chunk-4" width="576" style="display: block; margin: auto;"></p>

<p>Verteilung nähert sich sichtbar der Normalverteilung an.</p>

<h1 id="punktschätzung-von-populationsparametern">
<a class="anchor" href="#punktsch%C3%A4tzung-von-populationsparametern" aria-hidden="true"><span class="octicon octicon-link"></span></a>Punktschätzung von Populationsparametern</h1>

<p>Populationsparameter sind meist unbekannt, daher werden sie auf Basis der Statistiken (Verteilungskennwerte) einer einzelnen Stichprobe geschätzt. (“Punktschätzung”, weil ein Punktwert und kein Intervall geschätzt wird)</p>

<p><strong>Populationsparameter</strong>: Kennwert einer theoretisch unendlich großen Population</p>

<p><strong>Stichprobenstatistik</strong>: Kennwert einer Verteilung tatsächlicher, empirischer Stichproben</p>

<p><strong>Schätzer</strong>: Inferenz von der Stichprobe auf die Population</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th style="text-align: right">Population</th>
      <th style="text-align: right">Stichprobenstatistik</th>
      <th style="text-align: right">Schätzer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Arithmetisches Mittel</td>
      <td style="text-align: right">$\mu$</td>
      <td style="text-align: right">$\overline{x}$</td>
      <td style="text-align: right">$\hat{\mu}$</td>
    </tr>
    <tr>
      <td>Standardabweichung (SD)</td>
      <td style="text-align: right">$\sigma$</td>
      <td style="text-align: right">$s$</td>
      <td style="text-align: right">$\hat{\sigma}$</td>
    </tr>
    <tr>
      <td>Varianz</td>
      <td style="text-align: right">$\sigma^{2}$</td>
      <td style="text-align: right">$s^{2}$</td>
      <td style="text-align: right">$\hat{\sigma}^{2}$</td>
    </tr>
    <tr>
      <td>Korrelation</td>
      <td style="text-align: right">$\rho$</td>
      <td style="text-align: right">$r$</td>
      <td style="text-align: right">$\hat{\rho}$</td>
    </tr>
    <tr>
      <td>Regressionsgewicht</td>
      <td style="text-align: right">$\beta$</td>
      <td style="text-align: right">$b$</td>
      <td style="text-align: right">$\hat{\beta}$</td>
    </tr>
  </tbody>
</table>

<h2 id="gütekriterien-für-parameterschätzung">
<a class="anchor" href="#g%C3%BCtekriterien-f%C3%BCr-parametersch%C3%A4tzung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gütekriterien für Parameterschätzung</h2>

<ol>
  <li>
    <p><strong>Erwartungstreue</strong></p>

    <p>Erwartungswert des Stichprobenkennwertes entspricht dem Populationsparameter</p>
  </li>
  <li>
    <p><strong>Konsistenz</strong></p>

    <p>Stichprobenkennwert nähert sich mit wachsender Stichprobe dem Populationsparameter</p>
  </li>
  <li>
    <p><strong>Effizienz</strong></p>

    <p>Stichprobenkennwert hat den geringsten Standardfehler unter allen erwartungstreuen Schätzern für einen Populationsparameter</p>
  </li>
  <li>
    <p><strong>Suffizienz</strong></p>

    <p>Stichprobenkennwert basiert auf alles in den Daten enthaltenen Informationen</p>
  </li>
</ol>

<h2 id="punktschätzung-des-mittelwertes">
<a class="anchor" href="#punktsch%C3%A4tzung-des-mittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Punktschätzung des Mittelwertes</h2>

<p>$k = 100$ Stichproben einer uniform verteilten Merkmals $x$ mit jeweils $n = 100$ Messungen.</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-5-1.png" alt="plot of chunk unnamed-chunk-5" width="576" style="display: block; margin: auto;"></p>

<p>Der Mittelwert der Stichprobenverteilung $\hat{\mu}$ (rote Linie) nähert sich mit steigender Stichprobenzahl ($i$) dem Populationsmittelwert $\mu$ (blaue Linie) immer weiter an.</p>

<p>Der Mittelwert der Stichprobenverteilung $\hat{\mu}$ ist also ein erwartungstreuer und konsistenter Schätzer des Populationsmittelwertes $\mu$.</p>

<h2 id="punktschätzung-der-varianz">
<a class="anchor" href="#punktsch%C3%A4tzung-der-varianz" aria-hidden="true"><span class="octicon octicon-link"></span></a>Punktschätzung der Varianz</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: center">empirische Varianz</th>
      <th style="text-align: center">Stichprobenvarianz</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">$s^{2*} = \frac{1}{n} \sum_{i = 1}^{n}(x_i - \overline{x})^2$</td>
      <td style="text-align: center">$s^2 = \frac{1}{n - 1} \sum_{i = 1}^{n}(x_i - \overline{x})^2$</td>
    </tr>
  </tbody>
</table>

<p>$k = 100$ Stichproben mit je $n = 100$ Messungen eines normalverteilten Merkmals:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-6-1.png" alt="plot of chunk unnamed-chunk-6" width="576" style="display: block; margin: auto;"></p>

<p>Die empirische Varianz $s^{2*}$ (rote Linie) weicht stärker vom wahren Kennwert der Population $\sigma^{2}$ (blaue Linie) ab als die Stichproben-Varianz $s^2$ (grüne Linie).</p>

<p>Die empirische Varianz ist kein erwartungstreuer Schätzer der Populationsvarianz, die Stichproben-Varianz dagegen schon.</p>

<p><strong>Aber:</strong> $\sqrt{s^2}$ (Stichproben-Standardabweichung $s$) ist <strong>KEIN</strong> erwartungstreuer Schätzer der Populations-Standardabweichung $\sigma$!</p>

<h1 id="intervallschätzung-von-populationsparametern">
<a class="anchor" href="#intervallsch%C3%A4tzung-von-populationsparametern" aria-hidden="true"><span class="octicon octicon-link"></span></a>Intervallschätzung von Populationsparametern</h1>

<p><strong>Konfidenzintervall</strong>: Intervall um den geschätzten Parameter, in dem mit Wahrscheinlichkeit $1-\alpha$ der wahre Populationsparameter liegt.</p>

<h2 id="konfidenzintervall-des-mittelwertes">
<a class="anchor" href="#konfidenzintervall-des-mittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konfidenzintervall des Mittelwertes</h2>

<p>Nach dem <a href="#zentraler-grenzwertsatz">zentralem Grenzwertsatz</a> folgen die Mittelwerte der Stichproben $\overline{x}$ einer Normalverteilung mit den Parametern Populationsmittelwert $\mu$ und Standardfehler der Stichprobenmittelwerte $\sigma_{\overline{x}}$:</p>

<p>$$\overline{x} \sim Normal(\mu, \sigma_{\overline{x}})$$</p>

<p>Entsprechend folgen die z-standardisierten Mittelwerte der Stichproben der Standard-Normalverteilung:</p>

<p>$$\frac{\overline{x} - \mu}{\sigma_{\overline{x}}} \sim Normal(0,1)$$</p>

<p>Die Fläche $1 - \alpha = 0.95$ liegt im Intervall $z = [-1.96, 1.96]$ der Standard-Normalverteilung.</p>

<p>$1-\alpha$ wird auch Konfidenzkoeffizient genannt.</p>

<p>Beispiel: Stichprobe mit $n = 100$ Messungen eines normalverteilten Merkmals:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-7-1.png" alt="plot of chunk unnamed-chunk-7" width="576" style="display: block; margin: auto;"></p>

<p>Der Populationsparameter $\mu$ liegt im Intervall um den Stichprobenmittelwert $\overline{x}$ (grüne Linie), das 95% der Fläche der Kennwertverteilung (pink) abdeckt.</p>

<p>Da es ein zweiseitiges Konfidenzintervall ist, wird an beidem Seiten der Verteilung 2.5% abgeschnitten damit insgesamt $\alpha = 5\%$ gilt.</p>

<h3 id="konfidenzintervall-pro-stichprobe">
<a class="anchor" href="#konfidenzintervall-pro-stichprobe" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konfidenzintervall pro Stichprobe</h3>

<p>$k = 100$ Stichproben zu je $n = 1000$ normalverteilten Messungen, mit zweiseitigem Konfidenzintervall $\alpha = 0.05$:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-8-1.png" alt="plot of chunk unnamed-chunk-8" width="576" style="display: block; margin: auto;"></p>

<p>Prozentsatz der Mittelwerte die mit ihrem Konfidenzintervall <strong>nicht</strong> den Populationsmittelwert abdecken, entspricht in etwa dem Fehlerniveau $\alpha = 5\%$. 4 Stichproben von $k = 100$ decken nicht den Populationsmittelwert in ihrem Konfidenzintervall ab.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">filter</span><span class="p">(</span><span class="w">
    </span><span class="n">x.mean.lower</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">x.mean.upper</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">mu</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">summarize</span><span class="p">(</span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">k</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<h2 id="schätzung-des-konfidenzintervalls-des-mittelwertes">
<a class="anchor" href="#sch%C3%A4tzung-des-konfidenzintervalls-des-mittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Schätzung des Konfidenzintervalls des Mittelwertes</h2>

<p>Wenn die Standardabweichung $\sigma$ der Population nicht bekannt ist, der Standardfehler also nicht daraus abgeleitet werden kann, wird das Konfidenzintervall anhand des <a href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes">geschätzten Standardfehlers</a> berechnet.</p>

<p>$$\overline{x} \pm t(1- \frac{\alpha}{2}, n - 1) \cdot \hat\sigma_{\overline{x}}$$</p>

<p>Stichprobe von $n = 10$ Messungen eines normalverteilten Merkmals:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-10-1.png" alt="plot of chunk unnamed-chunk-10" width="576" style="display: block; margin: auto;"></p>

<p><em>Es ist gleichgültig ob das Konfidenzintervall um den Populationsmittelwert oder den Stichprobenmittelwert gelegt wird. Wichtig ist, dass beide Werte im Intervall liegen. Bei t-Verteilungen ist es einfacher, das Intervall um den 0-Punkt zu legen und alle Werte entsprechend zu standardisieren.</em></p>

<h2 id="konfidenzintervall-abgängig-von-stichprobengröße">
<a class="anchor" href="#konfidenzintervall-abg%C3%A4ngig-von-stichprobengr%C3%B6%C3%9Fe" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konfidenzintervall abgängig von Stichprobengröße</h2>

<p>Sowohl der Standardfehler $\sigma_{\overline{x}}$ als auch der geschätzte Standardfehler $\hat{\sigma}_{\overline{x}}$ hängen von der Stichprobengröße ab und werden kleiner, je größer die Stichprobe ist. Entsprechend verändert sich auch das Konfidenzintervall.</p>

<p>Zwei Stichproben mit $n_1 = 20$ (grau) und $n_2 = 40$ (pink) Messungen des gleichen normalverteilten Merkmals, sowie Populationsmittelwert (blau):</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-11-1.png" alt="plot of chunk unnamed-chunk-11" width="576" style="display: block; margin: auto;"></p>

<p>Die größere Stichprobe $n_2 = 40$ hat ein deutlich schmaleres Konfidenzintervall.</p>

<h1 id="statistische-hypothesenprüfung">
<a class="anchor" href="#statistische-hypothesenpr%C3%BCfung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Statistische Hypothesenprüfung</h1>

<h2 id="signifikanztests">
<a class="anchor" href="#signifikanztests" aria-hidden="true"><span class="octicon octicon-link"></span></a>Signifikanztests</h2>

<p><strong>Nullhypothese $H_0$:</strong> Annahme, dass kein Unterschied zwischen zwei Parametern besteht.</p>

<p><strong>p-Wert:</strong> Wahrscheinlichkeit, dass ein beobachteter Effekt trotz Annahme der $H_0$ zufällig auftritt.</p>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Bedingte Wahrscheinlichkeit $Pr(\overline{x}</td>
          <td>H_0)$, also eine Aussage über die Wahrscheinlichkeit des beobachteten Stichprobenmittelwertes $Pr(\overline{x})$ unter der Voraussetzung dass die Nullhypothese $H_0$ wahr ist, <strong>NICHT</strong> über die Wahrscheinlichkeit, dass die Nullhypothese $H_0$ an sich zutrifft.</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>“Signifikant”</strong> ist ein Effekt, wenn der <strong>p-Wert</strong> unter einem zuvor festgelegten Signifikanz-Niveau $\alpha$ liegt, oft 5%.</p>

<h3 id="einseitiger-signifikanztest">
<a class="anchor" href="#einseitiger-signifikanztest" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einseitiger Signifikanztest</h3>

<p>Population mit $\mu = 100$ und $\sigma = 55$, Stichprobe mit $n = 200$.</p>

<p>Liegt eine Stichprobe mit $\overline{x} = 107$ (blaue Linie) in den oberen 5% der Wahrscheinlichkeitsmasse? D.h. ist die Wahrscheinlichkeit für solch eine Stichprobe unter dem Signifikanz-Niveau?</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-12-1.png" alt="plot of chunk unnamed-chunk-12" width="576" style="display: block; margin: auto;"></p>

<p><strong>Die Parameter der Dichtefunktion sind hier Populationsmittelwert und Standardfehler $\sigma_{\overline{x}}$, errechnet aus der Standardabweichung $\sigma$ der Population und der Stichprobengröße $n$. (siehe <a href="#berechnung-des-standardfehlers-des-mittelwertes">Berechnung des Standardfehlers</a>)</strong></p>

<h3 id="zweiseitiger-signifikanztest">
<a class="anchor" href="#zweiseitiger-signifikanztest" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zweiseitiger Signifikanztest</h3>

<p>Population mit $\mu = 100$ und $\sigma = 55$, Stichprobe mit $n = 200$.</p>

<p>Beim zweiseitigen Signifikanztest wird das Signifikanz-Niveau auf beide Seiten aufgeteilt, da es die Wahrscheinlichkeit betrifft mit der eine Stichprobe in einem der beiden Extrembereiche liegt, egal in welchem.</p>

<p>Liegt eine Stichprobe mit $\overline{x} = 107$ (blaue Linie) außerhalb der zentralen 95% der Wahrscheinlichkeitsmasse?</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-13-1.png" alt="plot of chunk unnamed-chunk-13" width="576" style="display: block; margin: auto;"></p>

<h3 id="standardisierte-prüfgrößen">
<a class="anchor" href="#standardisierte-pr%C3%BCfgr%C3%B6%C3%9Fen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Standardisierte Prüfgrößen</h3>

<p>Oft werden Daten zur Hypothesenprüfung standardisiert:</p>

<p>$$z_{\overline{x}} = \frac{\overline{x} - \mu}{\sigma_{\overline{x}}}$$
Die Verteilung der Stichprobenkennwerte in der Population ist dann auf $\mu = 0$ zentriert und hat einen Standardfehler $\sigma_{\overline{x}} = 1.0$.</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-14-1.png" alt="plot of chunk unnamed-chunk-14" width="576" style="display: block; margin: auto;"></p>

<h3 id="signifikanztest-mit-empirischen-daten">
<a class="anchor" href="#signifikanztest-mit-empirischen-daten" aria-hidden="true"><span class="octicon octicon-link"></span></a>Signifikanztest mit empirischen Daten</h3>

<p><strong>One-Sample-T-Test:</strong> gibt für gegebene Samples und Populationsmittelwert den p-Wert aus. Verglichen wird eine Stichprobe (daher “one sample”) mit der Gesamtpopulation.</p>

<p>Da die Standardabweichung der Population nicht bekannt ist, wird der Standardfehler mittels der T-Verteilung geschätzt. (siehe <a href="#sch%C3%A4tzung-des-standardfehlers-des-mittelwertes">Schätzung des Standardfehlers</a>)</p>

<p>Samples:</p>

<p>Einseitiger One-Sample-T-Test:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mu</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">100</span><span class="w">
</span><span class="n">alpha</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.05</span><span class="w">

</span><span class="c1"># alternative = "greater" -  &gt; Einseitiger Test in positiver Richtung</span><span class="w">
</span><span class="c1"># alternative = "less"      -&gt; Einseitiger Test in negativer Richtung</span><span class="w">
</span><span class="c1"># alternative = "two.sided" -&gt; Zweiseitiger Test</span><span class="w">
</span><span class="n">t.test</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	One Sample t-test
## 
## data:  samples
## t = 1.204, df = 9, p-value = 0.1296
## alternative hypothesis: true mean is greater than 100
## 95 percent confidence interval:
##  88.01066      Inf
## sample estimates:
## mean of x 
##  122.9462
</code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-17-1.png" alt="plot of chunk unnamed-chunk-17" width="576" style="display: block; margin: auto;"></p>

<h2 id="hypothesentests">
<a class="anchor" href="#hypothesentests" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesentests</h2>

<p><strong>Nullhypothese $H_0$:</strong> Annahme, dass ein bestimmter bedeutsamer Effekt nicht existiert.</p>

<p><strong>Alternativhypothese $H_1$:</strong> Annahme, dass ein bestimmter bedeutsamer Effekt existiert</p>

<p><strong>Die Nullhypothese ist niemals wirklich wahr. Mit ausreichender Stichprobengröße lässt sich ein beliebig kleiner Effekt zeigen.</strong></p>

<p><strong>Irrtumswahrscheinlichkeit $\alpha$:</strong> Wahrscheinlichkeit, dass ein Test in einer Stichprobe einen bedeutsamen Effekt zufällig anzeigt, der eigentlich in der Population nicht existiert, also dass die Nullhypothese $H_0$ fälschlicherweise abgelehnt wird. ($\alpha$-Fehler, False-Positive)</p>

<p><strong>Irrtumswahrscheinlichkeit $\beta$:</strong> Wahrscheinlichkeit, dass ein Effekt, der in der Population vorhanden ist, zufällig in der getesteten Stichprobe nicht auftaucht, also dass die Nullhypothese $H_0$ fälschlicherweise angenommen wird. ($\beta$-Fehler, False-Negative)</p>

<p><strong>Teststärke/Power:</strong> $1 - \beta$, je höher die Power, umso unwahrscheinlicher werden $\beta$-Fehler</p>

<p><strong>parametrische vs. nicht-parametrische Tests:</strong> parametrische Tests setzen voraus, dass Merkmale in der Population normalverteilt sind (z.B. Gauss-Test, T-Test). Nicht-parametrische Tests machen diese Annahme nicht (Gegenstand im M.Sc.-Studium).</p>

<p>Ein Test kann zwar einen p-Wert unter $\alpha$-Niveau (0.05) liefern, aber trotzdem einen sehr großer $\beta$-Fehler haben:</p>

<ul>
  <li>grüne Linie: $\mu$</li>
  <li>blaue Linie: $\overline{x}$</li>
  <li>rosa Fläche: $\alpha$</li>
  <li>blaue Fläche: $\beta$</li>
  <li>gestrichelte Linie: kritischer Wert</li>
</ul>

<p><img src="statistik-2-abbildungen/unnamed-chunk-18-1.png" alt="plot of chunk unnamed-chunk-18" width="576" style="display: block; margin: auto;"></p>

<p>Mit niedrigerem $\alpha$-Niveau (0.01) wird der $\beta$-Fehler sogar noch größer.</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-19-1.png" alt="plot of chunk unnamed-chunk-19" width="576" style="display: block; margin: auto;"></p>

<p>Um den $\beta$-Fehler zu reduzieren, müsste ein stärkerer Effekt ($\overline{x} - \mu$) vorhanden sein:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-20-1.png" alt="plot of chunk unnamed-chunk-20" width="576" style="display: block; margin: auto;"></p>

<h3 id="standardisierter-effekt-cohens-delta">
<a class="anchor" href="#standardisierter-effekt-cohens-delta" aria-hidden="true"><span class="octicon octicon-link"></span></a>Standardisierter Effekt: Cohen’s $\delta$</h3>

<p><em>(Manchmal auch: “Cohen’s d”)</em></p>

<p>$$\delta = \frac{\overline{x} - \mu}{\sigma}$$</p>

<ul>
  <li>$\overline{x}$: Stichproben-Mittelwert</li>
  <li>$\mu$: Populationsmittelwert</li>
  <li>$\sigma$: Standardabweichung der Population</li>
</ul>

<p><img src="statistik-2-abbildungen/unnamed-chunk-21-1.png" alt="plot of chunk unnamed-chunk-21" width="576" style="display: block; margin: auto;"></p>

<h3 id="konfidenzintervalle-für-cohens-delta">
<a class="anchor" href="#konfidenzintervalle-f%C3%BCr-cohens-delta" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konfidenzintervalle für Cohen’s $\delta$</h3>

<p>Die Stichprobenkennwerte-Verteilung von $\overline{x}$ ist normalverteilt (siehe <a href="#zentraler-grenzwertsatz">Zentraler Grenzwertsatz</a>)</p>

<p>Der Erwartungswert von $\delta$ entspricht der standardisierten Differenz zwischen Stichprobenmittelwert und Populationsmittelwert.</p>

<p>$$E_{\delta} = \frac{\overline{x} - \mu}{\sigma}$$</p>

<p>Die Streuung $\sigma_{\delta}$ ist der Standardfehler wobei dieser hier vereinfacht $\frac{1}{\sqrt{n}}$ ist weil Standardisierung bereits erfolgt ist (die Standardabweichung von standardisierten Größen ist 1):</p>

<p>$$\sigma_{\delta} = \sigma_{\overline{x}} = \frac{1}{\sqrt{n}}$$</p>

<p>$$\delta \sim  Normal(E_{\delta} = \frac{\overline{x} - \mu}{\sigma}, \sigma_{\delta} = \frac{1}{\sqrt{n}})$$</p>

<p>Damit lassen sich die Konfidenzintervalle für ein gegebenes $\alpha$-Niveau berechnen:</p>

<p>$$\delta \pm z(1-\frac{\alpha}{2}) \cdot \sigma_{\delta} = \frac{\overline{x} - \mu}{\sigma} \pm  z(1-\frac{\alpha}{2}) \cdot \frac{1}{\sqrt{n}}$$</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-22-1.png" alt="plot of chunk unnamed-chunk-22" width="576" style="display: block; margin: auto;">
Konventionen für Effektinterpretationen für $\delta$ nach Cohen:</p>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>$</td>
          <td>d</td>
          <td>\approx 0.14$: “kleiner” Effekt</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>$</td>
          <td>d</td>
          <td>\approx 0.35$: “mittlerer” Effekt</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>$</td>
          <td>d</td>
          <td>\approx 0.57$: “großer” Effekt</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>TODO: ci.smd in R (MBESS)</strong></p>

<h3 id="einstichproben-gauss-test">
<a class="anchor" href="#einstichproben-gauss-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben-Gauss-Test</h3>

<p>Voraussetzungen:</p>

<ul>
  <li>Merkmal ist in der Population normalverteilt
    <ul>
      <li>
        <p>alternativ: bei nicht-normalverteiltem Merkmal $x$ ist der Stichproben Mittelwert ab ca. $n = 30$ nahezu normalverteilt. (Siehe <a href="#zentraler-grenzwertsatz">zentraler Grenzwertsatz</a>)</p>

        <p>Der z-Test ist dann allerdings nicht mehr exakt.</p>
      </li>
    </ul>
  </li>
  <li>Standardabweichung $\sigma$ in der Population ist bekannt</li>
</ul>

<p>Gauss-Test, auch “z-Test” genannt, ist geeignet, wenn die Standardabweichung $\sigma$ der Population bekannt ist, und damit der Standardfehler $\sigma_{\overline{x}}$ berechnet werden kann. (Siehe <a href="#berechnung-des-standardfehlers-des-mittelwertes">Berechnung des Standardfehlers des Mittelwertes</a>)</p>

<p>Prüfgröße: $z_{\overline{x} - \mu}$, z-standardisierte Differenz von Stichprobenmittelwert und Populationsmittelwert</p>

<p>$$z_{\overline{x} - \mu} = \frac{\overline{x} - \mu}{\sigma_{\overline{x}}}$$</p>

<p>Kritischer Wert: Wert für $\overline{x}$ der über- bzw. unterschritten werden muss damit $p \le 0.05$ eingehalten wird.</p>

<p>$Q(p)$ ist hier die Quantilsfunktion der Normalverteilung, die bestimmt welcher Wert eine Wahrscheinlichkeit von $p$ oder weniger hat.</p>

<p>Die Nullhypothese $H_0$ wird abgelehnt wenn:</p>

<ul>
  <li>
    <p>bei einseitigem Test in positiver Richtung</p>

    <p>$z_{\overline{x} - \mu} \ge Q(1 - \alpha)$</p>
  </li>
  <li>
    <p>bei einseitigem Test in negativer Richtung</p>

    <p>$z_{\overline{x} - \mu} \le Q(\alpha)$</p>
  </li>
  <li>
    <p>bei zweiseitigem Test</p>

    <p>$z_{\overline{x} - \mu} \le Q(\frac{\alpha}{2}) \cup z_{\overline{x} - \mu} \ge Q(1 - \frac{\alpha}{2})$</p>

    <p>($\cup$: “oder”)</p>
  </li>
</ul>

<p>Siehe auch: <a href="#signifikanztests">Signifikanztests</a></p>

<h4 id="einstichproben-gauss-test-in-r">
<a class="anchor" href="#einstichproben-gauss-test-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben-Gauss-Test in R</h4>

<p>Samples mit $\mu = 0.5$, $\sigma = 1.0$, und $n = 20$</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##  [1]  1.76295428  0.17376664  1.82979926  1.77242932  0.91464143 -1.03995004 -0.42856703  0.20527955  0.49423283  2.90465339  1.26359346 -0.29900925 -0.64765701  0.21053843
## [15]  0.20078488  0.08848917  0.75222345 -0.39192113  0.93568330 -0.73753842
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">BSDA</span><span class="p">)</span><span class="w">

</span><span class="n">z.test</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sigma.x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	One-sample z-Test
## 
## data:  samples
## z = 2.2281, p-value = 0.01294
## alternative hypothesis: true mean is greater than 0
## 95 percent confidence interval:
##  0.1304209        NA
## sample estimates:
## mean of x 
## 0.4982213
</code></pre></div></div>

<h3 id="einstichproben-t-test">
<a class="anchor" href="#einstichproben-t-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben T-Test</h3>

<p>Voraussetzungen:</p>

<ul>
  <li>Merkmal ist in der Population normalverteilt
    <ul>
      <li>alternativ: bei nicht-normalverteiltem Merkmal $x$ ist der Stichproben Mittelwert ab ca. $n = 30$ nahezu normalverteilt. (Siehe <a href="#zentraler-grenzwertsatz">zentraler Grenzwertsatz</a>)</li>
    </ul>
  </li>
  <li>Stichprobengröße ist bekannt (zur Schätzung des Standardfehlers)</li>
</ul>

<p><em>Der T-Test ist wenn möglich dem Gauss-Test vorzuziehen, da er auch ohne bekannte Standardabweichung der Population exakter ist.</em></p>

<p>Schätzung des Standardfehlers $\hat{\sigma}_{\overline{x}}$</p>

<ul>
  <li>$\hat{\sigma}^2_{x}$: geschätzte Populations-Varianz</li>
  <li>$s^2_{x}$: Stichproben-Varianz</li>
  <li>$s^{2*}$: empirische Varianz</li>
</ul>

<p>$$\hat{\sigma}<em>{\overline{x}} = \sqrt{\frac{\hat{\sigma}^2</em>{x}}{n}} = \sqrt{\frac{s^2<em>{x}}{n}} = \sqrt{\frac{s^{2*}</em>{x}}{n-1}}$$</p>

<p>Prüfgröße: $t_{\overline{x} - \mu}$</p>

<p>$$t_{\overline{x} - \mu} = \frac{\overline{x} - \mu}{\hat{\sigma}_{\overline{x}}}$$</p>

<p>Kritischer Wert: Analog zum <a href="#einstichproben-gauss-test">Einstichproben Gauss-Test</a></p>

<p>$Q(p)$ ist beim t-Test die Quantilsfunktion der Student-T-Verteilung mit $n-1$ Freiheitsgraden, denn die Verteilung von $t_{\overline{x} - \mu}$ folgt dieser Student-T-Verteilung:</p>

<p>$$t_{\overline{x} - \mu} \sim Student(df = n -1 )$$</p>

<p>Beispiel: Zwei T-Tests mit entsprechenden Student-T-Verteilungen für $n=10$ und $n=100$.</p>

<p>Die Prüfgröße fällt bei $n=10$ nicht über den kritischen Wert für $p \le \alpha$, bei $n=100$ aber schon, da der geschätzte Standardfehler geringer wird, d.h. der Test wird genauer.</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-26-1.png" alt="plot of chunk unnamed-chunk-26" width="576" style="display: block; margin: auto;"></p>

<h4 id="einstichproben-t-test-in-r">
<a class="anchor" href="#einstichproben-t-test-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben T-Test in R</h4>

<p>Samples mit $\mu = 0.5$, $\sigma = 1.0$, und $n = 20$</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##  [1] 0.8525909 0.5347533 0.8659599 0.8544859 0.6829283 0.2920100 0.4142866 0.5410559 0.5988466 1.0809307 0.7527187 0.4401982 0.3704686 0.5421077 0.5401570 0.5176978 0.6504447
## [18] 0.4216158 0.6871367 0.3524923
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t.test</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	One Sample t-test
## 
## data:  samples
## t = 2.1812, df = 19, p-value = 0.02097
## alternative hypothesis: true mean is greater than 0.5
## 95 percent confidence interval:
##  0.5206532       Inf
## sample estimates:
## mean of x 
## 0.5996443
</code></pre></div></div>

<h3 id="einstichproben-t-test-für-abhängige-beobachtungen">
<a class="anchor" href="#einstichproben-t-test-f%C3%BCr-abh%C3%A4ngige-beobachtungen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben T-Test für abhängige Beobachtungen</h3>

<p>T-Test für abhängige Messungen in einer Stichprobe. z.B. wenn die gleiche Stichprobe von Versuchspersonen vor und nach einem Treatment die gleiche Messung durchläuft.</p>

<p>Stichprobengröße ist hier die Anzahl der Messwertpaare, nicht die Anzahl aller Messungen.</p>

<p>Es wird eine neue Variable $\overline{x}_D$ eingeführt, der Mittelwert der Differenz der beiden Messungen von jeweils der gleichen Versuchsperson.</p>

<ul>
  <li>$H_0$: $\overline{x}_D = 0$</li>
  <li>$H_1$: $\overline{x}_D \neq 0$ (zweiseitiger Test)</li>
</ul>

<p><em>Es ist egal ob zuerst die Differenzen der Messungen für jede Versuchsperson gebildet und dann gemittelt werden, oder ob die Differenz der Mittelwerte beider Messungen gebildet wird. Das Ergebnis ist das gleiche</em></p>

<p>Der Rest der Tests verläuft wie beim Einstichproben T-Test.</p>

<h4 id="einstichproben-t-test-für-abhängige-beobachtungen-t-test-in-r">
<a class="anchor" href="#einstichproben-t-test-f%C3%BCr-abh%C3%A4ngige-beobachtungen-t-test-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben T-Test für abhängige Beobachtungen T-Test in R</h4>

<p>$n=20$ Samples,</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">samples</span><span class="o">$</span><span class="n">m2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">samples</span><span class="o">$</span><span class="n">m1</span><span class="w">
</span><span class="n">t.test</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"two.sided"</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	One Sample t-test
## 
## data:  xd
## t = -2.853, df = 9, p-value = 0.019
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -2.1962337 -0.2536916
## sample estimates:
## mean of x 
## -1.224963
</code></pre></div></div>

<p>Alternativ kann die Funktion <code class="language-plaintext highlighter-rouge">t.test</code> auch die paarweisen Differenzen automatisch bestimmen:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t.test</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">samples</span><span class="o">$</span><span class="n">m2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">samples</span><span class="o">$</span><span class="n">m1</span><span class="p">,</span><span class="w">
       </span><span class="n">paired</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w">
       </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w">
       </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"two.sided"</span><span class="p">,</span><span class="w">
       </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Paired t-test
## 
## data:  samples$m2 and samples$m1
## t = -2.853, df = 9, p-value = 0.019
## alternative hypothesis: true mean difference is not equal to 0
## 95 percent confidence interval:
##  -2.1962337 -0.2536916
## sample estimates:
## mean difference 
##       -1.224963
</code></pre></div></div>

<h3 id="einstichproben-binomialtest">
<a class="anchor" href="#einstichproben-binomialtest" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einstichproben Binomialtest</h3>

<p>Test für ein dichotomes Merkmal $x$ (Merkmal mit zwei möglichen Ausprägungen): $x \in {0,1}$</p>

<p>$\pi_0$: Wahrscheinlichkeit in der Population für $x = 1$</p>

<p>$\pi$: Wahrscheinlichkeit in der Stichprobe für $x = 1$</p>

<p>Hypothesenpaare:</p>

<ul>
  <li>ungerichtet
    <ul>
      <li>$H_0$: $\pi_0 = \pi$</li>
      <li>$H_1$: $\pi_0 \ne \pi$</li>
    </ul>
  </li>
  <li>gerichtet, positiv
    <ul>
      <li>$H_0$: $\pi_0 \ge \pi$</li>
      <li>$H_1$: $\pi_0 \lt \pi$</li>
    </ul>
  </li>
  <li>gerichtet, negativ
    <ul>
      <li>$H_0$: $\pi_0 \le \pi$</li>
      <li>$H_1$: $\pi_0 \gt \pi$</li>
    </ul>
  </li>
</ul>

<p>Aus $\pi_0$ und $\pi$ ergeben sich zwei Binomialverteilungen über $n$ Ziehungen, mit $\alpha$-Fehler analog zu anderen Tests.</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-34-1.png" alt="plot of chunk unnamed-chunk-34" width="576" style="display: block; margin: auto;"></p>

<h4 id="binomialtest-in-r">
<a class="anchor" href="#binomialtest-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Binomialtest in R</h4>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">binom.test</span><span class="p">(</span><span class="m">39</span><span class="p">,</span><span class="w"> </span><span class="m">60</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Exact binomial test
## 
## data:  39 and 60
## number of successes = 39, number of trials = 60, p-value = 0.01367
## alternative hypothesis: true probability of success is greater than 0.5
## 95 percent confidence interval:
##  0.5363726 1.0000000
## sample estimates:
## probability of success 
##                   0.65
</code></pre></div></div>

<h3 id="zweistichproben-t-test">
<a class="anchor" href="#zweistichproben-t-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zweistichproben T-Test</h3>

<p>Wird angewendet beim Vergleich von 2 unabhängigen Stichproben (z.B. Studienarme).</p>

<p>Voraussetzungen:</p>

<ul>
  <li>normalverteiltes Merkmal</li>
  <li>Messwerte in beiden Stichproben unabhängig</li>
  <li>Varianzhomogenität zwischen den Stichproben</li>
</ul>

<p>Prüfgröße:</p>

<p>$$T = t_{\overline{x}<em>1} - t</em>{\overline{x}<em>2} = \frac{\overline{x}_1 - \overline{x}_2} {\hat{\sigma}</em>{\overline{x}_1 - \overline{x}_2}}$$</p>

<p>$T$ folgt der Student-T-Verteilung mit $df = n_1 + n_2 - 2$$ Freiheitsgraden</p>

<p>$$T \sim Student(0, 1, n_1 + n_2 - 2)$$</p>

<p>Standardfehler hängt hier von den Größen beider Stichproben ab, da diese nicht unbedingt gleich groß sind.</p>

<p>$$\hat{\sigma}<em>{\overline{x}_1 - \overline{x}_2} = \sqrt{\frac{\hat{\sigma}^2</em>{inn}} {n_1} + \frac{\hat{\sigma}^2_{inn}}{n_2}}$$</p>

<p>Geteilte/Gepoolte Innerhalb-Varianz $\hat{\sigma}^2_{inn}$ wird aus den geschätzten Varianzen der Stichproben ($\hat{\sigma}^2_1$, $\hat{\sigma}^2_2$) berechnet (siehe auch <a href="#punktsch%C3%A4tzung-der-varianz">Punktschätzung der Varianz</a>):</p>

<p>$$\hat{\sigma}^2_{inn} = \frac{\hat{\sigma}^2_1 \cdot (n_1 -1) + \hat{\sigma}^2_2 \cdot (n_2 -1)} {(n_1 - 1) + (n_2 - 1)}$$</p>

<p>Beispiel: Stichproben aus zwei Studienarmen mit jeweils $n = 100$</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-36-1.png" alt="plot of chunk unnamed-chunk-36" width="576" style="display: block; margin: auto;"></p>

<p>Verteilung der Prüfgröße $T$:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-37-1.png" alt="plot of chunk unnamed-chunk-37" width="576" style="display: block; margin: auto;"></p>

<h4 id="zweistichproben-t-test-in-r">
<a class="anchor" href="#zweistichproben-t-test-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zweistichproben T-Test in R</h4>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t.test</span><span class="p">(</span><span class="n">samples2</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">samples1</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Welch Two Sample t-test
## 
## data:  samples2$x and samples1$x
## t = 2.5715, df = 193.31, p-value = 0.005438
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  6.070815      Inf
## sample estimates:
## mean of x mean of y 
##  118.1253  101.1334
</code></pre></div></div>

<h2 id="power-und-stichprobenplanung">
<a class="anchor" href="#power-und-stichprobenplanung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Power und Stichprobenplanung</h2>

<p><strong>Power: $1-\beta$</strong></p>

<p>$\beta$ und Power hängen vom Standardfehler und damit von der Stichprobengröße ab.</p>

<p>Beispiel $n = 20$, $\beta$-Fehler ist gering:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-39-1.png" alt="plot of chunk unnamed-chunk-39" width="576" style="display: block; margin: auto;"></p>

<p>Bei $n = 7$ ist der $\beta$-Fehler deutlich höher und die Power daher geringer, während $\alpha$-Niveau weiterhin unterschritten wird:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-40-1.png" alt="plot of chunk unnamed-chunk-40" width="576" style="display: block; margin: auto;"></p>

<p>$\beta$ ist ebenfalls vom Effekt abhängig. Zur Planung der Stichprobengröße müssen $\alpha$-Niveau und der minimale als signifikant akzeptierte Effekt bekannt sein.</p>

<h3 id="stichprobenplanung-in-r">
<a class="anchor" href="#stichprobenplanung-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stichprobenplanung in R</h3>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">pwr</span><span class="p">)</span><span class="w">

</span><span class="c1"># post-hoc Power-Analyse für einseitigen Gauss-Test/Z-Test</span><span class="w">
</span><span class="c1"># - Stichproben-Signifikanztest</span><span class="w">
</span><span class="c1"># - Normalverteilte Merkmale</span><span class="w">
</span><span class="c1"># - bekannter Standardabweichung</span><span class="w">
</span><span class="n">pwr.norm.test</span><span class="p">(</span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">sig.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
##      Mean power calculation for normal distribution with known variance 
## 
##               d = 0.5
##               n = 10
##       sig.level = 0.05
##           power = 0.4745987
##     alternative = greater
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># bei Test in negativer Richtung: alternative = "lesser"</span><span class="w">
</span><span class="c1"># bei zweiseitigem Test: alternative = "two.sided"</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># a priori Power Analyse für Zweistichproben-T-Test</span><span class="w">
</span><span class="c1"># n ist noch nicht bekannt, aber alpha-Niveau, Effekt und Power sind gegeben</span><span class="w">
</span><span class="n">pwr.t.test</span><span class="p">(</span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">sig.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">power</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.9</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"two.sample"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
##      Two-sample t test power calculation 
## 
##               n = 85.03128
##               d = 0.5
##       sig.level = 0.05
##           power = 0.9
##     alternative = two.sided
## 
## NOTE: n is number in *each* group
</code></pre></div></div>

<p>Plot von Power in Abhängigkeit von Stichprobengröße:</p>

<p>Effekt $d = 0.7$, $\alpha_1 = 5\%$ (blau), $\alpha_2 = 1\%$ (pink)</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Funktion die einen einseitigen Z-Test ausführt</span><span class="w">
</span><span class="c1"># und den Power-Wert aus dem Ergebnis extrahiert</span><span class="w">
</span><span class="n">power</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">pwr.norm.test</span><span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">sig.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">alpha</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">)</span><span class="w">
  
  </span><span class="nf">return</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="m">4</span><span class="p">]])</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># Plot der Funktion über Stichprobengrößen 1-75</span><span class="w">
</span><span class="c1"># Effekt d = 0.7</span><span class="w">
</span><span class="c1"># alpha = 0.05 und alpha = 0.01</span><span class="w">
</span><span class="n">tibble</span><span class="p">(</span><span class="w">
  </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">50</span><span class="p">,</span><span class="w">
  </span><span class="n">power5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">power</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.7</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">),</span><span class="w">
  </span><span class="n">power1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">power</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.7</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.01</span><span class="p">),</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">power</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_col</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">power5</span><span class="p">),</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"skyblue3"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_col</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">power1</span><span class="p">),</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"hotpink3"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">annotate</span><span class="p">(</span><span class="s2">"text"</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"alpha[1] == 0.05"</span><span class="p">,</span><span class="w"> </span><span class="n">parse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"skyblue3"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">annotate</span><span class="p">(</span><span class="s2">"text"</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"alpha[2] == 0.01"</span><span class="p">,</span><span class="w"> </span><span class="n">parse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.90</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"hotpink3"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">xlab</span><span class="p">(</span><span class="s2">"Stichprobengröße"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">ylab</span><span class="p">(</span><span class="s2">"Power"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme_custom</span><span class="w">
</span></code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-43-1.png" alt="plot of chunk unnamed-chunk-43" width="576" style="display: block; margin: auto;"></p>

<p>Für ein strengeres $\alpha_2 = 1\%$ ist gegenüber $\alpha_1 = 5\%$ eine größere Stichrobe nötig, um die gleiche Power zu erreichen.</p>

<h2 id="tests-für-kategoriale-merkmale">
<a class="anchor" href="#tests-f%C3%BCr-kategoriale-merkmale" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tests für Kategoriale Merkmale</h2>

<p>Kategoriale Merkmale:</p>

<ul>
  <li>nominalskalierte Merkmale</li>
  <li>ordinalskalierte Merkmale
    <ul>
      <li>auch geschichtete metrische Merkmale</li>
    </ul>
  </li>
</ul>

<h3 id="chi2-statistik">
<a class="anchor" href="#chi2-statistik" aria-hidden="true"><span class="octicon octicon-link"></span></a>$\chi^2$-Statistik</h3>

<p>$$\chi^2 = \sum_{i=1}^r{\sum_{j=1}^c{\frac{(f_{ij} - e_{ij})^2}{e_{ij}}}}$$</p>

<ul>
  <li>$r$: Anzahl Zeilen</li>
  <li>$c$: Anzahl Spalten</li>
  <li>$f_{ij}$: beobachtete Häufigkeiten</li>
  <li>
    <p>$e_{ij}$: erwartete Häufigkeiten</p>

    <p>$e_{ij} = \frac{Zeilensumme \cdot Spaltensumme}{Stichprobenumfang}$</p>
  </li>
</ul>

<h3 id="cramers-v">
<a class="anchor" href="#cramers-v" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cramer’s $V$</h3>

<p>$$V = \sqrt{\frac{\chi^2}{n \cdot (m - 1)}}$$</p>

<ul>
  <li>$n$: Stichprobenumfang</li>
  <li>
    <p>$m$: Merkmalsausprägungen</p>

    <p>$m = min(r, c)$</p>
  </li>
</ul>

<h3 id="chi2-test">
<a class="anchor" href="#chi2-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>$\chi^2$-Test</h3>

<ul>
  <li>$V$: Effektstärke</li>
  <li>$\chi^2$: Prüfgröße</li>
</ul>

<p>Nullhypothese $H_0$: $V = 0$, es existiert kein Effekt</p>

<p>Die Prüfgröße folgt einer $\chi^2$-Verteilung mit Freiheitsgraden $df = (r-1) \cdot (c-1)$.</p>

<h4 id="chi2-test-in-r">
<a class="anchor" href="#chi2-test-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>$\chi^2$-Test in R</h4>

<p>Beispieldaten:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##      A   B   C
## I  125 108 125
## II 127  93 230
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chisq.test</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Pearson's Chi-squared test
## 
## data:  samples
## X-squared = 22.002, df = 2, p-value = 1.669e-05
</code></pre></div></div>

<h4 id="kontinuitätskorrektur">
<a class="anchor" href="#kontinuit%C3%A4tskorrektur" aria-hidden="true"><span class="octicon octicon-link"></span></a>Kontinuitätskorrektur</h4>

<p>Zellen mit $f_{ij} \lt 5$ gelten als “unterbesetzt”. Der $\chi^2$-Test reagiert dann progressiv, das $\alpha$-Fehlerniveau wird unterschritten und die Wahrscheinlichkeit, die $H_1$ anzunehmen steigt.</p>

<p>Die Prüfgröße muss in diesem Fall adjustiert werden:</p>

<table>
  <tbody>
    <tr>
      <td>$$\chi^2<em>{adj} = \sum</em>{i=1}^r{\sum_{j=1}^c{\frac{(</td>
      <td>f_{ij} - e_{ij}</td>
      <td>
<ul>
  <li>0.5)^2}{e_{ij}}}}$$</li>
</ul>
</td>
    </tr>
  </tbody>
</table>

<p>In R erfolgt die Korrektur automatisch, kann aber auch mit der <code class="language-plaintext highlighter-rouge">correct</code>-Option explizit aktiviert oder deaktiviert werden:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##     A  B
## I  10  8
## II  4 16
</code></pre></div></div>

<p>Ohne Korrektur wird $\alpha = 0.05$ unterschritten:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chisq.test</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span><span class="w"> </span><span class="n">correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Pearson's Chi-squared test
## 
## data:  samples
## X-squared = 5.1471, df = 1, p-value = 0.02329
</code></pre></div></div>

<p>Mit Korrektur wird $\alpha = 0.05$ nicht unterschritten:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chisq.test</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span><span class="w"> </span><span class="n">correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Pearson's Chi-squared test with Yates' continuity correction
## 
## data:  samples
## X-squared = 3.7325, df = 1, p-value = 0.05336
</code></pre></div></div>

<h1 id="multiplizität">
<a class="anchor" href="#multiplizit%C3%A4t" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multiplizität</h1>

<p>Wenn mit erhobenen Daten mehrere Tests durchgeführt werden, gilt für jeden Test (“Endpunkt”) ein eigenes $\alpha$-Fehlerniveau (“Per-Comparison Error Rate”, PCER).</p>

<p>$$\alpha_1 = \alpha_2 = \ldots = \alpha_k = 0.05$$</p>

<p>Insgesamt bilden diese dann die “Family-Wise Error Rate” (FWER), die deutlich höher ausfallen kann, da die Wahrscheinlichkeiten $1-\alpha_i$, also dafür, sich korrekterweise für $H_0$ zu entscheiden, entsprechend der Kettenregel multipliziert werden.</p>

<p>$$(1-\alpha_1) \cdot (1-\alpha_2) \cdot \ldots \cdot (1-\alpha_k) = (1-\alpha_i)^k$$</p>

<p>Bei $\alpha = 0.05$ und 5 Endpunkten:</p>

<p>$$(1 - 0.05)^5 = 0.95^5 \approx 0.774$$
$$1-0.774 = 0.226 = \alpha_{FWER}$$</p>

<p>Bei 14 Endpunkten und $\alpha = 0.05$ wird eine FWER von 50% überschritten:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-49-1.png" alt="plot of chunk unnamed-chunk-49" width="576" style="display: block; margin: auto;"></p>

<h2 id="bonferroni-korrektur">
<a class="anchor" href="#bonferroni-korrektur" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bonferroni-Korrektur</h2>

<ul>
  <li>bestimmt $\alpha_i$, so dass $\alpha_{FWER} \le 0.05$ wird.</li>
</ul>

<p>Für $k$ unabhängige Endpunkte:</p>

<p>$$\alpha_i = \frac{\alpha_{FWER}}{k}$$
<strong>Beispiel: $\alpha_{FWER} = 0.05$ und $k = 3$</strong></p>

<p>$$\alpha_i = \frac{0.05}{3} \approx 0.0167 $$</p>

<p>$$1 - (1- 0.0167)^3 \approx 0.049 \le 0.05$$</p>

<p><strong>Beispiel: Zwei Endpunkte in Form von zwei gerichteten Alternativhypothesen $H_{1,1}$ und $H_{1,2}$ gegenüber Nullhypothese $H_{0,1}$</strong></p>

<p><em>(analog zu einer ungerichteten $H_1$, wo $\alpha$ ebenfalls auf beide Seiten aufgeteilt wird. Siehe <a href="#zweiseitiger-signifikanztest">Zweiseitiger Signifikanztest</a>)</em></p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-50-1.png" alt="plot of chunk unnamed-chunk-50" width="576" style="display: block; margin: auto;"></p>

<p>$\overline{x}_1$ liegt über dem kritischen Wert für $\alpha_i = 0.025$ in positiver Richtung während $\overline{x}_2$ nicht unterhalb des kritischen Wertes in negativer Richtung liegt.</p>

<p>$H_{1,1}$ kann also akzeptiert werden, $H_{1,2}$ jedoch nicht.</p>

<h2 id="holm-bonferroni-korrektur">
<a class="anchor" href="#holm-bonferroni-korrektur" aria-hidden="true"><span class="octicon octicon-link"></span></a>Holm-Bonferroni-Korrektur</h2>

<p>$k$ Unabhängige Endpunkte werden aufsteigend nach p-Wert sortiert.</p>

<p>$$\alpha_i = \frac{\alpha_{FWER}}{k - (i - 1)}$$</p>

<p>$$\alpha_1 = \frac{\alpha_{FWER}}{k}, \alpha_2 = \frac{\alpha_{FWER}}{k - 1}, \alpha_3 = \frac{\alpha_{FWER}}{k - 2}, \dots, \alpha_k = \frac{\alpha_{FWER}}{1}$$</p>

<h2 id="fallback-prozedur">
<a class="anchor" href="#fallback-prozedur" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fallback-Prozedur</h2>

<ol>
  <li>$k$ unabhängige Endpunkte werde <em>a priori</em> nach Wichtigkeit sortiert.</li>
  <li>$\alpha$ Fehler (z.B.) 5% wird frei auf Endpunkte verteilt.</li>
  <li>Endpunkte werden der Reihe nach getestet
    <ul>
      <li>$p_i &gt; \alpha_i \rightarrow \alpha_i = 0$, nicht signifikant</li>
      <li>$p_i \le \alpha_i \rightarrow \alpha^*<em>{i + 1} = \alpha</em>{i + 1} + \alpha_{i}$</li>
    </ul>

    <p>“unverbrauchter” $\alpha$-Fehler wird an folgenden Test vererbt</p>
  </li>
</ol>

<p>Beispiel:</p>

<p>Durch die “Vererbung” des $\alpha$-Fehlers werden einige Tests signifikant, die bei einfacher Aufteilung der Fehlerwahrscheinlichkeit nicht als signifikant gelten könnten. Insgesamt beleibt aber $\alpha_{FWER} \le 5\%$.</p>

<h1 id="varianzanalyse-anova">
<a class="anchor" href="#varianzanalyse-anova" aria-hidden="true"><span class="octicon octicon-link"></span></a>Varianzanalyse (ANOVA)</h1>

<p>Zweck der ANOVA ist es, aufzuklären, ob die Variation zwischen Stichproben, z.B. Versuchsarmen (Kontrollgruppe vs. Treatment-Gruppe), auf die experimentelle Manipulation zurückzuführen ist, oder zufällige Variation ist, die auch auftreten würde, wenn mehrere Zufallsstichproben aus der gleichen Population gezogen würden.</p>

<h2 id="voraussetzungen">
<a class="anchor" href="#voraussetzungen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Voraussetzungen</h2>

<ul>
  <li>
    <p><strong>unabhängige Variable in Faktorstufen</strong></p>

    <p>UV muss in diskreten Faktorstufen vorliegen, damit sich eindeutige Gruppen bilden lassen.</p>
  </li>
  <li>
    <p><strong>Homooskedastizität</strong></p>

    <p>Die Varianzen der einzelnen Gruppen dürfen sich nicht unterscheiden</p>

    <p>In R mittels <code class="language-plaintext highlighter-rouge">leveneTest</code> im Paket <code class="language-plaintext highlighter-rouge">car</code></p>
  </li>
  <li>
    <p><strong>Normalverteilung der Residuen</strong></p>
  </li>
</ul>

<h2 id="einfaktorielle-varianzanalyse">
<a class="anchor" href="#einfaktorielle-varianzanalyse" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einfaktorielle Varianzanalyse</h2>

<h3 id="messwertezerlegung">
<a class="anchor" href="#messwertezerlegung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Messwertezerlegung</h3>

<ul>
  <li>Messwert eines Merkmals einer Versuchsperson $m$, unter Versuchsbedingung $j$: $x_{mj}$</li>
  <li>Durchschnittlicher Messwert aller VP unter Bedingung $j$: $\overline{x}_j$</li>
  <li>
    <p>Abweichung vom Durchschnitt der Bedingungsgruppe $j$: $\overline{x}<em>j - x</em>{jm} = e_{mj}$</p>

    <p>$e$: Fehlerwert, auch Residuum genannt: die Variation von Messwerten, die übrig bleibt, nachdem alle systematischen Anteile der Variation entfernt wurden</p>
  </li>
</ul>

<p>$$x_{mj}=\overline{x}<em>j + e</em>{mj}$$</p>

<p>Der Messwert $x_{mj}$ wird zerlegt in den Gruppenmittelwert $\overline{x}<em>j$ und das Residuum $e</em>{mj}$.</p>

<h4 id="effekt-von-faktorstufen">
<a class="anchor" href="#effekt-von-faktorstufen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Effekt von Faktorstufen</h4>

<p>Der Effekt $t_j$ jeder Faktorstufe (Bedingung) ist die Abweichung des jeweiligen Gruppenmittelwertes $\overline{x}_j$ vom Gesamtmittelwert $\overline{x}$:</p>

<p>$$t_j = \overline{x}_j - \overline{x}$$
Der Effekt $t_j$ ist <em>nur bedingt interpretierbar</em>, da er sowohl eine systematische Abhängigkeit von der Faktorstufe $j$ haben kann, aber auch durch Stichprobenfehler entstehen kann.</p>

<p>Der Messwert $x_{mj}$ einer einzelnen Versuchsperson $m$ unter Bedingung $j$ wird also zerlegt in den Gesamtmittelwert $\overline{x}$ (Grundniveau), den Effekt der Bedingung $t_j$ und das Residuum der Person selbst $e_{mj}$:</p>

<p>$$x_{mj} = \overline{x} + t_j + e_{mj}$$</p>

<h3 id="quadratsummenzerlegung">
<a class="anchor" href="#quadratsummenzerlegung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Quadratsummenzerlegung</h3>

<p><strong>Quadratsumme</strong>: Maß der Variation (analog zur Varianz, nur ohne Einfluss der Stichprobengröße)</p>

<p>$$QS_{total} = \sum_{j=1}^{J}{\sum_{m=1}^{n_j}{(x_{mj} - \overline{x})^2}}$$</p>

<p>$J$: Anzahl der Faktorstufen</p>

<p>$n_j$: Anzahl Individuen in der jeweiligen Faktorgruppe</p>

<p><strong>Quadratsumme zwischen der Gruppen:</strong></p>

<p>$$QS_{zw} = \sum_{j=1}^{J}{\sum_{m=1}^{n_j}{(\overline{x}_{j} - \overline{x})^2}}$$</p>

<p>In $(\overline{x}<em>{j} - \overline{x})$ kommt $m$ nicht mehr vor. $QS</em>{zw}$ ist also unabhängig von der Variation die nur durch die einzelnen Versuchspersonen verursacht wird. Also lässt sich $QS_{zw}$ vereinfachen als, weil $(\overline{x}_{j} - \overline{x})$ jeweils für jedes $m$ gleich ist:</p>

<p>$$QS_{zw} = \sum_{j=1}^{J}{n_j \cdot (\overline{x}_{j} - \overline{x})^2}$$</p>

<p><strong>Quadratsumme innerhalb der Gruppen:</strong></p>

<p>$$QS_{inn} = \sum_{j=1}^{J}{\sum_{m=1}^{n_j}{(x_{mj} - \overline{x}_{j})^2}}$$</p>

<p>Hier taucht $\overline{x}$ nicht mehr auf und die Abweichungen der Faktorgruppen vom Gesamtmittelwert haben keinen Einfluss mehr.</p>

<p><strong>Die Gesamtquadratsumme entspricht der Summe der Teilquadratsummen:</strong></p>

<p>$$QS_{total} = QS_{zw} + QS_{inn}$$</p>

<p>Die Teilquadratsummen stellen ein Maß dafür dar, wie viel Varianz durch den Effekt des jeweiligen Faktors bzw. die Residuen individuellen Versuchspersonen erklärt werden.</p>

<p>$QS_{zw}$: Quadratsumme des Effektes</p>

<p>$QS_{inn}$: Quadratsumme der Residuen</p>

<h3 id="effektgrößenschätzer-hateta2">
<a class="anchor" href="#effektgr%C3%B6%C3%9Fensch%C3%A4tzer-hateta2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Effektgrößenschätzer $\hat{\eta}^2$</h3>

<p>$\eta$: Eta</p>

<p>Das Verhältnis der Effekt-Quadratsumme zur Gesamtquadratsumme stellt dar, welcher Anteil der Gesamtvarianz durch den Effekt aufgeklärt wird.</p>

<p>$$\hat{\eta}^2 = \frac{QS_{zw}}{QS_{total}}$$</p>

<p>$\hat{\eta}^2$ kann auch direkt aus dem empirischen F-Wert berechnet werden (siehe <a href="#f-test">F-Test</a>):</p>

<p>$$\hat{\eta}^2 = \frac{F \cdot df_{zw}}{F \cdot df_{zw} + df_{inn}}$$</p>

<p>$\hat{\eta}^2 = 0$: Variation entsteht komplett aus den Residuen und es gibt keinen gemessenen Effekt.</p>

<p>$\hat{\eta}^2 = 1$: Variation stammt vollständig vom Effekt, keine Residuen.</p>

<h3 id="effektgrößenschätzer-hatomega2">
<a class="anchor" href="#effektgr%C3%B6%C3%9Fensch%C3%A4tzer-hatomega2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Effektgrößenschätzer $\hat{\omega}^2$</h3>

<p>$\omega$: Omega</p>

<p>$\hat{\eta}^2$ ist kein erwartungstreuer Schätzer für $\eta^2$, da die zugrundeliegende Zählerquadratsumme $QS_{zw}$ Stichprobenfehler enthält.</p>

<p>$\hat{\omega}^2$ enthält diese Überschätzung von $\eta^2$ nicht.</p>

<p>$$\hat{\omega}^2 = \frac{QS_{zw} - (J - 1) \cdot MQS_{inn}}{QS_{total} + MQS_{inn}}$$</p>

<h3 id="effektgröße-phi2-signal-rausch-verhältnis">
<a class="anchor" href="#effektgr%C3%B6%C3%9Fe-phi2-signal-rausch-verh%C3%A4ltnis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Effektgröße $\phi^2$, Signal-Rausch-Verhältnis</h3>

<p>$\phi$: Phi</p>

<p>In der Population ist $\phi^2$ der Quotient aus Effektvarianz und Residualvarianz:</p>

<p>$$\phi^2 = \frac{\sigma_{\tau}^2}{\sigma_{\epsilon}^2}$$</p>

<p>$\phi^2$ lässt sich auch aus $\eta^2$ berechnen:</p>

<p>$$\phi^2 = \frac{\eta^2}{1 - \eta^2}$$</p>

<p>Analog gilt für den Schätzer $\hat{\phi}^2$:</p>

<p>$$\hat{\phi}^2 = \frac{\hat{\eta}^2}{1 - \hat{\eta}^2}$$</p>

<h4 id="konventionen-für-phi2">
<a class="anchor" href="#konventionen-f%C3%BCr-phi2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konventionen für $\phi^2$:</h4>

<ul>
  <li>$\phi^2 \approx 0.01$: kleiner Effekt</li>
  <li>$\phi^2 \approx 0.0625$: mittlerer Effekt</li>
  <li>$\phi^2 \approx 0.16$: großer Effekt</li>
</ul>

<h3 id="effektgröße-phi">
<a class="anchor" href="#effektgr%C3%B6%C3%9Fe-phi" aria-hidden="true"><span class="octicon octicon-link"></span></a>Effektgröße $\phi$</h3>

<p>Auch $f$ genannt</p>

<p>$$\phi = f = \sqrt{\phi^2}$$</p>

<p>$\phi$ ist leichter interpretierbar als $\phi^2$, da es Vielfache der Standardabweichung $\sigma$ des Merkmals angibt.</p>

<h3 id="effektgröße-lambda">
<a class="anchor" href="#effektgr%C3%B6%C3%9Fe-lambda" aria-hidden="true"><span class="octicon octicon-link"></span></a>Effektgröße $\lambda$</h3>

<p>$\lambda$: Lambda</p>

<p>$\lambda$ ist der Nicht-Zentralitäts-Parameter der F-Verteilung. Je größer $\lambda$, umso weiter nach rechts verschoben und flacher ist die Dichtefunktion der F-Verteilung:</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-52-1.png" alt="plot of chunk unnamed-chunk-52" width="576" style="display: block; margin: auto;"></p>

<p>Die Kurve für $\lambda = 0$ (“zentrale F-Verteilung”) ist die Verteilung unter der Nullhypothese dar während die Kurve mit $\lambda \gt 0$ die Alternativhypothese unter Annahme eines Effektes darstellt.</p>

<p>$$\lambda = n \cdot \frac{\sigma_{\tau}^2}{\sigma_{\epsilon}^2} = n \cdot \phi^2$$</p>

<h3 id="beziehungen-zwischen-effektgrößenschätzern">
<a class="anchor" href="#beziehungen-zwischen-effektgr%C3%B6%C3%9Fensch%C3%A4tzern" aria-hidden="true"><span class="octicon octicon-link"></span></a>Beziehungen zwischen Effektgrößenschätzern</h3>

<p>$$\hat{\lambda} = n \cdot \hat{\phi}^2 = n \cdot \frac{\hat{\eta}^2}{1 - \hat{\eta}^2}$$</p>

<p>$$\hat{\eta}^2 = \frac{\hat{\lambda}}{\hat{\lambda} + n}$$</p>

<p>$$\hat{\phi}^2 = \frac{\hat{\lambda}}{n}$$
Für die Effektgrößen in der Population gelten die Formeln analog ohne Schätzer.</p>

<h3 id="konfidenzintervalle-der-effektgrößen">
<a class="anchor" href="#konfidenzintervalle-der-effektgr%C3%B6%C3%9Fen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konfidenzintervalle der Effektgrößen</h3>

<p>Es wird meistens das Konfidenzintervall für eine Effektgröße berechnet und dann je nach Bedarf in eine der anderen  Effektgrößen umgerechnet.</p>

<p>Das Konfidenzintervall für $\hat{\eta}^2$ kann in R mit der Funktion <code class="language-plaintext highlighter-rouge">ci.pvaf</code> (Paket MBESS) ermittelt werden.</p>

<p><em>(CI: confidence interval, PVAF: proportion of variance accounted for)</em></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w">
</span><span class="n">df2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">20</span><span class="w">
</span><span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">100</span><span class="w">
</span><span class="n">f_v</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">6</span><span class="w">

</span><span class="n">ci.pvaf</span><span class="p">(</span><span class="n">F.value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f_v</span><span class="p">,</span><span class="w"> </span><span class="n">df.1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df1</span><span class="p">,</span><span class="w"> </span><span class="n">df.2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df2</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">ci_result</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in ci.pvaf(F.value = f_v, df.1 = df1, df.2 = df2, N = n, conf.level = 0.95): could not find function "ci.pvaf"
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ci_result</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in eval(expr, envir, enclos): object 'ci_result' not found
</code></pre></div></div>

<p>Dargestellt als F-Verteilungen mit $\lambda$-Konfidenzintervall:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in h(simpleError(msg, call)): error in evaluating the argument 'obj' in selecting a method for function 'unname': object 'ci_result' not found
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in h(simpleError(msg, call)): error in evaluating the argument 'obj' in selecting a method for function 'unname': object 'ci_result' not found
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in eval(expr, envir, enclos): object 'eta_sq_lower' not found
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in eval(expr, envir, enclos): object 'eta_sq_upper' not found
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Error in list2(na.rm = na.rm, ...): object 'ncp_lower' not found
</code></pre></div></div>

<h3 id="schätzung-der-populationsparameter">
<a class="anchor" href="#sch%C3%A4tzung-der-populationsparameter" aria-hidden="true"><span class="octicon octicon-link"></span></a>Schätzung der Populationsparameter</h3>

<h4 id="schätzung-des-populationsmittelwertes">
<a class="anchor" href="#sch%C3%A4tzung-des-populationsmittelwertes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Schätzung des Populationsmittelwertes</h4>

<p>$$\hat{\mu} = \overline{x} = \frac{\sum_{j=1}^J{\sum_{m=1}^{n_j}{x_{mj}}}}{n}$$</p>

<p>Der Gesamtmittelwert aller Messungen $x_{mj}$ ist der Schätzer für den Mittelwert der Population $\hat{\mu}$.</p>

<h4 id="schätzung-des-effektes-tau_j">
<a class="anchor" href="#sch%C3%A4tzung-des-effektes-tau_j" aria-hidden="true"><span class="octicon octicon-link"></span></a>Schätzung des Effektes $\tau_j$</h4>

<p>$$\hat{\tau_j} = t_j = x_{mj} - \overline{x}$$</p>

<h4 id="schätzung-der-varianz-der-residuen-in-der-population">
<a class="anchor" href="#sch%C3%A4tzung-der-varianz-der-residuen-in-der-population" aria-hidden="true"><span class="octicon octicon-link"></span></a>Schätzung der Varianz der Residuen in der Population</h4>

<p>Die geschätzte Varianz der Residuen in der Population $\hat{\sigma}<em>\epsilon^2$ entspricht der mittleren Quadratsumme $MQS</em>{inn}$ innerhalb der einzelnen Bedingungen $MQS_{j}$:</p>

<p>$$MQS_{j} = \frac{\sum_{m-1}^{n_j}{(x_{mj}-\overline{x})^2}}{n_j - 1}$$</p>

<p>$$\hat{\sigma}<em>\epsilon^2 = MQS</em>{inn} = \frac{\sum_{j=1}^{J}{MQS_j}}{J}$$</p>

<p>Beim unterschiedlich großen Gruppen wird ein gewichtetes arithmetisches Mittel der $MQS_j$ berechnet:</p>

<p>$$\hat{\sigma}<em>\epsilon^2 = MQS</em>{inn} = \frac{\sum_{j=1}^{J}{MQS_j \cdot (n_j - 1)}}{\sum_{j=1}^J{n_j-1}}$$</p>

<p>Das lässt sich vereinfachen als:</p>

<p>$$\hat{\sigma}<em>\epsilon^2 = MQS</em>{inn} = \frac{QS_{inn}}{n-J}$$</p>

<h2 id="hypothesenprüfung-in-der-varianzanalyse">
<a class="anchor" href="#hypothesenpr%C3%BCfung-in-der-varianzanalyse" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesenprüfung in der Varianzanalyse</h2>

<p>Wenn $H_0$ gilt, und kein Effekt zwischen den Faktorgruppen besteht, so sind $MQS_{zw}$ und $MQS_{inn}$ beides erwartungstreue Schätzer der Varianz der Residuen in der Population $\hat{\sigma}^2_\epsilon$, da außer den Residuen keine andere Quelle für Varianz vorhanden ist.</p>

<p>Je mehr $MQS{zw}$ von $MQS_{inn}$ abweicht, umso mehr spricht das dafür, dass die Nullhypothese nicht haltbar ist.</p>

<p>$$MQS_{zw} = \frac{QS_{zw}}{J-1}$$</p>

<h3 id="f-test">
<a class="anchor" href="#f-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>F-Test</h3>

<p>Die F-Statistik ist ein Maß dafür, wie stark $MQS_{zw}$ von $MQS_{inn}$ abweicht:</p>

<p>$$F = \frac{MQS_{zw}}{MQS_{inn}}$$</p>

<p>$F$ folgt der F-Verteilung. Diese hat zwei Parameter:</p>

<ul>
  <li>
    <p>Freiheitsgrade des Kennwertes im Zähler, hier $MQS_{zw}$</p>

    <p>$df_{zw} = J-1$</p>
  </li>
  <li>
    <p>Freiheitsgrade des Kennwertes in Nenner, hier $MQS_{inn}$</p>

    <p>$df_{inn} = n-J$</p>
  </li>
</ul>

<p>Geprüft wird der empirische F-Wert also gegen die Verteilung $F(df_{zw}; df_{inn})$. Wenn der kritische F-Wert für das festgelegte $\alpha$-Niveau erreicht wird, ist die Nullhypothese zu verwerfen.</p>

<p>Der F-Test <strong>prüft nur die globale Nullhypothese</strong>, also dass ALLE Effekte $\tau_j$ in der Population 0 sind. Er gibt keine Auskunft darüber, welche Mittelwertunterschiede zwischen welchen Faktorstufen signifikant sind.</p>

<h4 id="beispiel-für-f-test">
<a class="anchor" href="#beispiel-f%C3%BCr-f-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Beispiel für F-Test</h4>

<p>Zwei Faktorgruppen (Studienarme), je 10 Versuchspersonen, $J = 2, n_j = 10$</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-55-1.png" alt="plot of chunk unnamed-chunk-55" width="576" style="display: block; margin: auto;"></p>

<p><strong>Gesamtquadratsumme $QS_{total}$:</strong></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">summarize</span><span class="p">(</span><span class="w">
    </span><span class="n">QS_total</span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="p">)</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">pull</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">QS_total</span><span class="w">

</span><span class="n">QS_total</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 41.86613
</code></pre></div></div>

<p><strong>Quadratsumme zwischen den Faktorgruppen $QS_{zw}$:</strong></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="w">
    </span><span class="n">x_j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">ungroup</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">summarize</span><span class="p">(</span><span class="w">
    </span><span class="n">QS_zw</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="w"> </span><span class="p">(</span><span class="n">x_j</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="p">)</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">pull</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">QS_zw</span><span class="w">

</span><span class="n">QS_zw</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 16.27101
</code></pre></div></div>

<p><strong>Quadratsumme innerhalb der Gruppen $QS_{inn}$:</strong></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="w">
    </span><span class="n">x_j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">ungroup</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">summarize</span><span class="p">(</span><span class="w">
    </span><span class="n">QS_inn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">x_j</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="p">)</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">pull</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">QS_inn</span><span class="w">

</span><span class="n">QS_inn</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 25.59512
</code></pre></div></div>

<p><strong>Additivität der Quadratsummen:</strong></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">QS_total</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">QS_zw</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">QS_inn</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] TRUE
</code></pre></div></div>

<p><strong>Varianzaufklärung $\eta^2$:</strong></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">eta_sq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QS_zw</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">QS_total</span><span class="w">
</span><span class="n">eta_sq</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 0.3886438
</code></pre></div></div>

<p>Der Effekt zwischen den Faktorstufen klärt 38.9% der Varianz auf.</p>

<p><strong>Hypothesenprüfung:</strong></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MQS_zw</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">QS_zw</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">J</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">MQS_zw</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 16.27101
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MQS_inn</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">QS_inn</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">n_total</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">J</span><span class="p">)</span><span class="w">
</span><span class="n">MQS_inn</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1.421951
</code></pre></div></div>

<p>Empirischer F-Wert:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f_emp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MQS_zw</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">MQS_inn</span><span class="w">
</span><span class="n">f_emp</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 11.44274
</code></pre></div></div>

<p>Freiheitsgrade:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_zw</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">J</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">df_inn</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">n_total</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">J</span><span class="w">
</span><span class="nf">list</span><span class="p">(</span><span class="n">df_zw</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_zw</span><span class="p">,</span><span class="w"> </span><span class="n">df_inn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_inn</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## $df_zw
## [1] 1
## 
## $df_inn
## [1] 18
</code></pre></div></div>

<p>F-Verteilung und Vergleich mit kritischem F-Wert bei $\alpha = 0.05$:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f_crit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">qf</span><span class="p">(</span><span class="m">0.95</span><span class="p">,</span><span class="w"> </span><span class="n">df1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_zw</span><span class="p">,</span><span class="w"> </span><span class="n">df2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_inn</span><span class="p">)</span><span class="w">

</span><span class="n">ggplot</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">xlim</span><span class="p">(</span><span class="m">2.5</span><span class="p">,</span><span class="w"> </span><span class="m">13</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_function</span><span class="p">(</span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">df1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_zw</span><span class="p">,</span><span class="w"> </span><span class="n">df2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_inn</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">stat_function</span><span class="p">(</span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">df1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_zw</span><span class="p">,</span><span class="w"> </span><span class="n">df2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_inn</span><span class="p">),</span><span class="w">
                </span><span class="n">geom</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"area"</span><span class="p">,</span><span class="w">
                </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"hotpink3"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.3</span><span class="p">,</span><span class="w">
                </span><span class="n">xlim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">f_crit</span><span class="p">,</span><span class="w"> </span><span class="m">13</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f_emp</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"skyblue3"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">annotate</span><span class="p">(</span><span class="s2">"text"</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">paste</span><span class="p">(</span><span class="s2">"F ="</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">f_emp</span><span class="p">,</span><span class="m">2</span><span class="p">)),</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.025</span><span class="p">,</span><span class="w"> </span><span class="n">hjust</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"skyblue3"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"F-Wert"</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Wahrscheinlichkeitsdichte"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme_custom</span><span class="w">
</span></code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-65-1.png" alt="plot of chunk unnamed-chunk-65" width="576" style="display: block; margin: auto;"></p>

<p>Der empirische F-Wert überschreitet den kritischen F-Wert für $\alpha = 0.05$. Die Nullhypothese wird also verworfen. Es besteht ein signifikanter Unterschied zwischen den Faktorgruppen, der sich nicht durch zufällige Variation erklären lässt.</p>

<h3 id="automatische-durchführung-in-r">
<a class="anchor" href="#automatische-durchf%C3%BChrung-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Automatische Durchführung in R</h3>

<p>Die <code class="language-plaintext highlighter-rouge">aov()</code> Funktion ist standardmäßig verfügbar.</p>

<p>Es muss eine Formel angegeben werden, die den Zusammenhang zwischen unabhängigen und abhängigen Variablen beschreibt, hier z.B. <code class="language-plaintext highlighter-rouge">x ~ j</code> (Messwert $x$ in Abhängigkeit von Faktor $j$).</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">aov</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">j</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">samples</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">summary</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##             Df Sum Sq Mean Sq F value  Pr(&gt;F)   
## j            1  16.27  16.271   11.44 0.00332 **
## Residuals   18  25.59   1.422                   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
</code></pre></div></div>

<h2 id="zweifaktorielle-varianzanalyze">
<a class="anchor" href="#zweifaktorielle-varianzanalyze" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zweifaktorielle Varianzanalyze</h2>

<p>Zusätzlich zum ersten Faktor $A$ und einem zweiten Faktor $B$, die die Haupteffekte verursachen können, kommt noch die Interaktion $A \times B$ hinzu. Die Gesamtquadratsumme $QS_{total} wird bei zwei Faktoren zerlegt in:</p>

<ul>
  <li>$QS_A$</li>
  <li>$QS_B$</li>
  <li>$QS_{A \times B}$</li>
  <li>$QS_{inn}$</li>
</ul>

<p>Für die Quadratsummen der Haupteffekte werden die Abweichungen der Mittelwerte in ALLEN Gruppen der gleichen Faktorstufe auf dem jeweiligen Faktor vom Gesamtmittelwert bestimmt.</p>

<p>Für Faktor $A$ mit $j$ Stufen:</p>

<p>$$QS_A = \sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{(\overline{x}_j - \overline{x})^2}}}$$</p>

<p>Vereinfacht, da Variation der $n_{Zelle}$ Messwerte in jeder Zelle gemittelt werden:</p>

<p><em>(Vorausgesetzt alle Zellen enthalten gleich viele Messwerte)</em></p>

<p>$$QS_A = n_{Zelle} \cdot K \cdot\sum_{j=1}^J{}{(\overline{x}_j - \overline{x})^2}$$</p>

<p>Für Faktor $B$ analog:</p>

<p>$$QS_B = \sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{(\overline{x}<em>k - \overline{x})^2}}} = n</em>{Zelle} \cdot J \cdot\sum_{k=1}^K{}{(\overline{x}_k - \overline{x})^2} $$</p>

<p>Die Quadratsumme des Interaktionseffektes $QS_{A \times B}$ ergibt sich, indem die Mittelwertabweichungen der Haupteffekte $A$ und $B$ von der Mittelwertabweichung in jeder Zelle abgezogen werden:</p>

<p>$$QS_{A \times B} = \sum_{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{((\overline{x}_{jk} - \overline x) - (\overline x_j - \overline x) - (\overline x_k - \overline{x}))^2}}}$$</p>

<p>Auch hier lässt sich vereinfachen:</p>

<p>$$QS_{A \times B} = n_{Zelle} \cdot \sum_{k=1}^K{\sum_{j=1}^J{((\overline{x}_{jk} - \overline x) - (\overline x_j - \overline{x}) - (\overline x_k - \overline{x}))^2}}$$</p>

<h3 id="nicht-partiielles-effektstärkenmaß-hateta2">
<a class="anchor" href="#nicht-partiielles-effektst%C3%A4rkenma%C3%9F-hateta2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Nicht-partiielles Effektstärkenmaß: $\hat{\eta}^2$</h3>

<p>Genau wie in der einfaktoriellen Varianzanalyse ist $\hat{\eta}^2$ das Verhältnis von Effektquadratsumme zu Gesamtquadratsumme.</p>

<p>$$\hat{\eta}<em>A^2 = \frac{QS_A}{QS</em>{total}}$$
$$\hat{\eta}<em>B^2 = \frac{QS_B}{QS</em>{total}}$$
$$\hat{\eta}<em>{A \times B}^2 = \frac{QS</em>{A \times B}}{QS_{total}}$$</p>

<p>Das nicht-partielle $\hat{\eta}^2$ hat das Problem, dass es nur Auskunft darüber gibt, wie viel der Gesamtvarianz in einer konkreten Untersuchung ein Faktor oder eine Interaktion aufklärt. Es ermöglicht keinen Vergleich mit anderen Untersuchungen, die den gleichen Faktor enthalten aber zusätzlich noch weitere, die nicht in beiden Untersuchungen vorhanden sind.</p>

<h3 id="partielles-effektgrößenmaß-hateta_p2">
<a class="anchor" href="#partielles-effektgr%C3%B6%C3%9Fenma%C3%9F-hateta_p2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Partielles Effektgrößenmaß $\hat{\eta}_p^2$</h3>

<p>Das partielle $\hat{\eta}_p^2$ ist das Verhältnis einer Effektquadratsumme und einer Teilquadratsumme, die Effekt und Residuum enthält:</p>

<p>$$\hat{\eta}<em>{pA}^2 = \frac{QS</em>{A}}{QS_{A} + QS_{inn}}$$</p>

<p><em>(analog für Effekte $B$ und $A \times B$)</em></p>

<h3 id="schätzung-der-haupteffekte">
<a class="anchor" href="#sch%C3%A4tzung-der-haupteffekte" aria-hidden="true"><span class="octicon octicon-link"></span></a>Schätzung der Haupteffekte</h3>

<p>$$\tau_{b_j} = \hat{\tau}_{b_j} = \overline{x}_j - \overline {x}$$</p>

<p>$$\tau_{b_k} = \hat{\tau}_{b_k} = \overline{x}_k - \overline {x}$$</p>

<p>$$\tau_{b_{(A \times B)<em>{jk}}} = \hat{\tau}</em>{b_k} = (\overline{x}<em>{jk} - \overline {x}) - (\overline{x}</em>{j} - \overline {x}) - (\overline{x}_{k} - \overline {x})$$</p>

<h3 id="schätzung-des-residuums">
<a class="anchor" href="#sch%C3%A4tzung-des-residuums" aria-hidden="true"><span class="octicon octicon-link"></span></a>Schätzung des Residuums</h3>

<p>$$\hat{\epsilon}<em>{mjk} = x</em>{mjk} - \overline x_{jk}$$</p>

<h3 id="schätzung-der-populationsresidualvarianz">
<a class="anchor" href="#sch%C3%A4tzung-der-populationsresidualvarianz" aria-hidden="true"><span class="octicon octicon-link"></span></a>Schätzung der Populationsresidualvarianz</h3>

<p>$$\hat{\sigma}^2<em>{\epsilon} = \frac{\sum</em>{k=1}^K{\sum_{j=1}^J{\sum_{m=1}^{n_{Zelle}}{(x_{mjk} - \overline x_{jk})^2}}}}{J \cdot K \cdot (n_{Zelle} - 1)}$$</p>

<h3 id="hypothesenprüfung-bei-zweifaktorieller-varianzanalyse">
<a class="anchor" href="#hypothesenpr%C3%BCfung-bei-zweifaktorieller-varianzanalyse" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesenprüfung bei zweifaktorieller Varianzanalyse</h3>

<h4 id="zerlegung-der-freiheitsgrade">
<a class="anchor" href="#zerlegung-der-freiheitsgrade" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zerlegung der Freiheitsgrade</h4>

<p>$$df_{zw} = df_A + df_B + df_{A \times B} = J \cdot K - 1$$</p>

<p>$$df_A = J - 1$$
$$df_B = K - 1$$
$$df_{inn} = J \cdot K \cdot (n_{Zelle} - 1)$$</p>

<p>daraus folgt:</p>

<p>$$df_{A \times B} = (J \cdot K - 1) - (J - 1) - (K - 1)$$
$$df_{A \times B} = (J - 1) \cdot (K - 1)$$</p>

<p>$$df_{total} = df_A + df_B + df_{A \times B} +df_{inn}$$</p>

<p>Entsprechende mittlere Quadratsummen und F-Werte wie bei einfaktorieller ANOVA:</p>

<p>$$MQS_{inn} = \frac{QS_{inn}}{df_{inn}}$$</p>

<p>\begin{align<em>}
MQS_A &amp;= \frac{QS_A}{df_A} <br>
F_A &amp;= \frac{MQS_A}{MQS_{inn}}
\end{align</em>}</p>

<p>\begin{align<em>}
MQS_B &amp;= \frac{QS_B}{df_B} <br>
F_B &amp;= \frac{MQS_B}{MQS_{inn}}
\end{align</em>}</p>

<p>\begin{align<em>}
MQS_{A \times B} &amp;= \frac{QS_{A \times B}}{df_{A \times B}} <br>
F_{A \times B} &amp;= \frac{MQS_{A \times B}}{MQS_{inn}}
\end{align</em>}</p>

<p>F-Tests und Konfidenzintervalle funktionieren genau wie bei der einfaktoriellen Varianzanalyse.</p>

<h4 id="hypothesenpaare">
<a class="anchor" href="#hypothesenpaare" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesenpaare</h4>

<ul>
  <li>
    <p>Haupteffekt $A$</p>

    <p>$H_0: \mu_j - \mu = 0$ bzw. $\tau_{A_j} = 0$</p>

    <p>$H_1: \mu_j = \mu \neq 0$ bzw. $\tau_{A_j} \neq 0$</p>
  </li>
  <li>
    <p>Haupteffekt $B$</p>

    <p>$H_0: \mu_k - \mu = 0$ bzw. $\tau_{B_k} = 0$</p>

    <p>$H_1: \mu_k = \mu \neq 0$ bzw. $\tau_{B_k} \neq 0$</p>
  </li>
  <li>
    <p>Interaktion $A \times B$</p>

    <p>$H_0: \mu_{jk} - \mu_j - \mu_k = 0$ bzw. $\tau_{(A \times B)_{jk}} = 0$</p>

    <p>$H_1: \mu_{jk} - \mu_j - \mu_k \neq 0$ bzw. $\tau_{(A \times B)_{jk}} \neq 0$</p>
  </li>
</ul>

<h2 id="varianzanalyse-mit-messwiederholung">
<a class="anchor" href="#varianzanalyse-mit-messwiederholung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Varianzanalyse mit Messwiederholung</h2>

<p>Sowohl bei einfaktorieller als auch zweifaktorieller ANOVA können Messwiederholungen der gleichen Versuchspersonen mit berücksichtigt werden.</p>

<p>Hierzu wird die Versuchsperson selbst als Faktor mit Haupteffekt eingeführt und es findet eine weitere Quadratsummenzerlegung statt:</p>

<p>$$QS_{zw} = QS_{zwA} + QS_{zwP}$$</p>

<p>$QS_{zwA}$: Quadratsumme der Variation zwischen den Stufen des Faktors $A$</p>

<p>$QS_{zwP}$: Quadratsumme der Variation zwischen Versuchspersonen</p>

<p>$QS_{res}$ bezeichnet die verbleibende residuale Quadratsumme, die auch die Variation zwischen Messzeitpunkten der jeweils gleichen Versuchsperson enthält.</p>

<p>Das partielle $\hat{\eta}^2_p$ gibt dann Auskunft darüber, welcher Anteil der Gesamt Varianz NUR durch den Faktor $A$ aufgeklärt wird:</p>

<p>$$\hat{\eta}^2<em>p = \frac{QS</em>{zwA}}{QS_{zwA} + QS_{res}}$$</p>

<p>Messwiederholung ist sowohl auf einfaktorielle als auch zweifaktorielle ANOVA anwendbar.</p>

<h2 id="populationsmodell-der-varianzanalyse">
<a class="anchor" href="#populationsmodell-der-varianzanalyse" aria-hidden="true"><span class="octicon octicon-link"></span></a>Populationsmodell der Varianzanalyse</h2>

<p>In der Population ergibt sich der Messwert aus dem Gesamtmittelwert addiert mit allen Haupt- und Interaktionseffekten, sowie dem Residuum:</p>

<p>$$x_{mjk} = \mu + \tau_{a_j} + \tau_{b_k} + \tau_{(A \times B)<em>{jk}} + \epsilon</em>{mjk}$$</p>

<p>$\rightarrow$ Grundlage für allgemeines lineares Modell!</p>

<h1 id="allgemeines-lineares-modell">
<a class="anchor" href="#allgemeines-lineares-modell" aria-hidden="true"><span class="octicon octicon-link"></span></a>Allgemeines Lineares Modell</h1>

<ul>
  <li>Oberbegriff für eine generisches statistisches Modell zur Prognose bzw. Erklärung von metrischen abhängigen Variablen</li>
</ul>

<p>Student-T-Test und Varianzanalyse sind z.B. Sonderfälle dieses Modells.</p>

<h2 id="einfache-lineare-regression">
<a class="anchor" href="#einfache-lineare-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einfache lineare Regression</h2>

<p>Bei der linearen Regression wird versucht, eine Gerade so zu legen, dass deren mittlerer Abstand zu den empirischen Messwerten möglichst gering ist.</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-67-1.png" alt="plot of chunk unnamed-chunk-67" width="576" style="display: block; margin: auto;"></p>

<p><strong>Modellgleichung mit einer unabhängigen Variablen:</strong></p>

<p>In einer Stichprobe:</p>

<p>$$Y = b_0 + b_1 \cdot X_1 + E$$</p>

<p>In der Population:</p>

<p>$$Y = \beta_0 + \beta_1 \cdot X_1 + \epsilon$$</p>

<ul>
  <li>$b_0$/$\beta_0$: Regressionskonstante, Schnittpunkt mit der Y-Achse, “Intercept”</li>
  <li>$b_1$/$\beta_1$: Regressionsgewicht, Steigung der Regressionsgeraden, “Slope”</li>
</ul>

<p>Der Abstand der Messpunkte zur Regressionsgeraden sind die Residuen:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y_fit</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_segment</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">xend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">yend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"hotpink3"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Residuum"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme_custom</span><span class="w">
</span></code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-68-1.png" alt="plot of chunk unnamed-chunk-68" width="576" style="display: block; margin: auto;"></p>

<p>Der Mittelwert der Residuen ist immer 0.</p>

<p>Die Varianz der Residuen wird auch als <strong>Fehlervarianz</strong> bezeichnet, da die angibt, wie weit die empirischen Werte um die Regressionsgerade streuen und damit, wie ungenau die Vorhersagen des Modells sind.</p>

<p>Die Standardabweichung der Residuen ist der <strong>Standardschätzfehler</strong>. Sie ist in der Stichprobe allerdings kein erwartungstreuer Schätzer des Standardschätzfehlers in der Population.</p>

<h3 id="bestimmung-der-regressionskoeffizienten">
<a class="anchor" href="#bestimmung-der-regressionskoeffizienten" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bestimmung der Regressionskoeffizienten</h3>

<p>Die Bedingung, dass der Abstand der Messpunkte zur Regressionsgeraden minimal sein soll, ist am besten erfüllt wenn $b1$ aus der Produkt-Moment-Korrelation der beiden Variablen sowie ihrer Stichprobenstandardabweichungen $s_X$ und $z_Y$ bestimmt wird:</p>

<p>$$b_1 = r_{XY} \cdot \frac{s_Y}{s_X}$$</p>

<p>$$r_{XY} = \frac{1}{n} \cdot \sum_{m = 1}^n{z_X \cdot z_Y}$$
<em>$z_X$ und $z_Y$ sind die Z-transformierten Werte der Variablen.</em></p>

<p>Bei zwei Z-standardisierten Variablen ist das Regressionsgewicht gleich der Produkt-Moment-Korrelation, weil die Stichprobenstandardabweichungen beide 1 sind.</p>

<p>Die Regressionskonstante $b_0$ ergibt sich dann wie folgt:</p>

<p>$$b_0 = \overline{y} - b_1 \cdot \overline{x}$$</p>

<h3 id="standardfehler-der-modellparameter">
<a class="anchor" href="#standardfehler-der-modellparameter" aria-hidden="true"><span class="octicon octicon-link"></span></a>Standardfehler der Modellparameter</h3>

<p><strong>Erwartungsstreuer Schätzer des Standardschätzfehlers:</strong></p>

<p>$$\hat{\sigma}_e = \sqrt{\frac{1}{n-2} \cdot \sum{(y_m - \hat{y}_m)^2}}$$
$y_m - \hat{y}_m$ ist die Abweichung des tatsächlichen Messwertes vom modellierten Wert, also das Residuum.</p>

<p><strong>Schätzer der Standardfehler der Regressionskoeffizienten:</strong></p>

<p>$$\hat{\sigma}_{\beta_0} = \hat{\sigma}_e \cdot \sqrt{\frac{1}{n} + \frac{\overline{x}^2}{n \cdot s^2_X}}$$</p>

<p>$$\hat{\sigma}_{\beta_1} = \sqrt{\frac{\hat{\sigma_e}^2}{n \cdot s_X^2}}$$</p>

<h3 id="alternative-wege-zur-bestimmung-der-regressionskoeffizienten">
<a class="anchor" href="#alternative-wege-zur-bestimmung-der-regressionskoeffizienten" aria-hidden="true"><span class="octicon octicon-link"></span></a>Alternative Wege zur Bestimmung der Regressionskoeffizienten</h3>

<h4 id="kriterium-der-kleinsten-quadrate">
<a class="anchor" href="#kriterium-der-kleinsten-quadrate" aria-hidden="true"><span class="octicon octicon-link"></span></a>Kriterium der kleinsten Quadrate</h4>

<p>Die Regressionskoeffizienten werden so geschätzt, dass die Summe der quadrierten Abweichungen der tatsächlichen Messwerte von den modellierten Werten minimal wird.</p>

<p>$$\sum_{m=1}^n{(y_m - \hat{y}_m)^2} \rightarrow min$$</p>

<h4 id="likelihood-maximierung">
<a class="anchor" href="#likelihood-maximierung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Likelihood-Maximierung</h4>

<p>Die Grundannahme, dass die abhängige Variable in der Population normalverteilt ist, führt dazu, dass sie wie folgt modelliert werden kann:</p>

<p>$$y \sim Normal(\beta_0 + \beta_1 \cdot x_m, \sigma_e^2)$$</p>

<p>Die tatsächliche Ausprägung folgt einer Normalverteilung, bei der der Mittelwert der Vorhersagewert des linearen Modells und die Standardabweichung der Standardschätzfehler ist.</p>

<p>Für diese Normalverteilung kann die Likelihood der empirisch beobachteten Daten bestimmt werden.</p>

<p>Es werden dann die Regressionskoeffizienten gesucht, für die die Likelihood bzw. Log(Likelihood) maximal werden.</p>

<p><strong>Sowohl die Likelihood-Maximierung, als auch das Kriterium der kleinsten Quadrate sind Optimierungsprobleme, die sich kaum von Hand lösen lassen und durch Computer numerisch gelöst werden müssen.</strong></p>

<h3 id="hypothesenprüfung-bei-einfacher-linearer-regression">
<a class="anchor" href="#hypothesenpr%C3%BCfung-bei-einfacher-linearer-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesenprüfung bei einfacher linearer Regression</h3>

<p>$H_{00}$: $\beta_1 = 0$, $H_{01}$: $\beta_1 \neq 0$</p>

<p>$$t = \frac{b_1 - \beta_{10}}{\hat{\sigma}_{b_1}} \sim Student(df = n - 2)$$</p>

<p>($\beta_{10} = 0$ bei spezieller Nullhypothese $H_0: \beta_1 = 0$)</p>

<p>$H_{10}$: $\beta_0 = \beta_{00}$, $H_{11}$: $\beta_0 \neq \beta_{00}$</p>

<p>$$t = \frac{b_0 - \beta_{00}}{\hat{\sigma}_{b_0}} \sim Student(df = n - 2)$$</p>

<h3 id="konfidenzintervalle-für-regressionskoeffizienten">
<a class="anchor" href="#konfidenzintervalle-f%C3%BCr-regressionskoeffizienten" aria-hidden="true"><span class="octicon octicon-link"></span></a>Konfidenzintervalle für Regressionskoeffizienten</h3>

<p>$$b_1 \pm t_{(1-\frac{\alpha}{2}; n-2)} \cdot \hat{\sigma}_{b_1}$$</p>

<p>$$b_0 \pm t_{(1-\frac{\alpha}{2}; n-2)} \cdot \hat{\sigma}_{b_0}$$</p>

<h3 id="einfache-lineare-regression-in-r">
<a class="anchor" href="#einfache-lineare-regression-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Einfache lineare Regression in R</h3>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">samples</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">lm1</span><span class="w">

</span><span class="n">summary</span><span class="p">(</span><span class="n">lm1</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## Call:
## lm(formula = y ~ x, data = samples)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7060 -0.9742 -0.4539  0.9479  3.0728 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  7.25267    1.35524   5.352 4.37e-05 ***
## x            0.30451    0.05124   5.943 1.27e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.625 on 18 degrees of freedom
## Multiple R-squared:  0.6624,	Adjusted R-squared:  0.6437 
## F-statistic: 35.32 on 1 and 18 DF,  p-value: 1.267e-05
</code></pre></div></div>

<p>Extraktion der Koeffizienten:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">coef</span><span class="p">(</span><span class="n">lm1</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## (Intercept)           x 
##    7.252667    0.304506
</code></pre></div></div>

<p>Konfidenzintervalle der Koeffizienten:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">confint</span><span class="p">(</span><span class="n">lm1</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##                 2.5 %     97.5 %
## (Intercept) 4.4054111 10.0999220
## x           0.1968588  0.4121532
</code></pre></div></div>

<p>Residuen:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">resid</span><span class="p">(</span><span class="n">lm1</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##            1            2            3            4            5            6            7            8            9           10           11           12           13 
## -0.810005726 -1.669324066 -0.782480228  1.163274890  0.924972643  0.005258351 -1.220609279 -0.634036491  3.072819146  1.016600629 -0.523908529 -1.250597374  0.222625960 
##           14           15           16           17           18           19           20 
## -2.706005447 -0.383962449 -0.892032207  3.008439197  2.631282829  0.436793706 -1.609105554
</code></pre></div></div>

<p>Modellierte(“fitted”) Werte:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fitted</span><span class="p">(</span><span class="n">lm1</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##        1        2        3        4        5        6        7        8        9       10       11       12       13       14       15       16       17       18       19 
## 11.83282 17.67453 13.81424 13.29164 15.79802 15.81898 11.43628 12.98896 15.57430 16.06184 14.97508 14.91121 15.17624 15.38830 18.22633 17.87727 11.31583 16.72605 18.49644 
##       20 
## 12.85313
</code></pre></div></div>

<h2 id="multiple-lineare-regression">
<a class="anchor" href="#multiple-lineare-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multiple lineare Regression</h2>

<ul>
  <li>Vorhersage von metrischen Endpunkten bei mehreren unabhängigen Variablen</li>
  <li>Kontrolle von Störvariablen</li>
  <li>
    <p>Berücksichtigung von Redundanzen zwischen Merkmalen</p>

    <p>z.B. Wenn UVs nicht unabhängig voneinander sind</p>
  </li>
</ul>

<h3 id="modellgleichung">
<a class="anchor" href="#modellgleichung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Modellgleichung</h3>

<p>In der Stichprobe:</p>

<p>$$Y = b_0 + b_1 \cdot X_1 + b_2 \cdot X_2 + \dots + b_j \cdot X_j + E$$</p>

<p>In der Population:</p>

<p>$$Y = \beta_0 + \beta_1 \cdot X_1 + \beta_2 \cdot X_2 + \dots + \beta_j \cdot X_J + \epsilon$$</p>

<h3 id="bestimmung-der-regressionskoeffizienten-1">
<a class="anchor" href="#bestimmung-der-regressionskoeffizienten-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bestimmung der Regressionskoeffizienten</h3>

<p>Ähnlich wie bei einfacher linearer Regression werden die Koeffizienten so geschätzt, dass die Summer der quadrierten Abweichungen von den modellierten Werten minimal wird:</p>

<p>$$\sum_{m=1}^n{(y_m - \hat{y}_m)^2} \rightarrow min$$
Geometrische Sicht:</p>

<p>Bei zwei unabhängigen Variablen erzeugt das Regressionsmodell eine Ebene (statt einer Geraden bei einfacher Regression). Die Ebene wird so platziert, dass der Abstände aller empirischen Messpunkte zur Ebene minimal werden.</p>

<p>Die Regressionskoeffizienten können auch analog zur einfacher Regression berechnet werden, was aber unüblich ist. (siehe EGS Kapitel 19.3.3)</p>

<p>Stattdessen erfolgt die Bestimmung bei multipler Regression eher numerisch.</p>

<h3 id="kompensatorisches-modell">
<a class="anchor" href="#kompensatorisches-modell" aria-hidden="true"><span class="octicon octicon-link"></span></a>Kompensatorisches Modell</h3>

<p>Mehrere Kombinationen vom UVs können in der multiplen Regression zur gleichen Ausprägung der AV führen.</p>

<p>Beispiel:</p>

<ul>
  <li>$\beta_0 = 10$</li>
  <li>$\beta_1 = 2$</li>
  <li>$\beta_2 = 1$</li>
</ul>

<p>$$10 + 2 \cdot 2 + 1 \cdot 0.5 = 10 + 2 \cdot 1 + 1 \cdot 2.5 = 14.5$$</p>

<p>Für $X_1 = 2; X_2 = 0.5$ sowie für $X_1 = 1; X_2 = 2.5$ ergibt sich das gleiche $Y = 14.5$.</p>

<p>Die UVs können also ihre Einflüsse gegenseitig kompensieren.</p>

<h3 id="dummy-kodierung">
<a class="anchor" href="#dummy-kodierung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dummy Kodierung</h3>

<p>Bei UVs, die mehr als zwei Faktorstufen beinhalten, wird jede eine Referenzkategorie definiert und alle anderen Stufen als “Dummy”-Variablen kodiert die jeweils Ausprägungen 0 oder 1 haben.</p>

<h4 id="schritte-der-dummy-kodieruung">
<a class="anchor" href="#schritte-der-dummy-kodieruung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Schritte der Dummy-Kodieruung</h4>

<ol>
  <li>
    <p>Referenzkategorie zuweisen (vollkommen willkürlich)</p>

    <p>Die Faktorstufe der Referenzkategorie hat auf allen Dummy-Variablen den Wert 0.</p>
  </li>
  <li>
    <p>Allen anderen Kategorien der unabhängigen Faktorvariablen werden Dummy-Werte zugewiesen, so dass:</p>
    <ul>
      <li>jede Kategorie in nur einer Dummy-Variablen den Wert 1 hat</li>
      <li>jede Dummy-Variable nur für eine Kategorie den Wert 1 hat und sonst überall 0</li>
    </ul>
  </li>
</ol>

<h3 id="interpretation-von-multiplen-regressionsgewichten">
<a class="anchor" href="#interpretation-von-multiplen-regressionsgewichten" aria-hidden="true"><span class="octicon octicon-link"></span></a>Interpretation von multiplen Regressionsgewichten</h3>

<h4 id="als-regressionsgewicht-einer-bedingten-einfacher-regression">
<a class="anchor" href="#als-regressionsgewicht-einer-bedingten-einfacher-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Als Regressionsgewicht einer bedingten einfacher Regression.</h4>

<p>Alle UVs bis auf eine werden konstant gehalten.</p>

<p>Nur noch eine UV und ihr Regressionsgewicht haben Einfluss auf $Y$.</p>

<p>Entspricht dem Modell für eine Subgruppe an Personen, die hinsichtlich aller UVs bis auf eine identisch sind.</p>

<h4 id="als-regressionsgewicht-zweier-regressionsredsiduen">
<a class="anchor" href="#als-regressionsgewicht-zweier-regressionsredsiduen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Als Regressionsgewicht zweier Regressionsredsiduen</h4>

<p>Es werden zwei Residuen von einfachen Regressionen gebildet:</p>

<ul>
  <li>Residuum von $Y(X_2)$ ($Y$ in Abhängigkeit von $X_2$</li>
  <li>Residuum von $X_1(X_2)$ ($X_1$ in Abhängigkeit von $X_2$</li>
</ul>

<p>Diese Residuen werden dann als unabhängige und abhängige Variable in einer weiteren einfacher Regression verwendet.</p>

<p>Dadurch werden die betrachtete UV und die AV von Abhängigkeiten zu anderen UVs bereinigt. Das Regressionsgewicht quantifiziert den Einfluss der betrachteten UV, der nicht bereits durch andere UVs erklärt wird.</p>

<h3 id="inkrementelle-varianzaufklärung">
<a class="anchor" href="#inkrementelle-varianzaufkl%C3%A4rung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Inkrementelle Varianzaufklärung</h3>

<p>Der Determinationskoeffizient $R^2$ ist wie in der einfacher Regression ein Maß dafür, wie präzise die Vorhersagen des Modells sind.</p>

<p>Mit zumessender Anzahl UVs wird das Modell präziser:</p>

<table>
  <tbody>
    <tr>
      <td>$$R^2_{Y</td>
      <td>X_1} \lt R^2_{Y</td>
      <td>X_1,X_2} \lt R^2_{Y</td>
      <td>X_1, X_2, X_3}$$</td>
    </tr>
  </tbody>
</table>

<h3 id="punktschätzung-der-varianzaufklärung">
<a class="anchor" href="#punktsch%C3%A4tzung-der-varianzaufkl%C3%A4rung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Punktschätzung der Varianzaufklärung</h3>

<p><strong>$R^2$ ist kein erwartungstreuer Schätzer der Varianzaufklärung in der Population $\rho^2$.</strong></p>

<p>Beispiel: 100 Stichproben zu je $n =10$ Messpunkten von drei komplett unabhängigen Variablen $X_1$, $X_2$ und $Y$. Alle Variablen sind zufällig generiert und normalverteilt.</p>

<p>Korrelationsplot der ersten 20 Stichproben (200 Messwerte):</p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-74-1.png" alt="plot of chunk unnamed-chunk-74" width="576" style="display: block; margin: auto;"></p>

<p>Es sollte also keine Korrelation zwischen den Variablen geben und damit auch keine Varianzaufklärung. Entsprechend sollte in jeder Stichprobe $R^2 \approx 0$ gelten.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">stichprobe</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">mutate</span><span class="p">(</span><span class="w">
  </span><span class="n">Rsq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span><span class="n">lm</span><span class="p">(</span><span class="n">Y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">X1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X2</span><span class="p">))</span><span class="o">$</span><span class="n">r.squared</span><span class="w">
</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">samples</span><span class="w">
</span></code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-76-1.png" alt="plot of chunk unnamed-chunk-76" width="576" style="display: block; margin: auto;"></p>

<p>Durchschnittlicher Determinationskoeffizient, $\overline{R}^2$:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 0.2174016
</code></pre></div></div>

<p>Es muss eine Adjustierung vorgenommen werden, damit $\rho^2$ nicht überschätzt wird.</p>

<h4 id="wherry-1-adjustierung">
<a class="anchor" href="#wherry-1-adjustierung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Wherry-1-Adjustierung</h4>

<p>$$\hat{\rho}^2 = 1 - \frac{n-1}{n-k-1} \cdot (1-R^2)$$
($n$: Stichprobengröße, $k$: Anzahl der Regressionsgewichte)</p>

<p>Diese wird standardmäßig in R verwendet.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">stichprobe</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">mutate</span><span class="p">(</span><span class="w">
  </span><span class="n">Rsq_adj</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span><span class="n">lm</span><span class="p">(</span><span class="n">Y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">X1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X2</span><span class="p">))</span><span class="o">$</span><span class="n">adj.r.squared</span><span class="w">
</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">samples</span><span class="w">
</span></code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-79-1.png" alt="plot of chunk unnamed-chunk-79" width="576" style="display: block; margin: auto;"></p>

<p>Durchschnittlicher adjustierter Determinationskoeffizient, $\overline{R}_{Wherry-1}^2$:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] -0.006197947
</code></pre></div></div>

<h4 id="adjustierung-nach-olkin--pratt-2017">
<a class="anchor" href="#adjustierung-nach-olkin--pratt-2017" aria-hidden="true"><span class="octicon octicon-link"></span></a>Adjustierung nach Olkin &amp; Pratt (2017)</h4>

<p>$$\hat{\rho}^2 = 1= \frac{n-3}{n-k-1} \cdot ((1-R^2) + \frac{2}{n-k-1} \cdot (1-R^2))$$</p>

<p>In R kann die Olkin-Pratt-Adjustierung mit dem Paket <code class="language-plaintext highlighter-rouge">semEff</code> berechnet werden:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">semEff</span><span class="p">)</span><span class="w">

</span><span class="c1"># Berechnung ist sehr langsam, daher hier nur für erste Stichprobe</span><span class="w">
</span><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">filter</span><span class="p">(</span><span class="n">stichprobe</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">mutate</span><span class="p">(</span><span class="w">
  </span><span class="n">Rsq_OP</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">R2</span><span class="p">(</span><span class="n">lm</span><span class="p">(</span><span class="n">Y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">X1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X2</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">.</span><span class="p">),</span><span class="w"> </span><span class="n">adj.type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"olkin-pratt"</span><span class="p">)[</span><span class="m">2</span><span class="p">]</span><span class="w">
</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">samples</span><span class="w">
</span></code></pre></div></div>

<p>Durchschnittlicher adjustierter Determinationskoeffizient, $\overline{R}_{Olkin-Pratt}^2$:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="o">$</span><span class="n">Rsq_OP</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 0
</code></pre></div></div>

<h3 id="hypothesenprüfung-mit-multipler-linearer-regression">
<a class="anchor" href="#hypothesenpr%C3%BCfung-mit-multipler-linearer-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesenprüfung mit multipler linearer Regression</h3>

<h4 id="hypothesen-zum-gesamtmodell-globale-hypothesen">
<a class="anchor" href="#hypothesen-zum-gesamtmodell-globale-hypothesen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesen zum Gesamtmodell, globale Hypothesen</h4>

<p>$$H_0: \beta_1 = \beta_2 = \dots = \beta_k = 0 \rightarrow H_o: \rho^2 = 0$$</p>

<p>Alle Regressionsgewichte sind null, also wird keine Varianz durch die unabhängigen Variablen aufgeklärt.</p>

<p>$$H_1: \beta_j \ne 0 \rightarrow \rho^2 \ne 0$$</p>

<p>Mindestens eines der Regressionsgewichte $\beta_j$ ist nicht null, also wird ein Teil der Varianz aufgeklärt.</p>

<p>Verteilung der Prüfgröße unter der Nullhypothese:</p>

<p>$$F = \frac{n-k-1}{k} \cdot \frac{R^2}{1-R^2} \sim F(df_1 = k, df_2 = n-k-1)$$</p>

<h4 id="hypothesen-über-einzelne-regressionsgewichte">
<a class="anchor" href="#hypothesen-%C3%BCber-einzelne-regressionsgewichte" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesen über einzelne Regressionsgewichte</h4>

<p>$$H_0 : \beta_j = 0$$</p>

<p>Verteilung der Prüfgröße unter $H_0$:</p>

<p>$$T = \frac{\hat{\beta}<em>j}{\hat{\sigma}</em>{\beta_j}} \sim Student(df = n-k-1)$$</p>

<p>Das geschätzte Regressionsgewicht $\hat\beta_j$ wird am <a href="#standardfehler-der-modellparameter">geschätzten Standardfehler</a> $\hat\sigma_{\beta_j}$ standardisiert und folgt dann eine Student-T-Verteilung.</p>

<h4 id="hypothesen-über-modellvergleiche">
<a class="anchor" href="#hypothesen-%C3%BCber-modellvergleiche" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hypothesen über Modellvergleiche</h4>

<p>Die “Nützlichkeit” einer oder mehrerer unabhängiger Variablen kann durch den Vergleich eines uneingeschränkten Modells, welches alle UVs enthält, mit einem eingeschränkten Modell, in dem eine oder mehrere UV fehlen, bestimmt werden.</p>

<p>Indem UVs entfernt werden, verschwindet ihre Varianzaufklärung im nun größeren Residuum.</p>

<p>Verglichen werden letztendlich die Determinationskoeffizienten der Modelle $R_u^2$ (uneingeschränkt) und $R_e^2$ (eingeschränkt).</p>

<p>Verteilung unter der Nullhypothese $H_0: \rho_u^2 - \rho_y^2 = 0$:</p>

<p>$$F = \frac{n-k_u-1}{k_u - k_e} \cdot \frac{R_u^2 - R_e^2}{1-R_u^2} \sim F(df_1 = k_u - k_e, df_2 = n-k_u-1)$$</p>

<p>Sonderfall, wenn nur eine UV entfernt wird:</p>

<p>$$F = (n-k_u-1) \cdot \frac{R_u^2-R_e^2}{1-R_u^2} \sim F(df_1 = 1, df_2 = n - k_u -1)$$</p>

<p>Dieser F-Wert (für nur eine entfernte UV) entspricht dem quadrierten T-Wert aus der <a href="#hypothesen-%C3%BCber-einzelne-regressionsgewichte">Hypothesenprüfung über einzelne Regressionsgewichte</a>. Beide Ansätze sind äquivalent.</p>

<h3 id="modellvergleiche-in-r">
<a class="anchor" href="#modellvergleiche-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Modellvergleiche in R</h3>

<p>Beispiel:</p>

<ul>
  <li>Stichprobe mit $n=20$</li>
  <li>2 unabhängige, normalverteilte Variablen</li>
  <li>$Y$ korreliert mit $X_1$ leicht positiv und mit $X_2$ leicht negativ</li>
  <li>im Datensatz ist ein simulierter Interaktionseffekt vorhanden</li>
  <li>normalverteiltes Residuum</li>
</ul>

<p><img src="statistik-2-abbildungen/unnamed-chunk-83-1.png" alt="plot of chunk unnamed-chunk-83" width="576" style="display: block; margin: auto;"></p>

<p>Vergleich von uneingeschränktem Modell (mit Interaktion) und eingeschränktem (ohne Interaktion):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lm_u</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">Y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">X1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">X2</span><span class="p">,</span><span class="w"> </span><span class="n">samples</span><span class="p">)</span><span class="w">
</span><span class="n">lm_e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">Y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">X1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X2</span><span class="p">,</span><span class="w"> </span><span class="n">samples</span><span class="p">)</span><span class="w">

</span><span class="n">anova</span><span class="p">(</span><span class="n">lm_u</span><span class="p">,</span><span class="w"> </span><span class="n">lm_e</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Analysis of Variance Table
## 
## Model 1: Y ~ X1 * X2
## Model 2: Y ~ X1 + X2
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    196 3165.1                                  
## 2    197 3395.8 -1   -230.69 14.286 0.0002084 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
</code></pre></div></div>

<p>Das uneingeschränkte Modell klärt signifikant mehr Varianz auf als das eingeschränkte. Es gibt also einen Interaktionseffekt.</p>

<p>Vergleich der Determinationskoeffizienten:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">R_u</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span><span class="n">lm_u</span><span class="p">)</span><span class="o">$</span><span class="n">adj.r.squared</span><span class="w">
</span><span class="n">R_e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">summary</span><span class="p">(</span><span class="n">lm_e</span><span class="p">)</span><span class="o">$</span><span class="n">adj.r.squared</span><span class="w">

</span><span class="n">dR</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">R_u</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">R_e</span><span class="w">

</span><span class="n">dR</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 0.0442245
</code></pre></div></div>

<h4 id="likelihood-quotienten-test">
<a class="anchor" href="#likelihood-quotienten-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Likelihood-Quotienten-Test</h4>

<p>Wilks’ $\Lambda$: Quotient der Likelihoods der empirischen Daten unter dem eingeschränkten und dem uneingeschränkten Modell.</p>

<p>$$\Lambda = \frac{Lik(Y_e)}{Lik(Y_u)}$$</p>

<p>Prüfgröße des Likelihood-Quotienten-Tests:</p>

<p>$$-2 \cdot log(\Lambda) = -2 \cdot log(Lik(Y_e) + 2 \cdot log(Lik(Y_u))$$</p>

<p>Unter der Nullhypothese $H_0: \rho^2_u - \rho^2_e = 0$ gilt asymptotisch (also bei ausreichend großen Stichproben):</p>

<p>$$-2 \cdot log(\Lambda) \sim \chi^2(df = k_u - k_e)$$</p>

<h3 id="interaktionseffekte-bei-mutlipler-linearer-regression">
<a class="anchor" href="#interaktionseffekte-bei-mutlipler-linearer-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Interaktionseffekte bei mutlipler linearer Regression</h3>

<p>$$Y = \beta_0 + \beta_1 \cdot X_1 + \beta_2 \cdot X_2 + \beta_3 \cdot X_1 \cdot X_2 + \epsilon$$</p>

<p>$\beta_3 \cdot X_1 \cdot X_2$ ist der Interaktionsterm. $\beta_3$ ist das Regressionsgewicht des Interaktionseffektes.</p>

<p>Durch Modellvergleiche mit eingeschränkten Modellen, die den Interaktionsterm nicht enthalten, kann bestimmt werden, welcher Anteil der Varianz durch die Interaktion aufgeklärt wird.</p>

<p>Beispielhypothese:</p>

<p>$$Y_u = \beta_0 + \beta_1 \cdot X_1 + \beta_2 \cdot X_2 + \beta_3 \cdot X_1 \cdot X_2 + \epsilon$$
$$Y_e = \beta_0 + \beta_1 \cdot X_1 + \beta_2 \cdot X_2 + \epsilon$$
$H_0: \rho^2_u - \rho^2_e = 0$, die Interaktion von $X_1$ und $X_2$ klärt keine zusätzliche Varianz auf.</p>

<h2 id="annahmen-des-allgemeinen-linearen-modells">
<a class="anchor" href="#annahmen-des-allgemeinen-linearen-modells" aria-hidden="true"><span class="octicon octicon-link"></span></a>Annahmen des allgemeinen linearen Modells</h2>

<ul>
  <li>Messfehlerfreiheit der UVs</li>
  <li>korrekte Spezifikation des Modells (Linearität)</li>
  <li>Homoskedastizität</li>
  <li>Unabhängigkeit der Residuen</li>
  <li>Normalverteilung der Residuen</li>
</ul>

<h3 id="korrekte-spezifikation-linearität">
<a class="anchor" href="#korrekte-spezifikation-linearit%C3%A4t" aria-hidden="true"><span class="octicon octicon-link"></span></a>Korrekte Spezifikation, Linearität</h3>

<p><strong>Underfitting</strong>: relevante UVs fehlen im Modell</p>

<p><strong>Overfitting</strong>: irrelevante UVs, die keine Varianz aufklären, sind im Modell enthalten.</p>

<p>Form der Abbilddung der AV auf die UVs muss korrekt sein.</p>

<p>Bei Verletzung der Annahmen:</p>

<ul>
  <li>verzerrte Schätzer der Regressionsgewichte</li>
  <li>erhöhter Prognosefehler</li>
  <li>verringerte Teststärke</li>
  <li>falsche Schlussfolgerungen</li>
</ul>

<h4 id="prüfung-der-linearität">
<a class="anchor" href="#pr%C3%BCfung-der-linearit%C3%A4t" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prüfung der Linearität</h4>

<p>Plot der Residuen gegenüber den vorhergesagten (fitted) Werten</p>

<p><strong>Eingeschränktes Modell:</strong></p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-86-1.png" alt="plot of chunk unnamed-chunk-86" width="576" style="display: block; margin: auto;"></p>

<p><strong>Uneingeschränktes Modell:</strong></p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-87-1.png" alt="plot of chunk unnamed-chunk-87" width="576" style="display: block; margin: auto;"></p>

<p><strong>Die durchschnittlichen Residuen aller Kombinationen der UVs sollten einer Geraden mit Steigung 0 folgen, wenn Linearität gegeben ist.</strong></p>

<h3 id="prüfung-der-homoskedastizität">
<a class="anchor" href="#pr%C3%BCfung-der-homoskedastizit%C3%A4t" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prüfung der Homoskedastizität</h3>

<h4 id="breusch-pagan-test-in-r">
<a class="anchor" href="#breusch-pagan-test-in-r" aria-hidden="true"><span class="octicon octicon-link"></span></a>Breusch-Pagan-Test in R</h4>

<p>(mit Paket <code class="language-plaintext highlighter-rouge">lmtest</code>)</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">lmtest</span><span class="p">)</span><span class="w">

</span><span class="n">bptest</span><span class="p">(</span><span class="n">lm_u</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	studentized Breusch-Pagan test
## 
## data:  lm_u
## BP = 3.351, df = 3, p-value = 0.3406
</code></pre></div></div>

<p>Wenn $p \ge 0.05$, dann kann die Nullhypothese, dass Homoskedastizität vorliegt, akzeptiert werden.</p>

<p><strong>Der Breusch-Pagan-Test ist auch sensitiv für eine Verletzung der Unabhängigkeit der Residuen.</strong></p>

<h4 id="visuelle-prüfung-der-heteroskedastizität">
<a class="anchor" href="#visuelle-pr%C3%BCfung-der-heteroskedastizit%C3%A4t" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visuelle Prüfung der Heteroskedastizität</h4>

<p>Plot der Residuen gegenüber den vorhergesagten (fitted) Werten.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit_u</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">res_u</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Vorhersage"</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Residuum"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme_custom</span><span class="w">
</span></code></pre></div></div>

<p><img src="statistik-2-abbildungen/unnamed-chunk-89-1.png" alt="plot of chunk unnamed-chunk-89" width="576" style="display: block; margin: auto;"></p>

<p>Es sind keine offensichtlichen Unterschieden in der Varianz der Residuen erkennbar. Damit liegt vermutlich Homoskedastizität vor, sollte aber dennoch genau getestet werden.</p>

<h3 id="normalverteilung-der-residuen">
<a class="anchor" href="#normalverteilung-der-residuen" aria-hidden="true"><span class="octicon octicon-link"></span></a>Normalverteilung der Residuen</h3>

<h4 id="shapiro-wilk-test">
<a class="anchor" href="#shapiro-wilk-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Shapiro-Wilk-Test</h4>

<ul>
  <li>testet beliebige Werte auf Normalverteilung</li>
</ul>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">shapiro.test</span><span class="p">(</span><span class="n">samples</span><span class="o">$</span><span class="n">res_u</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## 	Shapiro-Wilk normality test
## 
## data:  samples$res_u
## W = 0.99108, p-value = 0.2553
</code></pre></div></div>

<p>Wenn $p \ge 0.05$, dann kann Normalverteilung der Residuen angenommen werden.</p>

<h4 id="visuelle-prüfung-der-normalverteilung">
<a class="anchor" href="#visuelle-pr%C3%BCfung-der-normalverteilung" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visuelle Prüfung der Normalverteilung</h4>

<p><strong>Histogram der Residuen</strong></p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-91-1.png" alt="plot of chunk unnamed-chunk-91" width="576" style="display: block; margin: auto;"></p>

<p><strong>Q-Q-Plot, Quantil-Quantil-Diagramm</strong></p>

<p><img src="statistik-2-abbildungen/unnamed-chunk-92-1.png" alt="plot of chunk unnamed-chunk-92" width="576" style="display: block; margin: auto;"></p>

<p>Wenn die Residuumswerte nah an der theoretischen Normalverteilung (entlang der diagonalen Geraden) liegen, liegt vermutlich Normalverteilung vor, sollte aber noch genau getestet werden.</p>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->


<div class="post-nav">
  <span>
    
  </span>
  <span>
    
  </span>
</div>
  </section>


    </main>
    


<footer class="background" style="--image: url('/preview/pr-9/images/lines-21.png')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    
  </div>

  <div>
    © 2024
    PHB
      |   Erstellt mit
    <a href="https://github.com/greenelab/lab-website-template">
      Lab Website Template
    </a>
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
